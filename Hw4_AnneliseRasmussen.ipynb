{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NojdHjLn6TqU",
        "outputId": "5e19ec93-4796-4edd-e01b-271eac5dc44a"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.13.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the Logan_housing.csv file as save it in a data frame df. Show the head (top 5 rows) of the data frame! (3 points)"
      ],
      "metadata": {
        "id": "UqnHWTp7BSaY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "TEI_CRlyA4xh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Logan_housing.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "djqJW86-C6eH",
        "outputId": "5485da9f-1b36-43ac-9bca-85608a95fb63"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sold Price  DOM  Garage Capacity  HOA Fee Irregular Shape Quadrant  \\\n",
              "0      176000    5                2        0              No       NW   \n",
              "1      225000    6                2        0              No       NW   \n",
              "2      274900   14                2        0              No       NW   \n",
              "3      175000   16                1        0              No       NW   \n",
              "4      179000   29                0        0              No       NW   \n",
              "\n",
              "  School District              Sold Terms  Total Bedrooms  Total Bathrooms  \\\n",
              "0           Cache                     FHA               3                1   \n",
              "1           Cache            Conventional               4                2   \n",
              "2           Cache            Conventional               3                1   \n",
              "3           Cache  USDA Rural Development               4                1   \n",
              "4           Cache                    Cash               4                2   \n",
              "\n",
              "   Total Square Feet  Year Built    Zip  year_sold  month_sold  \\\n",
              "0               1031        1974  84335       2018           9   \n",
              "1               2091        1995  84335       2018           7   \n",
              "2               2016        1980  84335       2018          11   \n",
              "3               1920        1978  84335       2018           6   \n",
              "4               1329        1976  84335       2018           9   \n",
              "\n",
              "   built_after_2000  \n",
              "0                 0  \n",
              "1                 0  \n",
              "2                 0  \n",
              "3                 0  \n",
              "4                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a58b668-8837-4106-b12c-b3da6bac9d07\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sold Price</th>\n",
              "      <th>DOM</th>\n",
              "      <th>Garage Capacity</th>\n",
              "      <th>HOA Fee</th>\n",
              "      <th>Irregular Shape</th>\n",
              "      <th>Quadrant</th>\n",
              "      <th>School District</th>\n",
              "      <th>Sold Terms</th>\n",
              "      <th>Total Bedrooms</th>\n",
              "      <th>Total Bathrooms</th>\n",
              "      <th>Total Square Feet</th>\n",
              "      <th>Year Built</th>\n",
              "      <th>Zip</th>\n",
              "      <th>year_sold</th>\n",
              "      <th>month_sold</th>\n",
              "      <th>built_after_2000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>176000</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NW</td>\n",
              "      <td>Cache</td>\n",
              "      <td>FHA</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1031</td>\n",
              "      <td>1974</td>\n",
              "      <td>84335</td>\n",
              "      <td>2018</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>225000</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NW</td>\n",
              "      <td>Cache</td>\n",
              "      <td>Conventional</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2091</td>\n",
              "      <td>1995</td>\n",
              "      <td>84335</td>\n",
              "      <td>2018</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>274900</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NW</td>\n",
              "      <td>Cache</td>\n",
              "      <td>Conventional</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "      <td>1980</td>\n",
              "      <td>84335</td>\n",
              "      <td>2018</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>175000</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NW</td>\n",
              "      <td>Cache</td>\n",
              "      <td>USDA Rural Development</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1920</td>\n",
              "      <td>1978</td>\n",
              "      <td>84335</td>\n",
              "      <td>2018</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>179000</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NW</td>\n",
              "      <td>Cache</td>\n",
              "      <td>Cash</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1329</td>\n",
              "      <td>1976</td>\n",
              "      <td>84335</td>\n",
              "      <td>2018</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a58b668-8837-4106-b12c-b3da6bac9d07')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a58b668-8837-4106-b12c-b3da6bac9d07 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a58b668-8837-4106-b12c-b3da6bac9d07');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e984e5fe-626c-4601-af93-287a8dc7c545\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e984e5fe-626c-4601-af93-287a8dc7c545')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e984e5fe-626c-4601-af93-287a8dc7c545 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check to see if there is any missing observations in the data set. (2 points)"
      ],
      "metadata": {
        "id": "N5nEMUorBiDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDz88j07CiZw",
        "outputId": "5a490407-4eaa-4959-fa11-93c8a802ebf3"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sold Price           False\n",
              "DOM                  False\n",
              "Garage Capacity      False\n",
              "HOA Fee              False\n",
              "Irregular Shape      False\n",
              "Quadrant             False\n",
              "School District      False\n",
              "Sold Terms           False\n",
              "Total Bedrooms       False\n",
              "Total Bathrooms      False\n",
              "Total Square Feet    False\n",
              "Year Built           False\n",
              "Zip                  False\n",
              "year_sold            False\n",
              "month_sold           False\n",
              "built_after_2000     False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine which variables should be numerics and which should be categorical. Go ahead and change their type in the original data frame. (10 points)"
      ],
      "metadata": {
        "id": "EwjbsCTQBkNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12xmit7YCh7y",
        "outputId": "ff153a63-6fbe-46a3-f62d-7847138d6af4"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sold Price           1217\n",
              "DOM                   248\n",
              "Garage Capacity        14\n",
              "HOA Fee                96\n",
              "Irregular Shape         2\n",
              "Quadrant                4\n",
              "School District         2\n",
              "Sold Terms              6\n",
              "Total Bedrooms          9\n",
              "Total Bathrooms         7\n",
              "Total Square Feet    2009\n",
              "Year Built            136\n",
              "Zip                    16\n",
              "year_sold               3\n",
              "month_sold             12\n",
              "built_after_2000        2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1q7tTX0Fc2g",
        "outputId": "a38d772d-8369-4ce7-d853-615c9942457a"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4110 entries, 0 to 4109\n",
            "Data columns (total 16 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   Sold Price         4110 non-null   int64 \n",
            " 1   DOM                4110 non-null   int64 \n",
            " 2   Garage Capacity    4110 non-null   int64 \n",
            " 3   HOA Fee            4110 non-null   int64 \n",
            " 4   Irregular Shape    4110 non-null   object\n",
            " 5   Quadrant           4110 non-null   object\n",
            " 6   School District    4110 non-null   object\n",
            " 7   Sold Terms         4110 non-null   object\n",
            " 8   Total Bedrooms     4110 non-null   int64 \n",
            " 9   Total Bathrooms    4110 non-null   int64 \n",
            " 10  Total Square Feet  4110 non-null   int64 \n",
            " 11  Year Built         4110 non-null   int64 \n",
            " 12  Zip                4110 non-null   int64 \n",
            " 13  year_sold          4110 non-null   int64 \n",
            " 14  month_sold         4110 non-null   int64 \n",
            " 15  built_after_2000   4110 non-null   int64 \n",
            "dtypes: int64(12), object(4)\n",
            "memory usage: 513.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_convert = ['built_after_2000','Sold Terms', 'School District', 'Quadrant','Irregular Shape']\n",
        "for col in columns_convert:\n",
        "    df[col] = df[col].astype('category')\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VMkCvBoChl_",
        "outputId": "18b88af9-5d56-4c71-caa4-e7525113b941"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4110 entries, 0 to 4109\n",
            "Data columns (total 16 columns):\n",
            " #   Column             Non-Null Count  Dtype   \n",
            "---  ------             --------------  -----   \n",
            " 0   Sold Price         4110 non-null   int64   \n",
            " 1   DOM                4110 non-null   int64   \n",
            " 2   Garage Capacity    4110 non-null   int64   \n",
            " 3   HOA Fee            4110 non-null   int64   \n",
            " 4   Irregular Shape    4110 non-null   category\n",
            " 5   Quadrant           4110 non-null   category\n",
            " 6   School District    4110 non-null   category\n",
            " 7   Sold Terms         4110 non-null   category\n",
            " 8   Total Bedrooms     4110 non-null   int64   \n",
            " 9   Total Bathrooms    4110 non-null   int64   \n",
            " 10  Total Square Feet  4110 non-null   int64   \n",
            " 11  Year Built         4110 non-null   int64   \n",
            " 12  Zip                4110 non-null   int64   \n",
            " 13  year_sold          4110 non-null   int64   \n",
            " 14  month_sold         4110 non-null   int64   \n",
            " 15  built_after_2000   4110 non-null   category\n",
            "dtypes: category(5), int64(11)\n",
            "memory usage: 374.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "In DNN, we need to change the categorical variables into dummy variables. Do this transformation and report the shape of the new data frame (5 points)"
      ],
      "metadata": {
        "id": "0fZ8A-NMBrI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, ['built_after_2000','Sold Terms', 'School District', 'Quadrant','Irregular Shape'])"
      ],
      "metadata": {
        "id": "oGY3_M2tChMt"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "P4aPuUipHXuE",
        "outputId": "97297076-f508-49e6-e434-b78b94537e5c"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sold Price  DOM  Garage Capacity  HOA Fee  Total Bedrooms  Total Bathrooms  \\\n",
              "0      176000    5                2        0               3                1   \n",
              "1      225000    6                2        0               4                2   \n",
              "2      274900   14                2        0               3                1   \n",
              "3      175000   16                1        0               4                1   \n",
              "4      179000   29                0        0               4                2   \n",
              "\n",
              "   Total Square Feet  Year Built    Zip  year_sold  ...  \\\n",
              "0               1031        1974  84335       2018  ...   \n",
              "1               2091        1995  84335       2018  ...   \n",
              "2               2016        1980  84335       2018  ...   \n",
              "3               1920        1978  84335       2018  ...   \n",
              "4               1329        1976  84335       2018  ...   \n",
              "\n",
              "   School District_Cache  School District_Logan  Quadrant_Cash  \\\n",
              "0                      1                      0              0   \n",
              "1                      1                      0              0   \n",
              "2                      1                      0              0   \n",
              "3                      1                      0              0   \n",
              "4                      1                      0              1   \n",
              "\n",
              "   Quadrant_Conventional  Quadrant_FHA  Quadrant_Other  \\\n",
              "0                      0             1               0   \n",
              "1                      1             0               0   \n",
              "2                      1             0               0   \n",
              "3                      0             0               0   \n",
              "4                      0             0               0   \n",
              "\n",
              "   Quadrant_USDA Rural Development  Quadrant_VA  Irregular Shape_0  \\\n",
              "0                                0            0                  1   \n",
              "1                                0            0                  1   \n",
              "2                                0            0                  1   \n",
              "3                                1            0                  1   \n",
              "4                                0            0                  1   \n",
              "\n",
              "   Irregular Shape_1  \n",
              "0                  0  \n",
              "1                  0  \n",
              "2                  0  \n",
              "3                  0  \n",
              "4                  0  \n",
              "\n",
              "[5 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1df88581-0cc9-4220-bbca-b97263075d82\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sold Price</th>\n",
              "      <th>DOM</th>\n",
              "      <th>Garage Capacity</th>\n",
              "      <th>HOA Fee</th>\n",
              "      <th>Total Bedrooms</th>\n",
              "      <th>Total Bathrooms</th>\n",
              "      <th>Total Square Feet</th>\n",
              "      <th>Year Built</th>\n",
              "      <th>Zip</th>\n",
              "      <th>year_sold</th>\n",
              "      <th>...</th>\n",
              "      <th>School District_Cache</th>\n",
              "      <th>School District_Logan</th>\n",
              "      <th>Quadrant_Cash</th>\n",
              "      <th>Quadrant_Conventional</th>\n",
              "      <th>Quadrant_FHA</th>\n",
              "      <th>Quadrant_Other</th>\n",
              "      <th>Quadrant_USDA Rural Development</th>\n",
              "      <th>Quadrant_VA</th>\n",
              "      <th>Irregular Shape_0</th>\n",
              "      <th>Irregular Shape_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>176000</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1031</td>\n",
              "      <td>1974</td>\n",
              "      <td>84335</td>\n",
              "      <td>2018</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>225000</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2091</td>\n",
              "      <td>1995</td>\n",
              "      <td>84335</td>\n",
              "      <td>2018</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>274900</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "      <td>1980</td>\n",
              "      <td>84335</td>\n",
              "      <td>2018</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>175000</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1920</td>\n",
              "      <td>1978</td>\n",
              "      <td>84335</td>\n",
              "      <td>2018</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>179000</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1329</td>\n",
              "      <td>1976</td>\n",
              "      <td>84335</td>\n",
              "      <td>2018</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1df88581-0cc9-4220-bbca-b97263075d82')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1df88581-0cc9-4220-bbca-b97263075d82 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1df88581-0cc9-4220-bbca-b97263075d82');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-647d735b-4772-497c-9631-7c918998f36f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-647d735b-4772-497c-9631-7c918998f36f')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-647d735b-4772-497c-9631-7c918998f36f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-h--vJbH1Xo",
        "outputId": "fbabee31-f219-45f3-fce1-e8f3fe00e742"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4110, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the dimensionality of the feature space, what is the minimum number of nodes (units) you should use in the first layer of your DNN? why? (5 points)"
      ],
      "metadata": {
        "id": "m1dzFWT6B33D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 26 feature variables and 1 target variable so there should be a minimum number of 26 nodes in the first layer to keep there from being a bottleneck for the DNN.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3LYuGzUIIGsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Use train_test_split() function from sklearn.model_selection. Split the data into 20% test, 80% train. use random_state=100 (5 points)\n",
        "Use StandardScaler from sklearn.preprocessing and transform the features in the train and test set. (5 points)"
      ],
      "metadata": {
        "id": "WG8c5jkdB8LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "XkLG-uaWCfm6"
      },
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(\"Sold Price\", axis=1, inplace=False).values\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81ZEqDIDjSOE",
        "outputId": "bc21006f-51a9-4198-9794-85f0fe68aed1"
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5,  2,  0, ...,  0,  1,  0],\n",
              "       [ 6,  2,  0, ...,  0,  1,  0],\n",
              "       [14,  2,  0, ...,  0,  1,  0],\n",
              "       ...,\n",
              "       [40,  0,  0, ...,  0,  1,  0],\n",
              "       [49,  0,  0, ...,  0,  1,  0],\n",
              "       [94,  3,  0, ...,  1,  1,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNCB2da-kkRr",
        "outputId": "c833a1a1-f5f6-4335-fd42-1dba775c80f5"
      },
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4110, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Sold Price'].values\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "socrUrO9kqWu",
        "outputId": "1a2d1092-c8af-4949-9ee5-164fd23c17d4"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([176000, 225000, 274900, ..., 298000, 215000, 450000])"
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=100)"
      ],
      "metadata": {
        "id": "GLANOU_4k8EC"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENIk1SHik8jn",
        "outputId": "3ddac830-c4d1-4671-ef05-bc6e33968007"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3288, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFFMeQvcmIon",
        "outputId": "b624797c-9e77-4b00-da1c-4252de0ed1c5"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(822,)"
            ]
          },
          "metadata": {},
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "_loe65z3nDHL"
      },
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "wJrpDlt8nC9L"
      },
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train= scaler.fit_transform(X_train)\n",
        "\n",
        "X_test  = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "ZeYXNxHrnL0e"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbPGTX2AnPhG",
        "outputId": "caa8f163-f18a-4f10-9bd1-95295ebdf517"
      },
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.71474243,  0.17138212,  0.76272137, ..., -0.20126184,\n",
              "        -0.97714671,  0.97714671],\n",
              "       [-0.1261254 ,  0.17138212,  0.33563169, ..., -0.20126184,\n",
              "        -0.97714671,  0.97714671],\n",
              "       [-0.44005448,  0.17138212, -0.51854765, ..., -0.20126184,\n",
              "        -0.97714671,  0.97714671],\n",
              "       ...,\n",
              "       [-0.61663959, -1.63762085, -0.51854765, ..., -0.20126184,\n",
              "         1.02338778, -1.02338778],\n",
              "       [-0.69512186, -0.73311936, -0.51854765, ..., -0.20126184,\n",
              "         1.02338778, -1.02338778],\n",
              "       [ 1.77706966, -1.63762085, -0.51854765, ..., -0.20126184,\n",
              "         1.02338778, -1.02338778]])"
            ]
          },
          "metadata": {},
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using TensorfFow, create two models. One with dropout and one without dropout. In both models, use the following properties: Input layer, 2 Dense layers (180 and 32 nodes respectively) and an output layer. Also use early stopping callback for both models. Answer the following questions:\n",
        "Print out the the model summary (for the one with dropout)? How many parameters are there in each layer. How many total trainable parameters does the model have? (10 points)"
      ],
      "metadata": {
        "id": "Eiz6NP_yB9F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "ec836PgrCC_c"
      },
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No dropout:"
      ],
      "metadata": {
        "id": "LizfayTCrCia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "  inputs   = keras.Input(shape=(X_train.shape[1]), name= \"my_input\")\n",
        "  features = layers.Dense(180, activation='relu',   name='first_layer')(inputs)\n",
        "  features = layers.Dense(32, activation='relu',   name='second_layer')(features)\n",
        "  outputs   = layers.Dense(1,  activation='linear',name='output_layer')(features)\n",
        "  model_functional = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  model_functional.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['mae'])\n",
        "  return model_functional"
      ],
      "metadata": {
        "id": "J27LLCprw1OL"
      },
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With dropout:"
      ],
      "metadata": {
        "id": "Y5kjn0IbrGPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model_dropout():\n",
        "  d_rate = .5\n",
        "  inputs_d   = keras.Input(shape=(X_train.shape[1]), name= \"my_input_d\")\n",
        "  features_d = layers.Dense(180, activation='relu',   name='first_layer_d')(inputs_d)\n",
        "  features_d = layers.Dropout(d_rate)(features_d)\n",
        "  features_d = layers.Dense(32, activation='relu',   name='second_layer_d')(features_d)\n",
        "  features_d = layers.Dropout(d_rate)(features_d)\n",
        "  outputs_d   = layers.Dense(1,  activation='linear',name='output_layer_d')(features_d)\n",
        "  model_functional_d = keras.Model(inputs=inputs_d, outputs=outputs_d)\n",
        "  model_functional_d.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['mae'])\n",
        "  return model_functional_d"
      ],
      "metadata": {
        "id": "_oWCWpPPz9GW"
      },
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_model()\n",
        "model_d = make_model_dropout()\n",
        "make_model_dropout().summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQitsQK-rFz8",
        "outputId": "f7d0fcd8-1a5b-4780-88af-9055cff876b8"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " my_input_d (InputLayer)     [(None, 26)]              0         \n",
            "                                                                 \n",
            " first_layer_d (Dense)       (None, 180)               4860      \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 180)               0         \n",
            "                                                                 \n",
            " second_layer_d (Dense)      (None, 32)                5792      \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " output_layer_d (Dense)      (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10685 (41.74 KB)\n",
            "Trainable params: 10685 (41.74 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 4860 trainable parameters in the first layer, 5792 in the second layer and 33 in the output layer. There are 0 in dropout layers and input layer. The model has a total of 10685 trainable parameters."
      ],
      "metadata": {
        "id": "j2lbk_oT2UuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What activation function should you use for the last layer? (remember, this is a regression model) (5 points)"
      ],
      "metadata": {
        "id": "A-pbbygYCDtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because this is a regression model, we need to use linear as an activation function or have no activation function."
      ],
      "metadata": {
        "id": "3B5oMJFAtEgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What loss function should you use? (5 points)"
      ],
      "metadata": {
        "id": "VP32ML7WCHDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am using the mean squared error loss function because it penalizes larger errors to help minimize errors during training."
      ],
      "metadata": {
        "id": "bnZ1eb3otFoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Training both models! in both models, use compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['mae']) and train them with\n",
        "batch_size=128, epochs=2000. Make sure you set validation_data. This step may take up to 10 minutes for each model. (10 points)"
      ],
      "metadata": {
        "id": "kHSucWxwCKUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "early_stopping   = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "model_checkpoint = ModelCheckpoint(monitor='val_loss', save_best_only=True, filepath=\"model_checkpoint.h5\") #model_checkpoint.keras#model_checkpoint.h5\n",
        "callback_list    = [early_stopping,model_checkpoint]"
      ],
      "metadata": {
        "id": "bgQNHQfCrzvq"
      },
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train, validation_data=(X_test, y_test), epochs=2000, batch_size=128,\n",
        "          callbacks=callback_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nZuIQPOtBW2",
        "outputId": "19f5e785-1f8b-46b2-92e2-52b900df746a"
      },
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "26/26 [==============================] - 1s 16ms/step - loss: 93255245824.0000 - mae: 281662.8438 - val_loss: 94383857664.0000 - val_mae: 283955.5312\n",
            "Epoch 2/2000\n",
            "18/26 [===================>..........] - ETA: 0s - loss: 92396388352.0000 - mae: 281471.5312"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26/26 [==============================] - 0s 7ms/step - loss: 93250248704.0000 - mae: 281655.0000 - val_loss: 94377123840.0000 - val_mae: 283945.4375\n",
            "Epoch 3/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 93242007552.0000 - mae: 281642.6562 - val_loss: 94366408704.0000 - val_mae: 283929.7812\n",
            "Epoch 4/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 93229318144.0000 - mae: 281624.0625 - val_loss: 94350327808.0000 - val_mae: 283906.8125\n",
            "Epoch 5/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 93211844608.0000 - mae: 281598.5000 - val_loss: 94329282560.0000 - val_mae: 283876.8438\n",
            "Epoch 6/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 93188890624.0000 - mae: 281565.1875 - val_loss: 94301691904.0000 - val_mae: 283838.0000\n",
            "Epoch 7/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 93159309312.0000 - mae: 281522.6250 - val_loss: 94267080704.0000 - val_mae: 283789.5000\n",
            "Epoch 8/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 93122355200.0000 - mae: 281470.0312 - val_loss: 94223745024.0000 - val_mae: 283729.2500\n",
            "Epoch 9/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 93077684224.0000 - mae: 281406.5312 - val_loss: 94172758016.0000 - val_mae: 283658.5000\n",
            "Epoch 10/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 93024468992.0000 - mae: 281330.8750 - val_loss: 94111580160.0000 - val_mae: 283574.0000\n",
            "Epoch 11/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 92961849344.0000 - mae: 281242.8125 - val_loss: 94040072192.0000 - val_mae: 283475.5312\n",
            "Epoch 12/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 92890038272.0000 - mae: 281140.8125 - val_loss: 93959331840.0000 - val_mae: 283364.3750\n",
            "Epoch 13/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 92807790592.0000 - mae: 281025.0625 - val_loss: 93865836544.0000 - val_mae: 283236.0312\n",
            "Epoch 14/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 92713140224.0000 - mae: 280892.3750 - val_loss: 93759348736.0000 - val_mae: 283090.1562\n",
            "Epoch 15/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 92606414848.0000 - mae: 280741.3438 - val_loss: 93641129984.0000 - val_mae: 282927.9688\n",
            "Epoch 16/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 92487516160.0000 - mae: 280575.3438 - val_loss: 93507600384.0000 - val_mae: 282745.1562\n",
            "Epoch 17/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 92353699840.0000 - mae: 280387.4375 - val_loss: 93361225728.0000 - val_mae: 282544.5000\n",
            "Epoch 18/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 92205973504.0000 - mae: 280180.7188 - val_loss: 93195067392.0000 - val_mae: 282317.3438\n",
            "Epoch 19/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 92041428992.0000 - mae: 279950.0000 - val_loss: 93013590016.0000 - val_mae: 282069.0625\n",
            "Epoch 20/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 91864113152.0000 - mae: 279700.2188 - val_loss: 92820316160.0000 - val_mae: 281804.0000\n",
            "Epoch 21/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 91669209088.0000 - mae: 279426.5000 - val_loss: 92605906944.0000 - val_mae: 281510.3125\n",
            "Epoch 22/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 91457544192.0000 - mae: 279129.0000 - val_loss: 92371337216.0000 - val_mae: 281188.7188\n",
            "Epoch 23/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 91230707712.0000 - mae: 278808.5312 - val_loss: 92125814784.0000 - val_mae: 280850.8750\n",
            "Epoch 24/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 90982883328.0000 - mae: 278460.5312 - val_loss: 91852840960.0000 - val_mae: 280475.8125\n",
            "Epoch 25/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 90717093888.0000 - mae: 278084.5625 - val_loss: 91561639936.0000 - val_mae: 280074.9062\n",
            "Epoch 26/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 90428899328.0000 - mae: 277680.8125 - val_loss: 91249008640.0000 - val_mae: 279644.1250\n",
            "Epoch 27/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 90126180352.0000 - mae: 277248.5000 - val_loss: 90920124416.0000 - val_mae: 279189.2500\n",
            "Epoch 28/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 89805627392.0000 - mae: 276791.4688 - val_loss: 90574471168.0000 - val_mae: 278709.9688\n",
            "Epoch 29/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 89459712000.0000 - mae: 276302.3125 - val_loss: 90193641472.0000 - val_mae: 278181.7812\n",
            "Epoch 30/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 89089384448.0000 - mae: 275776.7188 - val_loss: 89790668800.0000 - val_mae: 277621.8438\n",
            "Epoch 31/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 88698200064.0000 - mae: 275215.6250 - val_loss: 89369657344.0000 - val_mae: 277034.5625\n",
            "Epoch 32/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 88282193920.0000 - mae: 274621.5000 - val_loss: 88919613440.0000 - val_mae: 276405.5312\n",
            "Epoch 33/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 87846903808.0000 - mae: 273995.0312 - val_loss: 88447369216.0000 - val_mae: 275742.6250\n",
            "Epoch 34/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 87382466560.0000 - mae: 273327.3438 - val_loss: 87942217728.0000 - val_mae: 275032.5625\n",
            "Epoch 35/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 86896476160.0000 - mae: 272624.7500 - val_loss: 87423303680.0000 - val_mae: 274298.9062\n",
            "Epoch 36/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 86394855424.0000 - mae: 271892.4375 - val_loss: 86884794368.0000 - val_mae: 273533.7812\n",
            "Epoch 37/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 85864349696.0000 - mae: 271122.5000 - val_loss: 86305046528.0000 - val_mae: 272708.4688\n",
            "Epoch 38/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 85304057856.0000 - mae: 270296.7812 - val_loss: 85710839808.0000 - val_mae: 271856.9688\n",
            "Epoch 39/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 84716683264.0000 - mae: 269438.4375 - val_loss: 85069922304.0000 - val_mae: 270937.0625\n",
            "Epoch 40/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 84116905984.0000 - mae: 268542.5312 - val_loss: 84434796544.0000 - val_mae: 270016.4375\n",
            "Epoch 41/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 83484123136.0000 - mae: 267606.2812 - val_loss: 83752075264.0000 - val_mae: 269024.5312\n",
            "Epoch 42/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 82822946816.0000 - mae: 266621.6875 - val_loss: 83038871552.0000 - val_mae: 267982.8125\n",
            "Epoch 43/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 82140094464.0000 - mae: 265588.7812 - val_loss: 82305695744.0000 - val_mae: 266904.4375\n",
            "Epoch 44/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 81428144128.0000 - mae: 264516.0938 - val_loss: 81553563648.0000 - val_mae: 265791.0312\n",
            "Epoch 45/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 80697352192.0000 - mae: 263395.2500 - val_loss: 80764239872.0000 - val_mae: 264614.9375\n",
            "Epoch 46/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 79927328768.0000 - mae: 262220.7188 - val_loss: 79950512128.0000 - val_mae: 263394.6250\n",
            "Epoch 47/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 79146713088.0000 - mae: 261014.7812 - val_loss: 79101624320.0000 - val_mae: 262112.6406\n",
            "Epoch 48/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 78323400704.0000 - mae: 259738.6875 - val_loss: 78228455424.0000 - val_mae: 260783.5156\n",
            "Epoch 49/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 77488996352.0000 - mae: 258426.3594 - val_loss: 77333463040.0000 - val_mae: 259409.5000\n",
            "Epoch 50/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 76618588160.0000 - mae: 257050.9375 - val_loss: 76411035648.0000 - val_mae: 257980.2500\n",
            "Epoch 51/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 75734720512.0000 - mae: 255637.6406 - val_loss: 75464007680.0000 - val_mae: 256500.5156\n",
            "Epoch 52/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 74821197824.0000 - mae: 254162.6250 - val_loss: 74489380864.0000 - val_mae: 254962.2969\n",
            "Epoch 53/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 73862356992.0000 - mae: 252616.5781 - val_loss: 73469198336.0000 - val_mae: 253338.0625\n",
            "Epoch 54/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 72911413248.0000 - mae: 251038.7031 - val_loss: 72454594560.0000 - val_mae: 251704.2500\n",
            "Epoch 55/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 71918526464.0000 - mae: 249399.6094 - val_loss: 71402528768.0000 - val_mae: 249992.2969\n",
            "Epoch 56/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 70908059648.0000 - mae: 247702.7188 - val_loss: 70329835520.0000 - val_mae: 248225.9062\n",
            "Epoch 57/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 69868167168.0000 - mae: 245945.0312 - val_loss: 69211627520.0000 - val_mae: 246364.0156\n",
            "Epoch 58/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 68812046336.0000 - mae: 244136.7656 - val_loss: 68103696384.0000 - val_mae: 244494.2500\n",
            "Epoch 59/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 67742167040.0000 - mae: 242264.1406 - val_loss: 66964807680.0000 - val_mae: 242546.6250\n",
            "Epoch 60/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 66644422656.0000 - mae: 240325.7031 - val_loss: 65799217152.0000 - val_mae: 240526.7969\n",
            "Epoch 61/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 65513365504.0000 - mae: 238316.7031 - val_loss: 64602247168.0000 - val_mae: 238425.0469\n",
            "Epoch 62/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 64394616832.0000 - mae: 236265.7344 - val_loss: 63426666496.0000 - val_mae: 236322.5156\n",
            "Epoch 63/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 63242362880.0000 - mae: 234150.2344 - val_loss: 62200483840.0000 - val_mae: 234101.7969\n",
            "Epoch 64/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 62082326528.0000 - mae: 231967.8594 - val_loss: 60980318208.0000 - val_mae: 231850.7500\n",
            "Epoch 65/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 60904091648.0000 - mae: 229714.6719 - val_loss: 59727785984.0000 - val_mae: 229504.8438\n",
            "Epoch 66/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 59704262656.0000 - mae: 227396.0625 - val_loss: 58466766848.0000 - val_mae: 227101.0625\n",
            "Epoch 67/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 58498015232.0000 - mae: 225015.1250 - val_loss: 57198862336.0000 - val_mae: 224635.7969\n",
            "Epoch 68/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 57286316032.0000 - mae: 222590.6406 - val_loss: 55910322176.0000 - val_mae: 222083.9375\n",
            "Epoch 69/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 56065908736.0000 - mae: 220081.8906 - val_loss: 54622769152.0000 - val_mae: 219482.6875\n",
            "Epoch 70/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 54830661632.0000 - mae: 217518.4219 - val_loss: 53338550272.0000 - val_mae: 216831.5781\n",
            "Epoch 71/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 53597851648.0000 - mae: 214885.1719 - val_loss: 52039561216.0000 - val_mae: 214086.4844\n",
            "Epoch 72/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 52347101184.0000 - mae: 212171.7188 - val_loss: 50728697856.0000 - val_mae: 211257.2031\n",
            "Epoch 73/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 51118821376.0000 - mae: 209416.7188 - val_loss: 49426329600.0000 - val_mae: 208368.0938\n",
            "Epoch 74/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 49885925376.0000 - mae: 206570.4844 - val_loss: 48138301440.0000 - val_mae: 205433.8906\n",
            "Epoch 75/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 48650809344.0000 - mae: 203680.5781 - val_loss: 46856404992.0000 - val_mae: 202438.1875\n",
            "Epoch 76/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 47419551744.0000 - mae: 200715.4062 - val_loss: 45555814400.0000 - val_mae: 199311.1094\n",
            "Epoch 77/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 46191996928.0000 - mae: 197647.8594 - val_loss: 44276862976.0000 - val_mae: 196144.7031\n",
            "Epoch 78/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 44977479680.0000 - mae: 194555.2188 - val_loss: 43013398528.0000 - val_mae: 192949.0938\n",
            "Epoch 79/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 43763580928.0000 - mae: 191384.3125 - val_loss: 41746317312.0000 - val_mae: 189696.3906\n",
            "Epoch 80/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 42581712896.0000 - mae: 188150.6250 - val_loss: 40517312512.0000 - val_mae: 186431.0312\n",
            "Epoch 81/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 41400856576.0000 - mae: 184863.1406 - val_loss: 39292350464.0000 - val_mae: 183060.7344\n",
            "Epoch 82/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 40227188736.0000 - mae: 181549.7812 - val_loss: 38074085376.0000 - val_mae: 179576.4219\n",
            "Epoch 83/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 39106088960.0000 - mae: 178208.2500 - val_loss: 36930920448.0000 - val_mae: 176243.4688\n",
            "Epoch 84/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 38021357568.0000 - mae: 174938.6719 - val_loss: 35800772608.0000 - val_mae: 172893.5156\n",
            "Epoch 85/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 36950564864.0000 - mae: 171649.0312 - val_loss: 34694365184.0000 - val_mae: 169524.9688\n",
            "Epoch 86/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 35909996544.0000 - mae: 168386.3906 - val_loss: 33615257600.0000 - val_mae: 166230.1719\n",
            "Epoch 87/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 34888282112.0000 - mae: 165189.0469 - val_loss: 32583174144.0000 - val_mae: 163044.6562\n",
            "Epoch 88/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 33907075072.0000 - mae: 162069.9219 - val_loss: 31575943168.0000 - val_mae: 159918.4844\n",
            "Epoch 89/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 32964528128.0000 - mae: 159039.9219 - val_loss: 30626437120.0000 - val_mae: 156944.6875\n",
            "Epoch 90/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 32064376832.0000 - mae: 156184.3438 - val_loss: 29699164160.0000 - val_mae: 153980.9375\n",
            "Epoch 91/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 31223128064.0000 - mae: 153445.7969 - val_loss: 28857051136.0000 - val_mae: 151367.1406\n",
            "Epoch 92/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 30410651648.0000 - mae: 150883.3750 - val_loss: 28029679616.0000 - val_mae: 148824.4531\n",
            "Epoch 93/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 29646338048.0000 - mae: 148540.2969 - val_loss: 27276107776.0000 - val_mae: 146484.6250\n",
            "Epoch 94/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 28938102784.0000 - mae: 146434.2969 - val_loss: 26572015616.0000 - val_mae: 144286.7812\n",
            "Epoch 95/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 28269049856.0000 - mae: 144425.7344 - val_loss: 25888866304.0000 - val_mae: 142221.5938\n",
            "Epoch 96/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 27626315776.0000 - mae: 142552.6719 - val_loss: 25266040832.0000 - val_mae: 140314.9219\n",
            "Epoch 97/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 27046225920.0000 - mae: 140887.0781 - val_loss: 24701931520.0000 - val_mae: 138552.3750\n",
            "Epoch 98/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 26522388480.0000 - mae: 139335.6719 - val_loss: 24190474240.0000 - val_mae: 136975.3125\n",
            "Epoch 99/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 26041677824.0000 - mae: 137914.5938 - val_loss: 23716909056.0000 - val_mae: 135465.7344\n",
            "Epoch 100/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 25593985024.0000 - mae: 136613.7812 - val_loss: 23301677056.0000 - val_mae: 134134.6250\n",
            "Epoch 101/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 25181788160.0000 - mae: 135385.2812 - val_loss: 22895161344.0000 - val_mae: 132799.2031\n",
            "Epoch 102/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 24785688576.0000 - mae: 134213.2812 - val_loss: 22516695040.0000 - val_mae: 131546.3594\n",
            "Epoch 103/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 24411766784.0000 - mae: 133084.2188 - val_loss: 22150682624.0000 - val_mae: 130331.0156\n",
            "Epoch 104/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 24060301312.0000 - mae: 132083.5781 - val_loss: 21814421504.0000 - val_mae: 129204.6406\n",
            "Epoch 105/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 23711074304.0000 - mae: 131011.0547 - val_loss: 21475739648.0000 - val_mae: 128037.1797\n",
            "Epoch 106/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 23367274496.0000 - mae: 129951.9609 - val_loss: 21143853056.0000 - val_mae: 126877.1328\n",
            "Epoch 107/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 23033309184.0000 - mae: 128919.7266 - val_loss: 20821805056.0000 - val_mae: 125741.1406\n",
            "Epoch 108/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 22702540800.0000 - mae: 127860.6641 - val_loss: 20501917696.0000 - val_mae: 124617.3828\n",
            "Epoch 109/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 22368940032.0000 - mae: 126793.4375 - val_loss: 20174067712.0000 - val_mae: 123469.2734\n",
            "Epoch 110/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 22030989312.0000 - mae: 125665.7109 - val_loss: 19844665344.0000 - val_mae: 122306.5781\n",
            "Epoch 111/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 21685811200.0000 - mae: 124506.2266 - val_loss: 19510505472.0000 - val_mae: 121107.1719\n",
            "Epoch 112/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 21343778816.0000 - mae: 123373.0938 - val_loss: 19179718656.0000 - val_mae: 119930.3828\n",
            "Epoch 113/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 21000067072.0000 - mae: 122185.2734 - val_loss: 18847741952.0000 - val_mae: 118726.7812\n",
            "Epoch 114/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 20649158656.0000 - mae: 120967.5938 - val_loss: 18504609792.0000 - val_mae: 117480.9531\n",
            "Epoch 115/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 20303147008.0000 - mae: 119755.3516 - val_loss: 18175338496.0000 - val_mae: 116281.2969\n",
            "Epoch 116/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 19957657600.0000 - mae: 118527.4297 - val_loss: 17842409472.0000 - val_mae: 115055.1797\n",
            "Epoch 117/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 19613904896.0000 - mae: 117280.6406 - val_loss: 17513926656.0000 - val_mae: 113834.4297\n",
            "Epoch 118/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 19270199296.0000 - mae: 116032.7188 - val_loss: 17178136576.0000 - val_mae: 112576.0938\n",
            "Epoch 119/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 18919931904.0000 - mae: 114733.6250 - val_loss: 16842275840.0000 - val_mae: 111321.0781\n",
            "Epoch 120/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 18571819008.0000 - mae: 113450.3828 - val_loss: 16506786816.0000 - val_mae: 110059.4922\n",
            "Epoch 121/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 18224009216.0000 - mae: 112145.3828 - val_loss: 16170391552.0000 - val_mae: 108778.3438\n",
            "Epoch 122/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 17872470016.0000 - mae: 110789.3906 - val_loss: 15834900480.0000 - val_mae: 107483.8438\n",
            "Epoch 123/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 17531121664.0000 - mae: 109475.4766 - val_loss: 15507571712.0000 - val_mae: 106216.5234\n",
            "Epoch 124/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 17186662400.0000 - mae: 108130.1094 - val_loss: 15182398464.0000 - val_mae: 104939.5391\n",
            "Epoch 125/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 16850924544.0000 - mae: 106808.2500 - val_loss: 14863257600.0000 - val_mae: 103670.9688\n",
            "Epoch 126/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 16514565120.0000 - mae: 105477.3906 - val_loss: 14537587712.0000 - val_mae: 102362.7188\n",
            "Epoch 127/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 16172670976.0000 - mae: 104112.1172 - val_loss: 14207670272.0000 - val_mae: 101024.6094\n",
            "Epoch 128/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 15834754048.0000 - mae: 102770.0078 - val_loss: 13891686400.0000 - val_mae: 99724.2812\n",
            "Epoch 129/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 15499967488.0000 - mae: 101400.6016 - val_loss: 13571671040.0000 - val_mae: 98376.5625\n",
            "Epoch 130/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 15168677888.0000 - mae: 100054.3125 - val_loss: 13256025088.0000 - val_mae: 97034.6094\n",
            "Epoch 131/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 14833809408.0000 - mae: 98692.3125 - val_loss: 12934599680.0000 - val_mae: 95653.7969\n",
            "Epoch 132/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 14496288768.0000 - mae: 97291.0391 - val_loss: 12614419456.0000 - val_mae: 94251.2344\n",
            "Epoch 133/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 14163424256.0000 - mae: 95876.1094 - val_loss: 12299296768.0000 - val_mae: 92851.9531\n",
            "Epoch 134/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 13841602560.0000 - mae: 94527.1641 - val_loss: 11997505536.0000 - val_mae: 91507.0859\n",
            "Epoch 135/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 13523750912.0000 - mae: 93201.3516 - val_loss: 11700239360.0000 - val_mae: 90172.0469\n",
            "Epoch 136/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 13213764608.0000 - mae: 91861.2031 - val_loss: 11406784512.0000 - val_mae: 88847.3281\n",
            "Epoch 137/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 12901753856.0000 - mae: 90521.1875 - val_loss: 11111293952.0000 - val_mae: 87510.6094\n",
            "Epoch 138/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 12599135232.0000 - mae: 89178.2500 - val_loss: 10829772800.0000 - val_mae: 86223.7969\n",
            "Epoch 139/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 12300732416.0000 - mae: 87841.5078 - val_loss: 10550300672.0000 - val_mae: 84940.6250\n",
            "Epoch 140/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 12006111232.0000 - mae: 86510.6641 - val_loss: 10273561600.0000 - val_mae: 83674.4688\n",
            "Epoch 141/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 11718913024.0000 - mae: 85216.7500 - val_loss: 10009336832.0000 - val_mae: 82479.9688\n",
            "Epoch 142/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 11444704256.0000 - mae: 83970.8906 - val_loss: 9755292672.0000 - val_mae: 81335.3203\n",
            "Epoch 143/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 11171398656.0000 - mae: 82754.7578 - val_loss: 9494176768.0000 - val_mae: 80121.4922\n",
            "Epoch 144/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 10905569280.0000 - mae: 81539.8906 - val_loss: 9252578304.0000 - val_mae: 78988.3516\n",
            "Epoch 145/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 10647124992.0000 - mae: 80335.5000 - val_loss: 9010710528.0000 - val_mae: 77850.3438\n",
            "Epoch 146/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 10399031296.0000 - mae: 79135.7969 - val_loss: 8780652544.0000 - val_mae: 76749.3516\n",
            "Epoch 147/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 10159593472.0000 - mae: 77978.1172 - val_loss: 8559866368.0000 - val_mae: 75670.1406\n",
            "Epoch 148/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 9928455168.0000 - mae: 76885.5547 - val_loss: 8347430400.0000 - val_mae: 74631.1484\n",
            "Epoch 149/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9705162752.0000 - mae: 75779.7188 - val_loss: 8136949248.0000 - val_mae: 73580.3516\n",
            "Epoch 150/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 9485648896.0000 - mae: 74674.1328 - val_loss: 7936629760.0000 - val_mae: 72564.9062\n",
            "Epoch 151/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9278665728.0000 - mae: 73653.5625 - val_loss: 7742327808.0000 - val_mae: 71589.7578\n",
            "Epoch 152/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9075835904.0000 - mae: 72635.9453 - val_loss: 7553495552.0000 - val_mae: 70619.2734\n",
            "Epoch 153/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8882755584.0000 - mae: 71640.8984 - val_loss: 7377316352.0000 - val_mae: 69690.0938\n",
            "Epoch 154/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8703825920.0000 - mae: 70735.3359 - val_loss: 7211947520.0000 - val_mae: 68802.6250\n",
            "Epoch 155/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8527320576.0000 - mae: 69820.6406 - val_loss: 7046084608.0000 - val_mae: 67901.6328\n",
            "Epoch 156/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8356761088.0000 - mae: 68915.3125 - val_loss: 6887834624.0000 - val_mae: 67014.8203\n",
            "Epoch 157/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8195981824.0000 - mae: 68047.7109 - val_loss: 6739981312.0000 - val_mae: 66183.0391\n",
            "Epoch 158/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8040950784.0000 - mae: 67191.2578 - val_loss: 6595846144.0000 - val_mae: 65351.8789\n",
            "Epoch 159/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 7890991104.0000 - mae: 66351.5156 - val_loss: 6458374144.0000 - val_mae: 64550.5664\n",
            "Epoch 160/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 7746089984.0000 - mae: 65550.6250 - val_loss: 6320937984.0000 - val_mae: 63735.1289\n",
            "Epoch 161/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 7605761024.0000 - mae: 64731.2031 - val_loss: 6188545536.0000 - val_mae: 62922.1172\n",
            "Epoch 162/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 7467665408.0000 - mae: 63934.6484 - val_loss: 6059236352.0000 - val_mae: 62117.4219\n",
            "Epoch 163/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 7337408512.0000 - mae: 63144.9648 - val_loss: 5936294912.0000 - val_mae: 61346.5938\n",
            "Epoch 164/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 7208902144.0000 - mae: 62377.0430 - val_loss: 5813795328.0000 - val_mae: 60571.1523\n",
            "Epoch 165/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 7084698624.0000 - mae: 61651.2852 - val_loss: 5694876160.0000 - val_mae: 59815.4453\n",
            "Epoch 166/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 6961217536.0000 - mae: 60851.1641 - val_loss: 5577314304.0000 - val_mae: 59056.6680\n",
            "Epoch 167/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 6840992256.0000 - mae: 60133.7617 - val_loss: 5462297600.0000 - val_mae: 58288.3398\n",
            "Epoch 168/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 6725067776.0000 - mae: 59409.0430 - val_loss: 5351968256.0000 - val_mae: 57544.5898\n",
            "Epoch 169/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 6611500544.0000 - mae: 58681.8164 - val_loss: 5242782208.0000 - val_mae: 56805.4883\n",
            "Epoch 170/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 6499912192.0000 - mae: 57956.2227 - val_loss: 5133664256.0000 - val_mae: 56052.9453\n",
            "Epoch 171/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 6391058432.0000 - mae: 57212.1992 - val_loss: 5029385216.0000 - val_mae: 55325.3008\n",
            "Epoch 172/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 6281741312.0000 - mae: 56492.1797 - val_loss: 4925105152.0000 - val_mae: 54611.0156\n",
            "Epoch 173/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 6176278016.0000 - mae: 55782.1836 - val_loss: 4822766080.0000 - val_mae: 53895.4844\n",
            "Epoch 174/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 6076324864.0000 - mae: 55145.1953 - val_loss: 4729247232.0000 - val_mae: 53223.6289\n",
            "Epoch 175/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 5978427904.0000 - mae: 54458.8516 - val_loss: 4633265152.0000 - val_mae: 52558.2383\n",
            "Epoch 176/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 5882892800.0000 - mae: 53809.9531 - val_loss: 4540919296.0000 - val_mae: 51908.4102\n",
            "Epoch 177/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 5788098048.0000 - mae: 53137.2930 - val_loss: 4448530432.0000 - val_mae: 51254.0859\n",
            "Epoch 178/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 5696889856.0000 - mae: 52499.8359 - val_loss: 4363241984.0000 - val_mae: 50645.2539\n",
            "Epoch 179/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 5609388544.0000 - mae: 51888.6914 - val_loss: 4277565952.0000 - val_mae: 50022.9102\n",
            "Epoch 180/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 5523717632.0000 - mae: 51294.8867 - val_loss: 4195873024.0000 - val_mae: 49421.5625\n",
            "Epoch 181/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 5438205952.0000 - mae: 50694.6133 - val_loss: 4113274624.0000 - val_mae: 48810.0781\n",
            "Epoch 182/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 5354474496.0000 - mae: 50060.7969 - val_loss: 4033231872.0000 - val_mae: 48223.6875\n",
            "Epoch 183/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 5274912768.0000 - mae: 49525.9062 - val_loss: 3959263488.0000 - val_mae: 47664.7305\n",
            "Epoch 184/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 5200465920.0000 - mae: 48984.3906 - val_loss: 3888587776.0000 - val_mae: 47125.9922\n",
            "Epoch 185/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 5126021120.0000 - mae: 48454.6523 - val_loss: 3816746240.0000 - val_mae: 46582.3711\n",
            "Epoch 186/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 5054387712.0000 - mae: 47879.7500 - val_loss: 3748517888.0000 - val_mae: 46085.5117\n",
            "Epoch 187/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 4987244544.0000 - mae: 47453.7656 - val_loss: 3684389632.0000 - val_mae: 45596.3008\n",
            "Epoch 188/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 4919334912.0000 - mae: 46899.3867 - val_loss: 3618477568.0000 - val_mae: 45118.5938\n",
            "Epoch 189/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 4852296704.0000 - mae: 46423.9023 - val_loss: 3555877120.0000 - val_mae: 44637.7500\n",
            "Epoch 190/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 4787598848.0000 - mae: 45916.6211 - val_loss: 3493782528.0000 - val_mae: 44162.1367\n",
            "Epoch 191/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 4723239936.0000 - mae: 45468.0078 - val_loss: 3435435776.0000 - val_mae: 43710.8555\n",
            "Epoch 192/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 4664059392.0000 - mae: 44989.3008 - val_loss: 3379610880.0000 - val_mae: 43258.0000\n",
            "Epoch 193/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 4604914176.0000 - mae: 44530.7695 - val_loss: 3323454208.0000 - val_mae: 42811.6641\n",
            "Epoch 194/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 4547497984.0000 - mae: 44060.6680 - val_loss: 3271095296.0000 - val_mae: 42402.2109\n",
            "Epoch 195/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 4494079488.0000 - mae: 43640.7734 - val_loss: 3221039104.0000 - val_mae: 41983.6562\n",
            "Epoch 196/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 4442255360.0000 - mae: 43243.2500 - val_loss: 3173312000.0000 - val_mae: 41581.4102\n",
            "Epoch 197/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 4393261568.0000 - mae: 42817.6953 - val_loss: 3126987520.0000 - val_mae: 41183.1953\n",
            "Epoch 198/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 4344351232.0000 - mae: 42400.9922 - val_loss: 3083333376.0000 - val_mae: 40799.8789\n",
            "Epoch 199/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 4297944576.0000 - mae: 42002.0234 - val_loss: 3040651008.0000 - val_mae: 40439.0430\n",
            "Epoch 200/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 4254392576.0000 - mae: 41615.7305 - val_loss: 3000940544.0000 - val_mae: 40098.4883\n",
            "Epoch 201/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 4211105792.0000 - mae: 41248.2930 - val_loss: 2961062912.0000 - val_mae: 39744.0742\n",
            "Epoch 202/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 4168450304.0000 - mae: 40922.0391 - val_loss: 2923491328.0000 - val_mae: 39390.3828\n",
            "Epoch 203/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 4127510016.0000 - mae: 40555.1641 - val_loss: 2886676480.0000 - val_mae: 39049.2930\n",
            "Epoch 204/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 4089153536.0000 - mae: 40187.1562 - val_loss: 2851555840.0000 - val_mae: 38742.6406\n",
            "Epoch 205/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 4051398400.0000 - mae: 39844.0234 - val_loss: 2818337280.0000 - val_mae: 38437.2031\n",
            "Epoch 206/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 4013903104.0000 - mae: 39577.0938 - val_loss: 2784886528.0000 - val_mae: 38083.8398\n",
            "Epoch 207/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3980150016.0000 - mae: 39220.3164 - val_loss: 2754486272.0000 - val_mae: 37780.6250\n",
            "Epoch 208/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3947708672.0000 - mae: 38861.2695 - val_loss: 2726530304.0000 - val_mae: 37528.0547\n",
            "Epoch 209/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3915613440.0000 - mae: 38634.1133 - val_loss: 2697769728.0000 - val_mae: 37237.6211\n",
            "Epoch 210/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3884770048.0000 - mae: 38323.7344 - val_loss: 2671657472.0000 - val_mae: 36983.9648\n",
            "Epoch 211/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3854637056.0000 - mae: 38016.1992 - val_loss: 2646054400.0000 - val_mae: 36792.5469\n",
            "Epoch 212/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3824432896.0000 - mae: 37862.1914 - val_loss: 2620579072.0000 - val_mae: 36485.6406\n",
            "Epoch 213/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3797806848.0000 - mae: 37516.4414 - val_loss: 2595813632.0000 - val_mae: 36247.9844\n",
            "Epoch 214/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3771138304.0000 - mae: 37297.1133 - val_loss: 2573191680.0000 - val_mae: 36041.9453\n",
            "Epoch 215/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3745709056.0000 - mae: 37015.7852 - val_loss: 2550853888.0000 - val_mae: 35822.5781\n",
            "Epoch 216/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3721142272.0000 - mae: 36801.8711 - val_loss: 2530827008.0000 - val_mae: 35644.4727\n",
            "Epoch 217/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3697856256.0000 - mae: 36616.8555 - val_loss: 2511809024.0000 - val_mae: 35436.1602\n",
            "Epoch 218/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3675295232.0000 - mae: 36392.8672 - val_loss: 2492599040.0000 - val_mae: 35265.6992\n",
            "Epoch 219/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3654398976.0000 - mae: 36216.5195 - val_loss: 2474622976.0000 - val_mae: 35119.4219\n",
            "Epoch 220/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3632670464.0000 - mae: 35969.8867 - val_loss: 2455738624.0000 - val_mae: 34936.1758\n",
            "Epoch 221/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3611141632.0000 - mae: 35771.2812 - val_loss: 2440765440.0000 - val_mae: 34835.7773\n",
            "Epoch 222/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3594032896.0000 - mae: 35639.1250 - val_loss: 2426109184.0000 - val_mae: 34686.4297\n",
            "Epoch 223/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3577267456.0000 - mae: 35409.3125 - val_loss: 2409558528.0000 - val_mae: 34514.2539\n",
            "Epoch 224/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3556035328.0000 - mae: 35298.5195 - val_loss: 2395324928.0000 - val_mae: 34378.6484\n",
            "Epoch 225/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3540159744.0000 - mae: 35141.2422 - val_loss: 2381307392.0000 - val_mae: 34248.2344\n",
            "Epoch 226/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3522405376.0000 - mae: 35020.2773 - val_loss: 2367505920.0000 - val_mae: 34078.9727\n",
            "Epoch 227/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3507774720.0000 - mae: 34828.3672 - val_loss: 2354462720.0000 - val_mae: 33935.2227\n",
            "Epoch 228/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3491753728.0000 - mae: 34601.1641 - val_loss: 2341949952.0000 - val_mae: 33870.0859\n",
            "Epoch 229/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3475346432.0000 - mae: 34576.6875 - val_loss: 2328562688.0000 - val_mae: 33712.9844\n",
            "Epoch 230/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3460308736.0000 - mae: 34424.3516 - val_loss: 2315592704.0000 - val_mae: 33562.8086\n",
            "Epoch 231/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3446765056.0000 - mae: 34220.3633 - val_loss: 2304387072.0000 - val_mae: 33455.9805\n",
            "Epoch 232/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3432703488.0000 - mae: 34077.8477 - val_loss: 2294102784.0000 - val_mae: 33364.5820\n",
            "Epoch 233/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3419171584.0000 - mae: 33973.6641 - val_loss: 2285013760.0000 - val_mae: 33312.0195\n",
            "Epoch 234/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3407283968.0000 - mae: 33896.8047 - val_loss: 2274961920.0000 - val_mae: 33203.8789\n",
            "Epoch 235/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3394149632.0000 - mae: 33777.5469 - val_loss: 2265324800.0000 - val_mae: 33120.4219\n",
            "Epoch 236/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3380653056.0000 - mae: 33726.0703 - val_loss: 2255124480.0000 - val_mae: 32962.5156\n",
            "Epoch 237/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3372057088.0000 - mae: 33429.5273 - val_loss: 2244281856.0000 - val_mae: 32879.5078\n",
            "Epoch 238/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3359160064.0000 - mae: 33415.6406 - val_loss: 2236374784.0000 - val_mae: 32810.2188\n",
            "Epoch 239/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3345907456.0000 - mae: 33397.4492 - val_loss: 2226875136.0000 - val_mae: 32656.4570\n",
            "Epoch 240/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3338423808.0000 - mae: 33165.5391 - val_loss: 2218738688.0000 - val_mae: 32597.5078\n",
            "Epoch 241/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3326965760.0000 - mae: 33112.7383 - val_loss: 2211623680.0000 - val_mae: 32550.4746\n",
            "Epoch 242/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3315661056.0000 - mae: 33038.4297 - val_loss: 2204758016.0000 - val_mae: 32493.1719\n",
            "Epoch 243/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3305194752.0000 - mae: 32979.9414 - val_loss: 2197073152.0000 - val_mae: 32398.6211\n",
            "Epoch 244/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3296730880.0000 - mae: 32878.7266 - val_loss: 2189432576.0000 - val_mae: 32323.8203\n",
            "Epoch 245/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3285106688.0000 - mae: 32759.7793 - val_loss: 2182527488.0000 - val_mae: 32236.5430\n",
            "Epoch 246/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3277572352.0000 - mae: 32626.1367 - val_loss: 2177009408.0000 - val_mae: 32209.4590\n",
            "Epoch 247/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3266516992.0000 - mae: 32672.5332 - val_loss: 2169247488.0000 - val_mae: 32087.7520\n",
            "Epoch 248/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 3259217920.0000 - mae: 32478.7793 - val_loss: 2163538176.0000 - val_mae: 32049.0703\n",
            "Epoch 249/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 3249251072.0000 - mae: 32453.8027 - val_loss: 2157822976.0000 - val_mae: 31986.0820\n",
            "Epoch 250/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3240457728.0000 - mae: 32366.9297 - val_loss: 2151825408.0000 - val_mae: 31943.4551\n",
            "Epoch 251/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 3231440896.0000 - mae: 32278.8184 - val_loss: 2145071616.0000 - val_mae: 31866.4668\n",
            "Epoch 252/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 3224964096.0000 - mae: 32199.5781 - val_loss: 2139626368.0000 - val_mae: 31811.2363\n",
            "Epoch 253/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 3216124928.0000 - mae: 32164.2188 - val_loss: 2133505152.0000 - val_mae: 31719.2852\n",
            "Epoch 254/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 3209271808.0000 - mae: 32049.3652 - val_loss: 2127715072.0000 - val_mae: 31671.1914\n",
            "Epoch 255/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 3200982272.0000 - mae: 31953.7910 - val_loss: 2122763648.0000 - val_mae: 31662.3242\n",
            "Epoch 256/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3192811520.0000 - mae: 31919.1055 - val_loss: 2117597824.0000 - val_mae: 31620.8379\n",
            "Epoch 257/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 3185407488.0000 - mae: 31832.0781 - val_loss: 2112796928.0000 - val_mae: 31617.9316\n",
            "Epoch 258/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3178411520.0000 - mae: 31808.1562 - val_loss: 2109130112.0000 - val_mae: 31589.5137\n",
            "Epoch 259/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 3171128320.0000 - mae: 31799.2168 - val_loss: 2102089344.0000 - val_mae: 31483.3652\n",
            "Epoch 260/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3164335872.0000 - mae: 31688.1914 - val_loss: 2097625088.0000 - val_mae: 31428.5820\n",
            "Epoch 261/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3157514496.0000 - mae: 31668.5508 - val_loss: 2090984064.0000 - val_mae: 31324.4570\n",
            "Epoch 262/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3150973696.0000 - mae: 31573.7461 - val_loss: 2086982016.0000 - val_mae: 31274.6816\n",
            "Epoch 263/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3144702720.0000 - mae: 31443.9434 - val_loss: 2082728320.0000 - val_mae: 31267.3438\n",
            "Epoch 264/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3138865664.0000 - mae: 31430.0000 - val_loss: 2078648576.0000 - val_mae: 31225.6504\n",
            "Epoch 265/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3132040704.0000 - mae: 31427.2949 - val_loss: 2073623936.0000 - val_mae: 31143.9961\n",
            "Epoch 266/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3129753856.0000 - mae: 31222.2363 - val_loss: 2069786752.0000 - val_mae: 31104.6074\n",
            "Epoch 267/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3120999680.0000 - mae: 31293.9023 - val_loss: 2066245504.0000 - val_mae: 31075.4121\n",
            "Epoch 268/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 3116737280.0000 - mae: 31203.8184 - val_loss: 2062411392.0000 - val_mae: 31027.0664\n",
            "Epoch 269/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3110073344.0000 - mae: 31147.3105 - val_loss: 2059644032.0000 - val_mae: 31011.0625\n",
            "Epoch 270/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 3104395776.0000 - mae: 31102.7402 - val_loss: 2055678592.0000 - val_mae: 30994.9492\n",
            "Epoch 271/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3099588864.0000 - mae: 31114.8145 - val_loss: 2052752896.0000 - val_mae: 30966.5469\n",
            "Epoch 272/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3092976128.0000 - mae: 31076.0195 - val_loss: 2047745152.0000 - val_mae: 30897.2305\n",
            "Epoch 273/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3087905536.0000 - mae: 31000.0488 - val_loss: 2044355840.0000 - val_mae: 30842.2266\n",
            "Epoch 274/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3082696704.0000 - mae: 30921.7832 - val_loss: 2041991040.0000 - val_mae: 30827.1270\n",
            "Epoch 275/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3077709312.0000 - mae: 30925.5547 - val_loss: 2038910208.0000 - val_mae: 30794.9688\n",
            "Epoch 276/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3073789184.0000 - mae: 30866.4434 - val_loss: 2035722880.0000 - val_mae: 30779.0000\n",
            "Epoch 277/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3068199168.0000 - mae: 30900.6367 - val_loss: 2031907328.0000 - val_mae: 30690.0703\n",
            "Epoch 278/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3063340032.0000 - mae: 30746.9375 - val_loss: 2029421568.0000 - val_mae: 30684.3340\n",
            "Epoch 279/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3059171072.0000 - mae: 30778.1680 - val_loss: 2026547584.0000 - val_mae: 30652.2344\n",
            "Epoch 280/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3054095616.0000 - mae: 30717.5625 - val_loss: 2024520576.0000 - val_mae: 30625.5703\n",
            "Epoch 281/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3050541056.0000 - mae: 30670.0332 - val_loss: 2021483648.0000 - val_mae: 30617.7988\n",
            "Epoch 282/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 3046251008.0000 - mae: 30615.3770 - val_loss: 2018381056.0000 - val_mae: 30567.7793\n",
            "Epoch 283/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3041523968.0000 - mae: 30613.7266 - val_loss: 2016477056.0000 - val_mae: 30542.5957\n",
            "Epoch 284/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 3037162752.0000 - mae: 30582.9316 - val_loss: 2014591360.0000 - val_mae: 30550.0762\n",
            "Epoch 285/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3032180992.0000 - mae: 30517.9473 - val_loss: 2013346176.0000 - val_mae: 30539.6152\n",
            "Epoch 286/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 3028125440.0000 - mae: 30437.9512 - val_loss: 2010876032.0000 - val_mae: 30525.7402\n",
            "Epoch 287/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 3023533056.0000 - mae: 30513.3652 - val_loss: 2006874624.0000 - val_mae: 30449.4590\n",
            "Epoch 288/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3020006912.0000 - mae: 30416.1348 - val_loss: 2004069376.0000 - val_mae: 30416.6523\n",
            "Epoch 289/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3016717824.0000 - mae: 30358.6348 - val_loss: 2001541504.0000 - val_mae: 30390.9570\n",
            "Epoch 290/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3012154112.0000 - mae: 30312.6445 - val_loss: 1999972608.0000 - val_mae: 30384.9180\n",
            "Epoch 291/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3009509376.0000 - mae: 30366.6113 - val_loss: 1997225088.0000 - val_mae: 30321.3574\n",
            "Epoch 292/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3004694784.0000 - mae: 30281.5156 - val_loss: 1995370880.0000 - val_mae: 30316.9141\n",
            "Epoch 293/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3000550912.0000 - mae: 30215.9121 - val_loss: 1993698048.0000 - val_mae: 30300.7754\n",
            "Epoch 294/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2997315072.0000 - mae: 30237.0391 - val_loss: 1991646080.0000 - val_mae: 30257.9922\n",
            "Epoch 295/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2994627840.0000 - mae: 30125.8418 - val_loss: 1989347712.0000 - val_mae: 30247.6465\n",
            "Epoch 296/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2989851904.0000 - mae: 30145.2461 - val_loss: 1987327488.0000 - val_mae: 30223.1055\n",
            "Epoch 297/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2985901056.0000 - mae: 30113.6016 - val_loss: 1985584640.0000 - val_mae: 30201.1621\n",
            "Epoch 298/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2982441984.0000 - mae: 30061.9375 - val_loss: 1982982272.0000 - val_mae: 30195.2285\n",
            "Epoch 299/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2980635392.0000 - mae: 30002.6113 - val_loss: 1981183104.0000 - val_mae: 30181.6836\n",
            "Epoch 300/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2976406272.0000 - mae: 30033.9043 - val_loss: 1979114624.0000 - val_mae: 30163.5371\n",
            "Epoch 301/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2973500928.0000 - mae: 29987.0801 - val_loss: 1978068992.0000 - val_mae: 30158.3965\n",
            "Epoch 302/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2969212160.0000 - mae: 30042.5117 - val_loss: 1974830208.0000 - val_mae: 30075.3008\n",
            "Epoch 303/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2966982912.0000 - mae: 30006.1680 - val_loss: 1971710848.0000 - val_mae: 30011.6230\n",
            "Epoch 304/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2964035072.0000 - mae: 29890.2695 - val_loss: 1970369664.0000 - val_mae: 30020.3730\n",
            "Epoch 305/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2961695232.0000 - mae: 29891.5605 - val_loss: 1968022016.0000 - val_mae: 29991.7266\n",
            "Epoch 306/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2957617920.0000 - mae: 29853.0664 - val_loss: 1966911360.0000 - val_mae: 29998.2441\n",
            "Epoch 307/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2954465280.0000 - mae: 29836.7227 - val_loss: 1966058368.0000 - val_mae: 29979.0820\n",
            "Epoch 308/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2951389696.0000 - mae: 29880.2246 - val_loss: 1964833408.0000 - val_mae: 29962.7012\n",
            "Epoch 309/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2948680192.0000 - mae: 29797.1797 - val_loss: 1961087488.0000 - val_mae: 29894.2871\n",
            "Epoch 310/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2946095360.0000 - mae: 29756.8477 - val_loss: 1959278592.0000 - val_mae: 29879.1348\n",
            "Epoch 311/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2942531328.0000 - mae: 29750.0781 - val_loss: 1957382016.0000 - val_mae: 29854.7910\n",
            "Epoch 312/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2940810496.0000 - mae: 29711.4980 - val_loss: 1956130944.0000 - val_mae: 29849.8750\n",
            "Epoch 313/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2937548032.0000 - mae: 29633.8594 - val_loss: 1956593664.0000 - val_mae: 29888.2676\n",
            "Epoch 314/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2934133248.0000 - mae: 29699.5117 - val_loss: 1956013952.0000 - val_mae: 29883.2461\n",
            "Epoch 315/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2932691968.0000 - mae: 29613.6836 - val_loss: 1953444480.0000 - val_mae: 29843.3574\n",
            "Epoch 316/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2929167616.0000 - mae: 29624.4668 - val_loss: 1953759232.0000 - val_mae: 29849.4844\n",
            "Epoch 317/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2926073344.0000 - mae: 29602.4258 - val_loss: 1953034368.0000 - val_mae: 29856.1270\n",
            "Epoch 318/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2924347648.0000 - mae: 29687.1465 - val_loss: 1950054400.0000 - val_mae: 29785.7695\n",
            "Epoch 319/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2921067776.0000 - mae: 29519.6562 - val_loss: 1950756864.0000 - val_mae: 29814.1719\n",
            "Epoch 320/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2918748928.0000 - mae: 29541.5449 - val_loss: 1949638656.0000 - val_mae: 29813.8496\n",
            "Epoch 321/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2915205888.0000 - mae: 29549.2910 - val_loss: 1947683968.0000 - val_mae: 29788.7988\n",
            "Epoch 322/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2914713088.0000 - mae: 29589.0000 - val_loss: 1944662528.0000 - val_mae: 29726.0332\n",
            "Epoch 323/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2910997504.0000 - mae: 29443.1113 - val_loss: 1945032960.0000 - val_mae: 29751.0195\n",
            "Epoch 324/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2909550592.0000 - mae: 29489.0137 - val_loss: 1944937216.0000 - val_mae: 29760.4375\n",
            "Epoch 325/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2906599936.0000 - mae: 29543.7148 - val_loss: 1941603200.0000 - val_mae: 29694.2500\n",
            "Epoch 326/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2905641728.0000 - mae: 29489.5977 - val_loss: 1940000000.0000 - val_mae: 29665.6348\n",
            "Epoch 327/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2902914304.0000 - mae: 29370.5410 - val_loss: 1939505664.0000 - val_mae: 29670.3926\n",
            "Epoch 328/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2899916544.0000 - mae: 29470.0684 - val_loss: 1937311104.0000 - val_mae: 29630.7402\n",
            "Epoch 329/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2899046144.0000 - mae: 29389.7324 - val_loss: 1937611264.0000 - val_mae: 29648.6055\n",
            "Epoch 330/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2895937536.0000 - mae: 29341.9863 - val_loss: 1936163072.0000 - val_mae: 29634.6250\n",
            "Epoch 331/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2894178560.0000 - mae: 29349.2461 - val_loss: 1935855616.0000 - val_mae: 29631.0527\n",
            "Epoch 332/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2892208384.0000 - mae: 29361.7656 - val_loss: 1934531072.0000 - val_mae: 29605.5234\n",
            "Epoch 333/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2890560512.0000 - mae: 29376.8730 - val_loss: 1933445760.0000 - val_mae: 29587.5430\n",
            "Epoch 334/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2887475968.0000 - mae: 29302.4043 - val_loss: 1931043712.0000 - val_mae: 29567.2344\n",
            "Epoch 335/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2885185536.0000 - mae: 29276.1777 - val_loss: 1929977344.0000 - val_mae: 29550.4082\n",
            "Epoch 336/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2882768640.0000 - mae: 29259.5430 - val_loss: 1930256256.0000 - val_mae: 29573.1367\n",
            "Epoch 337/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2883353088.0000 - mae: 29253.5566 - val_loss: 1927197696.0000 - val_mae: 29519.2363\n",
            "Epoch 338/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2878227968.0000 - mae: 29218.1895 - val_loss: 1925936128.0000 - val_mae: 29499.2168\n",
            "Epoch 339/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2877554432.0000 - mae: 29220.6562 - val_loss: 1925771008.0000 - val_mae: 29513.7109\n",
            "Epoch 340/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2874182912.0000 - mae: 29231.8301 - val_loss: 1925042048.0000 - val_mae: 29488.0625\n",
            "Epoch 341/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2873064704.0000 - mae: 29154.5156 - val_loss: 1924686976.0000 - val_mae: 29497.7031\n",
            "Epoch 342/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2871325440.0000 - mae: 29198.0078 - val_loss: 1923011712.0000 - val_mae: 29481.9219\n",
            "Epoch 343/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2869515008.0000 - mae: 29135.5273 - val_loss: 1921340288.0000 - val_mae: 29462.6543\n",
            "Epoch 344/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2867633664.0000 - mae: 29173.9512 - val_loss: 1919034112.0000 - val_mae: 29410.8203\n",
            "Epoch 345/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2865869824.0000 - mae: 29012.0176 - val_loss: 1918857216.0000 - val_mae: 29435.4863\n",
            "Epoch 346/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2864177408.0000 - mae: 29090.1172 - val_loss: 1918790784.0000 - val_mae: 29441.2383\n",
            "Epoch 347/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2863990528.0000 - mae: 29059.5625 - val_loss: 1916994432.0000 - val_mae: 29409.2090\n",
            "Epoch 348/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2859580160.0000 - mae: 29134.5527 - val_loss: 1915236608.0000 - val_mae: 29365.4961\n",
            "Epoch 349/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2859385088.0000 - mae: 29067.1016 - val_loss: 1914351488.0000 - val_mae: 29358.2168\n",
            "Epoch 350/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2856689920.0000 - mae: 29080.3770 - val_loss: 1913494912.0000 - val_mae: 29344.3770\n",
            "Epoch 351/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2855815168.0000 - mae: 29031.4688 - val_loss: 1912362368.0000 - val_mae: 29339.5176\n",
            "Epoch 352/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2853865216.0000 - mae: 28979.0293 - val_loss: 1913381248.0000 - val_mae: 29383.4629\n",
            "Epoch 353/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2851899392.0000 - mae: 29029.3691 - val_loss: 1912788864.0000 - val_mae: 29361.7656\n",
            "Epoch 354/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2850121984.0000 - mae: 29066.7656 - val_loss: 1910898176.0000 - val_mae: 29317.1504\n",
            "Epoch 355/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2847963648.0000 - mae: 28983.9707 - val_loss: 1910022784.0000 - val_mae: 29310.4336\n",
            "Epoch 356/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2847256064.0000 - mae: 28982.7734 - val_loss: 1909522560.0000 - val_mae: 29285.4766\n",
            "Epoch 357/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2845323520.0000 - mae: 28916.2598 - val_loss: 1909774848.0000 - val_mae: 29308.5840\n",
            "Epoch 358/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2843569408.0000 - mae: 28922.3438 - val_loss: 1909929728.0000 - val_mae: 29323.3691\n",
            "Epoch 359/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2842959360.0000 - mae: 29012.9727 - val_loss: 1908210304.0000 - val_mae: 29278.6934\n",
            "Epoch 360/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2840731648.0000 - mae: 28917.6445 - val_loss: 1907392384.0000 - val_mae: 29253.6074\n",
            "Epoch 361/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2839098368.0000 - mae: 28854.2383 - val_loss: 1907485696.0000 - val_mae: 29274.5039\n",
            "Epoch 362/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2838344448.0000 - mae: 28893.2949 - val_loss: 1907095808.0000 - val_mae: 29264.2363\n",
            "Epoch 363/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2836516608.0000 - mae: 28866.9609 - val_loss: 1906252928.0000 - val_mae: 29259.0918\n",
            "Epoch 364/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2836249088.0000 - mae: 28824.3574 - val_loss: 1904567552.0000 - val_mae: 29230.5859\n",
            "Epoch 365/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2831811840.0000 - mae: 28869.9199 - val_loss: 1902445824.0000 - val_mae: 29195.8223\n",
            "Epoch 366/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2832238336.0000 - mae: 28853.2969 - val_loss: 1901854592.0000 - val_mae: 29175.1875\n",
            "Epoch 367/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2829866240.0000 - mae: 28767.7598 - val_loss: 1902185216.0000 - val_mae: 29216.1602\n",
            "Epoch 368/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2829649920.0000 - mae: 28833.5703 - val_loss: 1901517312.0000 - val_mae: 29203.7441\n",
            "Epoch 369/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2828461056.0000 - mae: 28779.0801 - val_loss: 1901036672.0000 - val_mae: 29211.8105\n",
            "Epoch 370/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2825592064.0000 - mae: 28810.1465 - val_loss: 1900218880.0000 - val_mae: 29183.6309\n",
            "Epoch 371/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2822402048.0000 - mae: 28734.2148 - val_loss: 1902720256.0000 - val_mae: 29243.6406\n",
            "Epoch 372/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2822765312.0000 - mae: 28822.1055 - val_loss: 1902611712.0000 - val_mae: 29238.9629\n",
            "Epoch 373/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2820901888.0000 - mae: 28835.4863 - val_loss: 1899846400.0000 - val_mae: 29179.0957\n",
            "Epoch 374/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2820749568.0000 - mae: 28714.2148 - val_loss: 1899456000.0000 - val_mae: 29173.3633\n",
            "Epoch 375/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2819620608.0000 - mae: 28762.6367 - val_loss: 1898656640.0000 - val_mae: 29174.3301\n",
            "Epoch 376/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2816755968.0000 - mae: 28717.2832 - val_loss: 1897049728.0000 - val_mae: 29155.3594\n",
            "Epoch 377/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2815396352.0000 - mae: 28721.1680 - val_loss: 1896174080.0000 - val_mae: 29144.3184\n",
            "Epoch 378/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2814602240.0000 - mae: 28687.6348 - val_loss: 1895151872.0000 - val_mae: 29128.2910\n",
            "Epoch 379/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2813635584.0000 - mae: 28713.7598 - val_loss: 1894363008.0000 - val_mae: 29113.2441\n",
            "Epoch 380/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2811235840.0000 - mae: 28674.2754 - val_loss: 1895639936.0000 - val_mae: 29142.3672\n",
            "Epoch 381/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2809907712.0000 - mae: 28726.0977 - val_loss: 1894806016.0000 - val_mae: 29116.5664\n",
            "Epoch 382/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2808483328.0000 - mae: 28599.9707 - val_loss: 1895236224.0000 - val_mae: 29149.1289\n",
            "Epoch 383/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2806429440.0000 - mae: 28678.6230 - val_loss: 1894277760.0000 - val_mae: 29133.0996\n",
            "Epoch 384/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2806649088.0000 - mae: 28704.9023 - val_loss: 1892889216.0000 - val_mae: 29101.2891\n",
            "Epoch 385/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2804686848.0000 - mae: 28644.7695 - val_loss: 1891604992.0000 - val_mae: 29082.2578\n",
            "Epoch 386/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2803448064.0000 - mae: 28678.5840 - val_loss: 1891201152.0000 - val_mae: 29079.4648\n",
            "Epoch 387/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2801366016.0000 - mae: 28565.9141 - val_loss: 1891654528.0000 - val_mae: 29111.1680\n",
            "Epoch 388/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2800305408.0000 - mae: 28601.2734 - val_loss: 1890424704.0000 - val_mae: 29101.7148\n",
            "Epoch 389/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2797819648.0000 - mae: 28693.0684 - val_loss: 1887293568.0000 - val_mae: 29031.6016\n",
            "Epoch 390/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2798155776.0000 - mae: 28550.0215 - val_loss: 1887322624.0000 - val_mae: 29040.1582\n",
            "Epoch 391/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2796945152.0000 - mae: 28555.7852 - val_loss: 1886677760.0000 - val_mae: 29033.8848\n",
            "Epoch 392/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2795696896.0000 - mae: 28622.5840 - val_loss: 1885980288.0000 - val_mae: 29003.1680\n",
            "Epoch 393/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2793558784.0000 - mae: 28480.0762 - val_loss: 1886893056.0000 - val_mae: 29047.8320\n",
            "Epoch 394/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2794146048.0000 - mae: 28562.3184 - val_loss: 1885198592.0000 - val_mae: 29021.1992\n",
            "Epoch 395/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2792600576.0000 - mae: 28530.5059 - val_loss: 1885588224.0000 - val_mae: 29033.0762\n",
            "Epoch 396/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2790785024.0000 - mae: 28556.9688 - val_loss: 1884792064.0000 - val_mae: 29016.2090\n",
            "Epoch 397/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2789697024.0000 - mae: 28510.0566 - val_loss: 1884625920.0000 - val_mae: 29022.5469\n",
            "Epoch 398/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2787770112.0000 - mae: 28577.6602 - val_loss: 1883251712.0000 - val_mae: 28984.1152\n",
            "Epoch 399/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2786764288.0000 - mae: 28496.1172 - val_loss: 1881632512.0000 - val_mae: 28964.6367\n",
            "Epoch 400/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2786020096.0000 - mae: 28435.9922 - val_loss: 1883670784.0000 - val_mae: 29016.9824\n",
            "Epoch 401/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2784436480.0000 - mae: 28510.7051 - val_loss: 1883980288.0000 - val_mae: 29018.3594\n",
            "Epoch 402/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2783591424.0000 - mae: 28523.4492 - val_loss: 1881944576.0000 - val_mae: 28980.1797\n",
            "Epoch 403/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2783208960.0000 - mae: 28481.6523 - val_loss: 1881123456.0000 - val_mae: 28954.2910\n",
            "Epoch 404/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2780921088.0000 - mae: 28482.8477 - val_loss: 1880224640.0000 - val_mae: 28950.2090\n",
            "Epoch 405/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2780774400.0000 - mae: 28471.8945 - val_loss: 1878827136.0000 - val_mae: 28924.5117\n",
            "Epoch 406/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2779465216.0000 - mae: 28435.2988 - val_loss: 1878541952.0000 - val_mae: 28927.4141\n",
            "Epoch 407/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2777795584.0000 - mae: 28496.0586 - val_loss: 1877575168.0000 - val_mae: 28903.4434\n",
            "Epoch 408/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2777135360.0000 - mae: 28409.8730 - val_loss: 1877913472.0000 - val_mae: 28918.9707\n",
            "Epoch 409/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2777065216.0000 - mae: 28391.4395 - val_loss: 1878407936.0000 - val_mae: 28938.7637\n",
            "Epoch 410/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2773522432.0000 - mae: 28452.2773 - val_loss: 1877078656.0000 - val_mae: 28893.7598\n",
            "Epoch 411/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2773241088.0000 - mae: 28414.4453 - val_loss: 1875956992.0000 - val_mae: 28873.0469\n",
            "Epoch 412/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2772756480.0000 - mae: 28327.1250 - val_loss: 1877052416.0000 - val_mae: 28902.5664\n",
            "Epoch 413/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2771203840.0000 - mae: 28376.6641 - val_loss: 1879135360.0000 - val_mae: 28940.7832\n",
            "Epoch 414/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2771047680.0000 - mae: 28429.2168 - val_loss: 1876909952.0000 - val_mae: 28888.9004\n",
            "Epoch 415/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2769637376.0000 - mae: 28385.6133 - val_loss: 1875251456.0000 - val_mae: 28854.9727\n",
            "Epoch 416/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2768396544.0000 - mae: 28336.0195 - val_loss: 1875515776.0000 - val_mae: 28872.7949\n",
            "Epoch 417/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2767354112.0000 - mae: 28369.7344 - val_loss: 1875048576.0000 - val_mae: 28850.6758\n",
            "Epoch 418/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2764476672.0000 - mae: 28384.3691 - val_loss: 1872509952.0000 - val_mae: 28794.3770\n",
            "Epoch 419/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2764999936.0000 - mae: 28311.7656 - val_loss: 1872432512.0000 - val_mae: 28798.1211\n",
            "Epoch 420/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2764100608.0000 - mae: 28339.2207 - val_loss: 1872033792.0000 - val_mae: 28798.2871\n",
            "Epoch 421/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2762577408.0000 - mae: 28340.9688 - val_loss: 1871627136.0000 - val_mae: 28798.6562\n",
            "Epoch 422/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2761286144.0000 - mae: 28311.5430 - val_loss: 1871857280.0000 - val_mae: 28808.1152\n",
            "Epoch 423/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2760950272.0000 - mae: 28280.6035 - val_loss: 1871713280.0000 - val_mae: 28831.7207\n",
            "Epoch 424/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2760150528.0000 - mae: 28248.8301 - val_loss: 1870598656.0000 - val_mae: 28814.2676\n",
            "Epoch 425/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2758627072.0000 - mae: 28279.5527 - val_loss: 1870965120.0000 - val_mae: 28829.4141\n",
            "Epoch 426/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2757302272.0000 - mae: 28354.6016 - val_loss: 1868881664.0000 - val_mae: 28775.4355\n",
            "Epoch 427/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2756079360.0000 - mae: 28294.0996 - val_loss: 1868619520.0000 - val_mae: 28764.4062\n",
            "Epoch 428/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2754052096.0000 - mae: 28260.9492 - val_loss: 1869246208.0000 - val_mae: 28786.8242\n",
            "Epoch 429/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2754678016.0000 - mae: 28307.2363 - val_loss: 1870075520.0000 - val_mae: 28814.9004\n",
            "Epoch 430/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2753099008.0000 - mae: 28284.5703 - val_loss: 1868577536.0000 - val_mae: 28799.0684\n",
            "Epoch 431/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2752100608.0000 - mae: 28213.3555 - val_loss: 1869031680.0000 - val_mae: 28810.8730\n",
            "Epoch 432/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2751552768.0000 - mae: 28206.8828 - val_loss: 1868643328.0000 - val_mae: 28808.5176\n",
            "Epoch 433/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2749776640.0000 - mae: 28251.4863 - val_loss: 1868898944.0000 - val_mae: 28808.0684\n",
            "Epoch 434/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2748083968.0000 - mae: 28269.2305 - val_loss: 1867159168.0000 - val_mae: 28783.8145\n",
            "Epoch 435/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2748782592.0000 - mae: 28249.1152 - val_loss: 1865783808.0000 - val_mae: 28760.8945\n",
            "Epoch 436/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2746724096.0000 - mae: 28219.4648 - val_loss: 1865200384.0000 - val_mae: 28743.4785\n",
            "Epoch 437/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2745679616.0000 - mae: 28189.6641 - val_loss: 1866425856.0000 - val_mae: 28786.4863\n",
            "Epoch 438/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2744331008.0000 - mae: 28251.4141 - val_loss: 1865891072.0000 - val_mae: 28770.5020\n",
            "Epoch 439/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2744879104.0000 - mae: 28203.6152 - val_loss: 1864280576.0000 - val_mae: 28741.1816\n",
            "Epoch 440/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2742428928.0000 - mae: 28196.8691 - val_loss: 1862389248.0000 - val_mae: 28693.5645\n",
            "Epoch 441/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2743393280.0000 - mae: 28123.2500 - val_loss: 1862818560.0000 - val_mae: 28704.2676\n",
            "Epoch 442/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2741708288.0000 - mae: 28174.3867 - val_loss: 1864818944.0000 - val_mae: 28754.8301\n",
            "Epoch 443/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2740867328.0000 - mae: 28186.9492 - val_loss: 1863250944.0000 - val_mae: 28727.8379\n",
            "Epoch 444/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2739607296.0000 - mae: 28175.4023 - val_loss: 1861674624.0000 - val_mae: 28691.5430\n",
            "Epoch 445/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2738257408.0000 - mae: 28108.8691 - val_loss: 1862658944.0000 - val_mae: 28723.4492\n",
            "Epoch 446/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2735795712.0000 - mae: 28203.9277 - val_loss: 1860878464.0000 - val_mae: 28670.9102\n",
            "Epoch 447/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2735860992.0000 - mae: 28153.8613 - val_loss: 1860802560.0000 - val_mae: 28675.1953\n",
            "Epoch 448/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2735476736.0000 - mae: 28132.9785 - val_loss: 1860137344.0000 - val_mae: 28661.8320\n",
            "Epoch 449/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2733802496.0000 - mae: 28119.3008 - val_loss: 1860813568.0000 - val_mae: 28688.6348\n",
            "Epoch 450/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2733981184.0000 - mae: 28124.3887 - val_loss: 1861992704.0000 - val_mae: 28725.4727\n",
            "Epoch 451/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2733159680.0000 - mae: 28110.8027 - val_loss: 1860340608.0000 - val_mae: 28701.8379\n",
            "Epoch 452/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2732412672.0000 - mae: 28165.7305 - val_loss: 1860252288.0000 - val_mae: 28682.1895\n",
            "Epoch 453/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2731088896.0000 - mae: 28096.5039 - val_loss: 1861424000.0000 - val_mae: 28700.2734\n",
            "Epoch 454/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2728609792.0000 - mae: 28186.3105 - val_loss: 1858516608.0000 - val_mae: 28623.3770\n",
            "Epoch 455/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2727372032.0000 - mae: 28086.7422 - val_loss: 1857464192.0000 - val_mae: 28631.5352\n",
            "Epoch 456/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2727651328.0000 - mae: 28054.6426 - val_loss: 1857403136.0000 - val_mae: 28646.0508\n",
            "Epoch 457/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2726702336.0000 - mae: 28093.2637 - val_loss: 1857978496.0000 - val_mae: 28659.0898\n",
            "Epoch 458/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2725934080.0000 - mae: 28076.1504 - val_loss: 1858489856.0000 - val_mae: 28678.5566\n",
            "Epoch 459/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2725446656.0000 - mae: 28118.4434 - val_loss: 1858674816.0000 - val_mae: 28667.2539\n",
            "Epoch 460/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2723719936.0000 - mae: 28096.3398 - val_loss: 1859565184.0000 - val_mae: 28683.6797\n",
            "Epoch 461/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2723253504.0000 - mae: 28102.6797 - val_loss: 1856987392.0000 - val_mae: 28642.1758\n",
            "Epoch 462/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2721922560.0000 - mae: 28045.1387 - val_loss: 1856653696.0000 - val_mae: 28635.7656\n",
            "Epoch 463/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2721374464.0000 - mae: 28091.4355 - val_loss: 1856018688.0000 - val_mae: 28624.9121\n",
            "Epoch 464/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2720675840.0000 - mae: 28061.9199 - val_loss: 1854620160.0000 - val_mae: 28610.7754\n",
            "Epoch 465/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2719301888.0000 - mae: 28085.4980 - val_loss: 1854672000.0000 - val_mae: 28598.9043\n",
            "Epoch 466/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2718031360.0000 - mae: 28072.5840 - val_loss: 1852622976.0000 - val_mae: 28545.0703\n",
            "Epoch 467/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2718548480.0000 - mae: 28003.8203 - val_loss: 1853439872.0000 - val_mae: 28580.7500\n",
            "Epoch 468/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2716432128.0000 - mae: 28033.3105 - val_loss: 1854727424.0000 - val_mae: 28618.1582\n",
            "Epoch 469/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2716041728.0000 - mae: 27998.7090 - val_loss: 1854202880.0000 - val_mae: 28627.6074\n",
            "Epoch 470/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2715027200.0000 - mae: 27972.5938 - val_loss: 1853763200.0000 - val_mae: 28632.9531\n",
            "Epoch 471/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2714866944.0000 - mae: 27987.5723 - val_loss: 1852016768.0000 - val_mae: 28605.0879\n",
            "Epoch 472/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2713448448.0000 - mae: 28028.2188 - val_loss: 1851325568.0000 - val_mae: 28578.8984\n",
            "Epoch 473/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2712974080.0000 - mae: 28014.2598 - val_loss: 1850866560.0000 - val_mae: 28560.5859\n",
            "Epoch 474/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2712859136.0000 - mae: 27949.2734 - val_loss: 1849732352.0000 - val_mae: 28549.3145\n",
            "Epoch 475/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2710907904.0000 - mae: 27967.8535 - val_loss: 1849087616.0000 - val_mae: 28533.1895\n",
            "Epoch 476/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2710788352.0000 - mae: 27946.5020 - val_loss: 1849284992.0000 - val_mae: 28541.1582\n",
            "Epoch 477/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2708814080.0000 - mae: 27929.1914 - val_loss: 1849948928.0000 - val_mae: 28561.0312\n",
            "Epoch 478/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2708878080.0000 - mae: 27988.9785 - val_loss: 1848366848.0000 - val_mae: 28537.1719\n",
            "Epoch 479/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2708134656.0000 - mae: 27999.6543 - val_loss: 1849319040.0000 - val_mae: 28534.2246\n",
            "Epoch 480/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2706996736.0000 - mae: 27925.3008 - val_loss: 1848841984.0000 - val_mae: 28538.5410\n",
            "Epoch 481/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2706841344.0000 - mae: 27908.2891 - val_loss: 1849634176.0000 - val_mae: 28579.6309\n",
            "Epoch 482/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2705042688.0000 - mae: 27964.5176 - val_loss: 1848873856.0000 - val_mae: 28550.0000\n",
            "Epoch 483/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2704126464.0000 - mae: 27956.0977 - val_loss: 1849000320.0000 - val_mae: 28529.8906\n",
            "Epoch 484/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2702444800.0000 - mae: 27974.3926 - val_loss: 1847569024.0000 - val_mae: 28495.3594\n",
            "Epoch 485/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2702262016.0000 - mae: 27919.4980 - val_loss: 1847316352.0000 - val_mae: 28501.3535\n",
            "Epoch 486/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2701718784.0000 - mae: 27880.9492 - val_loss: 1847256064.0000 - val_mae: 28494.9688\n",
            "Epoch 487/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2699367936.0000 - mae: 27977.3457 - val_loss: 1845983232.0000 - val_mae: 28446.2188\n",
            "Epoch 488/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2700033024.0000 - mae: 27861.3145 - val_loss: 1847225728.0000 - val_mae: 28489.2578\n",
            "Epoch 489/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2698853376.0000 - mae: 27929.6934 - val_loss: 1847155584.0000 - val_mae: 28476.8477\n",
            "Epoch 490/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2698005504.0000 - mae: 27904.6758 - val_loss: 1845980544.0000 - val_mae: 28459.5547\n",
            "Epoch 491/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2696382976.0000 - mae: 27906.7012 - val_loss: 1845002624.0000 - val_mae: 28426.3984\n",
            "Epoch 492/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2697512192.0000 - mae: 27816.2109 - val_loss: 1845877120.0000 - val_mae: 28467.5625\n",
            "Epoch 493/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2694438912.0000 - mae: 27903.3359 - val_loss: 1844835840.0000 - val_mae: 28433.3066\n",
            "Epoch 494/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2694916864.0000 - mae: 27802.1055 - val_loss: 1845542528.0000 - val_mae: 28481.5820\n",
            "Epoch 495/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2694163968.0000 - mae: 27882.7031 - val_loss: 1845011072.0000 - val_mae: 28468.7754\n",
            "Epoch 496/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2693184512.0000 - mae: 27872.2285 - val_loss: 1842926336.0000 - val_mae: 28432.4336\n",
            "Epoch 497/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2693255936.0000 - mae: 27823.0918 - val_loss: 1844185216.0000 - val_mae: 28461.1387\n",
            "Epoch 498/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2690637824.0000 - mae: 27862.9473 - val_loss: 1841952128.0000 - val_mae: 28429.4023\n",
            "Epoch 499/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2691044864.0000 - mae: 27820.0000 - val_loss: 1840949504.0000 - val_mae: 28430.4492\n",
            "Epoch 500/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2690378752.0000 - mae: 27806.5605 - val_loss: 1841308416.0000 - val_mae: 28436.7344\n",
            "Epoch 501/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2688638208.0000 - mae: 27856.5039 - val_loss: 1840066176.0000 - val_mae: 28413.5020\n",
            "Epoch 502/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2688511232.0000 - mae: 27839.9238 - val_loss: 1840225024.0000 - val_mae: 28412.0957\n",
            "Epoch 503/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2687010048.0000 - mae: 27796.2168 - val_loss: 1839612800.0000 - val_mae: 28424.4434\n",
            "Epoch 504/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2686670848.0000 - mae: 27832.5645 - val_loss: 1839593088.0000 - val_mae: 28418.2148\n",
            "Epoch 505/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2687460096.0000 - mae: 27797.2871 - val_loss: 1839002496.0000 - val_mae: 28419.5977\n",
            "Epoch 506/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2685574912.0000 - mae: 27855.0234 - val_loss: 1837930112.0000 - val_mae: 28386.0625\n",
            "Epoch 507/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2685291520.0000 - mae: 27773.0137 - val_loss: 1838311424.0000 - val_mae: 28404.5820\n",
            "Epoch 508/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2683935488.0000 - mae: 27766.3496 - val_loss: 1839921024.0000 - val_mae: 28441.4551\n",
            "Epoch 509/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2682621184.0000 - mae: 27825.0488 - val_loss: 1839395712.0000 - val_mae: 28425.8848\n",
            "Epoch 510/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2682626816.0000 - mae: 27806.0176 - val_loss: 1838495744.0000 - val_mae: 28412.0039\n",
            "Epoch 511/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2681529600.0000 - mae: 27842.7500 - val_loss: 1837585536.0000 - val_mae: 28371.2344\n",
            "Epoch 512/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2681367040.0000 - mae: 27747.8535 - val_loss: 1836921344.0000 - val_mae: 28360.4082\n",
            "Epoch 513/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2680222720.0000 - mae: 27794.1348 - val_loss: 1836562944.0000 - val_mae: 28349.5117\n",
            "Epoch 514/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2678667008.0000 - mae: 27743.5762 - val_loss: 1835944064.0000 - val_mae: 28350.2090\n",
            "Epoch 515/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2679069952.0000 - mae: 27768.1719 - val_loss: 1835085312.0000 - val_mae: 28336.4141\n",
            "Epoch 516/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2678288640.0000 - mae: 27736.6699 - val_loss: 1835264128.0000 - val_mae: 28356.3672\n",
            "Epoch 517/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2676597760.0000 - mae: 27768.5840 - val_loss: 1835877376.0000 - val_mae: 28359.4336\n",
            "Epoch 518/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2676488960.0000 - mae: 27727.8203 - val_loss: 1834970624.0000 - val_mae: 28351.4434\n",
            "Epoch 519/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2676016384.0000 - mae: 27675.1484 - val_loss: 1836264064.0000 - val_mae: 28374.0371\n",
            "Epoch 520/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2674370048.0000 - mae: 27753.8594 - val_loss: 1835441664.0000 - val_mae: 28357.7324\n",
            "Epoch 521/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2673295360.0000 - mae: 27683.1758 - val_loss: 1836741888.0000 - val_mae: 28393.0996\n",
            "Epoch 522/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2674111488.0000 - mae: 27719.4258 - val_loss: 1834772992.0000 - val_mae: 28365.5078\n",
            "Epoch 523/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2671486720.0000 - mae: 27788.1406 - val_loss: 1832993024.0000 - val_mae: 28317.8281\n",
            "Epoch 524/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2672059648.0000 - mae: 27646.1426 - val_loss: 1833597184.0000 - val_mae: 28341.5176\n",
            "Epoch 525/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2671247872.0000 - mae: 27718.3145 - val_loss: 1832508800.0000 - val_mae: 28320.1582\n",
            "Epoch 526/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2670627840.0000 - mae: 27676.2734 - val_loss: 1831278080.0000 - val_mae: 28303.8984\n",
            "Epoch 527/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2668882944.0000 - mae: 27711.6348 - val_loss: 1830590720.0000 - val_mae: 28313.3965\n",
            "Epoch 528/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2668799232.0000 - mae: 27704.8594 - val_loss: 1831215872.0000 - val_mae: 28313.1406\n",
            "Epoch 529/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2666501632.0000 - mae: 27671.8633 - val_loss: 1830624128.0000 - val_mae: 28317.5371\n",
            "Epoch 530/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2668050176.0000 - mae: 27679.0039 - val_loss: 1829914112.0000 - val_mae: 28309.3398\n",
            "Epoch 531/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2667027456.0000 - mae: 27682.4395 - val_loss: 1829523200.0000 - val_mae: 28295.7812\n",
            "Epoch 532/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2665749248.0000 - mae: 27693.4082 - val_loss: 1830525056.0000 - val_mae: 28310.3203\n",
            "Epoch 533/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2665391104.0000 - mae: 27642.0469 - val_loss: 1829882496.0000 - val_mae: 28300.4570\n",
            "Epoch 534/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2664186624.0000 - mae: 27636.3438 - val_loss: 1830231040.0000 - val_mae: 28303.1875\n",
            "Epoch 535/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2663651072.0000 - mae: 27626.0469 - val_loss: 1828011136.0000 - val_mae: 28283.6797\n",
            "Epoch 536/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2663732992.0000 - mae: 27610.9629 - val_loss: 1827244928.0000 - val_mae: 28273.5176\n",
            "Epoch 537/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2662756608.0000 - mae: 27661.9336 - val_loss: 1827017984.0000 - val_mae: 28263.2285\n",
            "Epoch 538/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2661094656.0000 - mae: 27599.2891 - val_loss: 1827654272.0000 - val_mae: 28282.5781\n",
            "Epoch 539/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2659465472.0000 - mae: 27668.1660 - val_loss: 1826048128.0000 - val_mae: 28231.7305\n",
            "Epoch 540/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2661170688.0000 - mae: 27623.7344 - val_loss: 1826921856.0000 - val_mae: 28229.3340\n",
            "Epoch 541/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2658615296.0000 - mae: 27606.0684 - val_loss: 1826412288.0000 - val_mae: 28229.3047\n",
            "Epoch 542/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2659001600.0000 - mae: 27568.8535 - val_loss: 1826608128.0000 - val_mae: 28252.7695\n",
            "Epoch 543/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2656850176.0000 - mae: 27619.0703 - val_loss: 1827004288.0000 - val_mae: 28265.6895\n",
            "Epoch 544/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2657445888.0000 - mae: 27607.7617 - val_loss: 1826134016.0000 - val_mae: 28254.8652\n",
            "Epoch 545/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2657320704.0000 - mae: 27582.1094 - val_loss: 1826068480.0000 - val_mae: 28264.2578\n",
            "Epoch 546/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2654959872.0000 - mae: 27604.3340 - val_loss: 1825616128.0000 - val_mae: 28249.8438\n",
            "Epoch 547/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2654813184.0000 - mae: 27608.0781 - val_loss: 1826143616.0000 - val_mae: 28246.7148\n",
            "Epoch 548/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2653694976.0000 - mae: 27612.0410 - val_loss: 1825590528.0000 - val_mae: 28239.5234\n",
            "Epoch 549/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2654096128.0000 - mae: 27552.3281 - val_loss: 1825126528.0000 - val_mae: 28228.6035\n",
            "Epoch 550/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2652067840.0000 - mae: 27567.6250 - val_loss: 1825399936.0000 - val_mae: 28247.4395\n",
            "Epoch 551/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2651493632.0000 - mae: 27565.0371 - val_loss: 1826275968.0000 - val_mae: 28269.6602\n",
            "Epoch 552/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2650492416.0000 - mae: 27625.1523 - val_loss: 1825096704.0000 - val_mae: 28247.1562\n",
            "Epoch 553/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2650054144.0000 - mae: 27633.0371 - val_loss: 1823102464.0000 - val_mae: 28220.8516\n",
            "Epoch 554/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2649677568.0000 - mae: 27569.3828 - val_loss: 1822676992.0000 - val_mae: 28208.2188\n",
            "Epoch 555/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2648291328.0000 - mae: 27554.0215 - val_loss: 1822358912.0000 - val_mae: 28193.8750\n",
            "Epoch 556/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2648663552.0000 - mae: 27457.3594 - val_loss: 1823561728.0000 - val_mae: 28235.2344\n",
            "Epoch 557/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2646988800.0000 - mae: 27555.7715 - val_loss: 1823104384.0000 - val_mae: 28223.7305\n",
            "Epoch 558/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2646410752.0000 - mae: 27530.5078 - val_loss: 1823649536.0000 - val_mae: 28236.2188\n",
            "Epoch 559/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2645961216.0000 - mae: 27571.6406 - val_loss: 1824037120.0000 - val_mae: 28235.5449\n",
            "Epoch 560/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2644290560.0000 - mae: 27579.3926 - val_loss: 1823098752.0000 - val_mae: 28223.3164\n",
            "Epoch 561/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2645098240.0000 - mae: 27543.9043 - val_loss: 1822153600.0000 - val_mae: 28208.9238\n",
            "Epoch 562/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2643873024.0000 - mae: 27563.2344 - val_loss: 1821372416.0000 - val_mae: 28208.5664\n",
            "Epoch 563/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2643391744.0000 - mae: 27553.5938 - val_loss: 1821121280.0000 - val_mae: 28192.3164\n",
            "Epoch 564/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2642465024.0000 - mae: 27496.7598 - val_loss: 1822642560.0000 - val_mae: 28221.7559\n",
            "Epoch 565/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2640672000.0000 - mae: 27590.8633 - val_loss: 1821035008.0000 - val_mae: 28183.9531\n",
            "Epoch 566/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2640869888.0000 - mae: 27531.0410 - val_loss: 1820636928.0000 - val_mae: 28169.9336\n",
            "Epoch 567/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2639976960.0000 - mae: 27506.1797 - val_loss: 1820769024.0000 - val_mae: 28170.6328\n",
            "Epoch 568/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2640158208.0000 - mae: 27455.5957 - val_loss: 1821162240.0000 - val_mae: 28198.4766\n",
            "Epoch 569/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2639432960.0000 - mae: 27515.1426 - val_loss: 1819997696.0000 - val_mae: 28175.3242\n",
            "Epoch 570/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2638103808.0000 - mae: 27516.2051 - val_loss: 1818061312.0000 - val_mae: 28148.7500\n",
            "Epoch 571/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2638063616.0000 - mae: 27449.8418 - val_loss: 1819061248.0000 - val_mae: 28173.1055\n",
            "Epoch 572/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2637084672.0000 - mae: 27481.5039 - val_loss: 1818892544.0000 - val_mae: 28181.2266\n",
            "Epoch 573/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2636145408.0000 - mae: 27448.4258 - val_loss: 1820176000.0000 - val_mae: 28203.7305\n",
            "Epoch 574/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2636225536.0000 - mae: 27513.3789 - val_loss: 1819039232.0000 - val_mae: 28181.7090\n",
            "Epoch 575/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2635337728.0000 - mae: 27543.5781 - val_loss: 1818713344.0000 - val_mae: 28174.6465\n",
            "Epoch 576/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2633974528.0000 - mae: 27452.4844 - val_loss: 1819575168.0000 - val_mae: 28195.0801\n",
            "Epoch 577/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2634266368.0000 - mae: 27539.2285 - val_loss: 1819761024.0000 - val_mae: 28192.5977\n",
            "Epoch 578/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2632683776.0000 - mae: 27485.0098 - val_loss: 1819645184.0000 - val_mae: 28189.1406\n",
            "Epoch 579/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2631133440.0000 - mae: 27497.1660 - val_loss: 1817807104.0000 - val_mae: 28156.7754\n",
            "Epoch 580/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2631936000.0000 - mae: 27448.4395 - val_loss: 1817593728.0000 - val_mae: 28162.6055\n",
            "Epoch 581/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2630398720.0000 - mae: 27484.0410 - val_loss: 1816775808.0000 - val_mae: 28146.4941\n",
            "Epoch 582/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2630631168.0000 - mae: 27406.2852 - val_loss: 1816840320.0000 - val_mae: 28164.9609\n",
            "Epoch 583/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2628978688.0000 - mae: 27454.3848 - val_loss: 1817463424.0000 - val_mae: 28165.5625\n",
            "Epoch 584/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2628894976.0000 - mae: 27456.1289 - val_loss: 1815051776.0000 - val_mae: 28139.3984\n",
            "Epoch 585/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2628730880.0000 - mae: 27462.3984 - val_loss: 1815145600.0000 - val_mae: 28141.1348\n",
            "Epoch 586/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2627185664.0000 - mae: 27467.4082 - val_loss: 1814453248.0000 - val_mae: 28126.7637\n",
            "Epoch 587/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2627331584.0000 - mae: 27429.8730 - val_loss: 1815414656.0000 - val_mae: 28146.3848\n",
            "Epoch 588/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2625427712.0000 - mae: 27431.3145 - val_loss: 1814019072.0000 - val_mae: 28127.1973\n",
            "Epoch 589/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2625233664.0000 - mae: 27440.6309 - val_loss: 1814810624.0000 - val_mae: 28151.7129\n",
            "Epoch 590/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2625967872.0000 - mae: 27436.2402 - val_loss: 1814688512.0000 - val_mae: 28146.8320\n",
            "Epoch 591/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2623878912.0000 - mae: 27433.9629 - val_loss: 1816210432.0000 - val_mae: 28162.8613\n",
            "Epoch 592/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2623440640.0000 - mae: 27428.1523 - val_loss: 1815453824.0000 - val_mae: 28147.9121\n",
            "Epoch 593/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2622811136.0000 - mae: 27427.4844 - val_loss: 1816169088.0000 - val_mae: 28167.2695\n",
            "Epoch 594/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2622055424.0000 - mae: 27436.6211 - val_loss: 1815252864.0000 - val_mae: 28150.6602\n",
            "Epoch 595/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2622613248.0000 - mae: 27457.0332 - val_loss: 1813290496.0000 - val_mae: 28116.9473\n",
            "Epoch 596/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2619919104.0000 - mae: 27378.3438 - val_loss: 1813746688.0000 - val_mae: 28128.3242\n",
            "Epoch 597/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2620321024.0000 - mae: 27424.4180 - val_loss: 1813585280.0000 - val_mae: 28116.9590\n",
            "Epoch 598/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2619792128.0000 - mae: 27423.4082 - val_loss: 1812499712.0000 - val_mae: 28097.1211\n",
            "Epoch 599/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2618821120.0000 - mae: 27409.7422 - val_loss: 1812376832.0000 - val_mae: 28099.4531\n",
            "Epoch 600/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2618797312.0000 - mae: 27380.2910 - val_loss: 1812886528.0000 - val_mae: 28117.1680\n",
            "Epoch 601/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2617950208.0000 - mae: 27363.8809 - val_loss: 1811908864.0000 - val_mae: 28100.0508\n",
            "Epoch 602/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2617634048.0000 - mae: 27408.4863 - val_loss: 1811640320.0000 - val_mae: 28095.0898\n",
            "Epoch 603/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2616861696.0000 - mae: 27360.3652 - val_loss: 1812012416.0000 - val_mae: 28123.2754\n",
            "Epoch 604/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2614845952.0000 - mae: 27431.4023 - val_loss: 1809668352.0000 - val_mae: 28072.3867\n",
            "Epoch 605/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2616082432.0000 - mae: 27320.6816 - val_loss: 1811702400.0000 - val_mae: 28109.9824\n",
            "Epoch 606/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2613633792.0000 - mae: 27408.6035 - val_loss: 1809883136.0000 - val_mae: 28079.6211\n",
            "Epoch 607/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2613975040.0000 - mae: 27376.5410 - val_loss: 1808816384.0000 - val_mae: 28056.6660\n",
            "Epoch 608/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2612965888.0000 - mae: 27303.1465 - val_loss: 1809764736.0000 - val_mae: 28077.5820\n",
            "Epoch 609/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2612734464.0000 - mae: 27335.7305 - val_loss: 1808540032.0000 - val_mae: 28065.4141\n",
            "Epoch 610/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2612397568.0000 - mae: 27266.1895 - val_loss: 1809754752.0000 - val_mae: 28096.8730\n",
            "Epoch 611/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2611539968.0000 - mae: 27405.0762 - val_loss: 1808098688.0000 - val_mae: 28059.7598\n",
            "Epoch 612/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2610789888.0000 - mae: 27295.0508 - val_loss: 1808738560.0000 - val_mae: 28084.2461\n",
            "Epoch 613/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2610789888.0000 - mae: 27314.0566 - val_loss: 1808281088.0000 - val_mae: 28076.1250\n",
            "Epoch 614/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2609544960.0000 - mae: 27336.0234 - val_loss: 1807897088.0000 - val_mae: 28054.2480\n",
            "Epoch 615/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2608339712.0000 - mae: 27339.2539 - val_loss: 1806008448.0000 - val_mae: 28022.5332\n",
            "Epoch 616/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2608048128.0000 - mae: 27333.2285 - val_loss: 1806537728.0000 - val_mae: 28025.8320\n",
            "Epoch 617/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2608181760.0000 - mae: 27281.8594 - val_loss: 1806319232.0000 - val_mae: 28055.2207\n",
            "Epoch 618/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2607239936.0000 - mae: 27337.7227 - val_loss: 1805232128.0000 - val_mae: 28035.8340\n",
            "Epoch 619/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2606549248.0000 - mae: 27294.8848 - val_loss: 1805485568.0000 - val_mae: 28046.9102\n",
            "Epoch 620/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2604957184.0000 - mae: 27317.6660 - val_loss: 1805766784.0000 - val_mae: 28053.8145\n",
            "Epoch 621/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2605231616.0000 - mae: 27296.9238 - val_loss: 1805920384.0000 - val_mae: 28056.7402\n",
            "Epoch 622/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2603987200.0000 - mae: 27320.8613 - val_loss: 1806725504.0000 - val_mae: 28055.1113\n",
            "Epoch 623/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2603474688.0000 - mae: 27299.8789 - val_loss: 1805662336.0000 - val_mae: 28037.3281\n",
            "Epoch 624/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2603177472.0000 - mae: 27292.7656 - val_loss: 1804203392.0000 - val_mae: 28016.6328\n",
            "Epoch 625/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2602744576.0000 - mae: 27288.0039 - val_loss: 1803250688.0000 - val_mae: 28002.6406\n",
            "Epoch 626/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2602617088.0000 - mae: 27266.9375 - val_loss: 1803760384.0000 - val_mae: 28016.5879\n",
            "Epoch 627/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2602698240.0000 - mae: 27285.8984 - val_loss: 1803899008.0000 - val_mae: 28020.2402\n",
            "Epoch 628/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2600412416.0000 - mae: 27289.2148 - val_loss: 1804709120.0000 - val_mae: 28024.8652\n",
            "Epoch 629/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2600581632.0000 - mae: 27303.7207 - val_loss: 1805130752.0000 - val_mae: 28031.6836\n",
            "Epoch 630/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2599551232.0000 - mae: 27282.2480 - val_loss: 1804817280.0000 - val_mae: 28033.7168\n",
            "Epoch 631/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2599953920.0000 - mae: 27272.2852 - val_loss: 1805289088.0000 - val_mae: 28045.2363\n",
            "Epoch 632/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2598030080.0000 - mae: 27308.4551 - val_loss: 1803883008.0000 - val_mae: 28017.0508\n",
            "Epoch 633/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2598464512.0000 - mae: 27272.2734 - val_loss: 1801836544.0000 - val_mae: 27994.4531\n",
            "Epoch 634/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2597712896.0000 - mae: 27283.9512 - val_loss: 1801339136.0000 - val_mae: 27973.6016\n",
            "Epoch 635/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2597617152.0000 - mae: 27255.8848 - val_loss: 1800508928.0000 - val_mae: 27963.1172\n",
            "Epoch 636/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2596443904.0000 - mae: 27219.3926 - val_loss: 1800949888.0000 - val_mae: 27978.6953\n",
            "Epoch 637/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2595793664.0000 - mae: 27271.3789 - val_loss: 1800316544.0000 - val_mae: 27961.9805\n",
            "Epoch 638/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2595315456.0000 - mae: 27233.6523 - val_loss: 1799747584.0000 - val_mae: 27955.8203\n",
            "Epoch 639/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2595534080.0000 - mae: 27248.9297 - val_loss: 1799052928.0000 - val_mae: 27956.7422\n",
            "Epoch 640/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2594209792.0000 - mae: 27254.0430 - val_loss: 1797868032.0000 - val_mae: 27935.4434\n",
            "Epoch 641/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2593933568.0000 - mae: 27210.9727 - val_loss: 1797294848.0000 - val_mae: 27925.6719\n",
            "Epoch 642/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2593687296.0000 - mae: 27195.0332 - val_loss: 1798896128.0000 - val_mae: 27972.0605\n",
            "Epoch 643/2000\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 2592320256.0000 - mae: 27247.6953 - val_loss: 1800161664.0000 - val_mae: 27977.4395\n",
            "Epoch 644/2000\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 2592307456.0000 - mae: 27240.8477 - val_loss: 1800748288.0000 - val_mae: 27982.8301\n",
            "Epoch 645/2000\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 2591609600.0000 - mae: 27218.5020 - val_loss: 1801419008.0000 - val_mae: 27991.5215\n",
            "Epoch 646/2000\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 2593254656.0000 - mae: 27210.7617 - val_loss: 1798478336.0000 - val_mae: 27949.1387\n",
            "Epoch 647/2000\n",
            "26/26 [==============================] - 0s 16ms/step - loss: 2589868032.0000 - mae: 27243.3867 - val_loss: 1796958080.0000 - val_mae: 27924.1367\n",
            "Epoch 648/2000\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 2590291968.0000 - mae: 27172.1406 - val_loss: 1796523008.0000 - val_mae: 27934.2676\n",
            "Epoch 649/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2589853184.0000 - mae: 27173.4551 - val_loss: 1795871488.0000 - val_mae: 27936.4375\n",
            "Epoch 650/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2589229056.0000 - mae: 27166.4180 - val_loss: 1796391168.0000 - val_mae: 27932.7090\n",
            "Epoch 651/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2587410944.0000 - mae: 27201.7402 - val_loss: 1796901632.0000 - val_mae: 27924.9805\n",
            "Epoch 652/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2587677696.0000 - mae: 27173.7500 - val_loss: 1796223488.0000 - val_mae: 27922.3184\n",
            "Epoch 653/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2586880512.0000 - mae: 27204.9668 - val_loss: 1796676992.0000 - val_mae: 27923.2344\n",
            "Epoch 654/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2585947904.0000 - mae: 27186.1211 - val_loss: 1795817984.0000 - val_mae: 27920.5547\n",
            "Epoch 655/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2586438656.0000 - mae: 27118.3887 - val_loss: 1796806272.0000 - val_mae: 27948.7695\n",
            "Epoch 656/2000\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 2585053952.0000 - mae: 27195.2695 - val_loss: 1795046784.0000 - val_mae: 27911.7988\n",
            "Epoch 657/2000\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 2584209920.0000 - mae: 27199.1875 - val_loss: 1795174912.0000 - val_mae: 27904.1895\n",
            "Epoch 658/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2583826944.0000 - mae: 27180.8477 - val_loss: 1794368128.0000 - val_mae: 27887.0801\n",
            "Epoch 659/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2583937280.0000 - mae: 27139.2246 - val_loss: 1794517248.0000 - val_mae: 27896.5449\n",
            "Epoch 660/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2583688448.0000 - mae: 27168.7637 - val_loss: 1794798208.0000 - val_mae: 27917.0391\n",
            "Epoch 661/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2582192128.0000 - mae: 27196.8340 - val_loss: 1795000704.0000 - val_mae: 27907.2500\n",
            "Epoch 662/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2581679104.0000 - mae: 27147.8730 - val_loss: 1793629056.0000 - val_mae: 27894.8281\n",
            "Epoch 663/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2583131904.0000 - mae: 27102.1172 - val_loss: 1793177472.0000 - val_mae: 27900.8105\n",
            "Epoch 664/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2580027904.0000 - mae: 27118.8145 - val_loss: 1793700736.0000 - val_mae: 27917.7949\n",
            "Epoch 665/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2579901696.0000 - mae: 27157.0703 - val_loss: 1791869824.0000 - val_mae: 27890.2188\n",
            "Epoch 666/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2579760640.0000 - mae: 27156.0332 - val_loss: 1792538880.0000 - val_mae: 27897.4668\n",
            "Epoch 667/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2579025920.0000 - mae: 27154.2383 - val_loss: 1792093696.0000 - val_mae: 27891.3574\n",
            "Epoch 668/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2578963200.0000 - mae: 27142.5762 - val_loss: 1791736960.0000 - val_mae: 27884.0117\n",
            "Epoch 669/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2578607616.0000 - mae: 27114.8125 - val_loss: 1792457600.0000 - val_mae: 27896.6758\n",
            "Epoch 670/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2576527872.0000 - mae: 27177.0527 - val_loss: 1791917824.0000 - val_mae: 27876.5840\n",
            "Epoch 671/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2577818112.0000 - mae: 27163.2363 - val_loss: 1791543552.0000 - val_mae: 27876.4492\n",
            "Epoch 672/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2576665600.0000 - mae: 27110.3535 - val_loss: 1791437824.0000 - val_mae: 27886.4219\n",
            "Epoch 673/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2575870976.0000 - mae: 27125.1582 - val_loss: 1791328768.0000 - val_mae: 27881.8203\n",
            "Epoch 674/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2575652864.0000 - mae: 27139.7637 - val_loss: 1790547968.0000 - val_mae: 27850.4590\n",
            "Epoch 675/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2574354432.0000 - mae: 27079.8516 - val_loss: 1791876736.0000 - val_mae: 27881.5508\n",
            "Epoch 676/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2574064384.0000 - mae: 27114.9883 - val_loss: 1790862208.0000 - val_mae: 27871.3203\n",
            "Epoch 677/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2574322944.0000 - mae: 27072.6992 - val_loss: 1789875200.0000 - val_mae: 27866.4668\n",
            "Epoch 678/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2573456896.0000 - mae: 27118.9766 - val_loss: 1789528064.0000 - val_mae: 27863.4395\n",
            "Epoch 679/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2571382016.0000 - mae: 27113.3633 - val_loss: 1790041088.0000 - val_mae: 27851.8301\n",
            "Epoch 680/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2572859136.0000 - mae: 27066.6348 - val_loss: 1789719936.0000 - val_mae: 27860.7031\n",
            "Epoch 681/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2570479104.0000 - mae: 27116.7930 - val_loss: 1788542208.0000 - val_mae: 27842.2305\n",
            "Epoch 682/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2571552000.0000 - mae: 27050.0039 - val_loss: 1790519936.0000 - val_mae: 27871.4883\n",
            "Epoch 683/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2570402048.0000 - mae: 27155.1582 - val_loss: 1791203584.0000 - val_mae: 27857.7168\n",
            "Epoch 684/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2569814528.0000 - mae: 27084.2695 - val_loss: 1792275072.0000 - val_mae: 27875.2109\n",
            "Epoch 685/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2570531328.0000 - mae: 27087.6816 - val_loss: 1790973056.0000 - val_mae: 27857.7227\n",
            "Epoch 686/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2568713728.0000 - mae: 27104.4961 - val_loss: 1789734784.0000 - val_mae: 27831.3242\n",
            "Epoch 687/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2567249408.0000 - mae: 27098.3457 - val_loss: 1789508736.0000 - val_mae: 27826.0488\n",
            "Epoch 688/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2568211968.0000 - mae: 27087.3359 - val_loss: 1789834752.0000 - val_mae: 27829.7637\n",
            "Epoch 689/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2567928064.0000 - mae: 27064.0781 - val_loss: 1788269824.0000 - val_mae: 27812.8438\n",
            "Epoch 690/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2566797824.0000 - mae: 27012.9004 - val_loss: 1789693568.0000 - val_mae: 27851.1875\n",
            "Epoch 691/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2566764288.0000 - mae: 27062.2988 - val_loss: 1787971072.0000 - val_mae: 27831.4434\n",
            "Epoch 692/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2566632192.0000 - mae: 27061.2266 - val_loss: 1786522240.0000 - val_mae: 27805.9277\n",
            "Epoch 693/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2564091904.0000 - mae: 27069.5273 - val_loss: 1784363520.0000 - val_mae: 27771.7402\n",
            "Epoch 694/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2565339392.0000 - mae: 27004.0527 - val_loss: 1785199744.0000 - val_mae: 27792.8945\n",
            "Epoch 695/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2565305600.0000 - mae: 27006.0293 - val_loss: 1785048704.0000 - val_mae: 27810.4473\n",
            "Epoch 696/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2564297216.0000 - mae: 27031.5566 - val_loss: 1784786176.0000 - val_mae: 27803.1211\n",
            "Epoch 697/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2563555072.0000 - mae: 27074.8711 - val_loss: 1784642048.0000 - val_mae: 27798.6855\n",
            "Epoch 698/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2563343872.0000 - mae: 26997.1895 - val_loss: 1784696064.0000 - val_mae: 27807.4473\n",
            "Epoch 699/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2561772544.0000 - mae: 27058.8203 - val_loss: 1783889664.0000 - val_mae: 27775.8652\n",
            "Epoch 700/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2561931520.0000 - mae: 26986.4180 - val_loss: 1783394176.0000 - val_mae: 27778.6348\n",
            "Epoch 701/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2561045248.0000 - mae: 27024.7051 - val_loss: 1784712704.0000 - val_mae: 27787.9043\n",
            "Epoch 702/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2561005824.0000 - mae: 27012.0605 - val_loss: 1786056320.0000 - val_mae: 27811.4766\n",
            "Epoch 703/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2558778880.0000 - mae: 27117.7109 - val_loss: 1784110464.0000 - val_mae: 27771.9023\n",
            "Epoch 704/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2558533376.0000 - mae: 27034.6895 - val_loss: 1783463424.0000 - val_mae: 27757.1426\n",
            "Epoch 705/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2559925248.0000 - mae: 26975.7012 - val_loss: 1784418304.0000 - val_mae: 27797.0918\n",
            "Epoch 706/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2558413056.0000 - mae: 26977.8574 - val_loss: 1785185664.0000 - val_mae: 27818.0176\n",
            "Epoch 707/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2558134272.0000 - mae: 27034.9688 - val_loss: 1784850816.0000 - val_mae: 27794.1074\n",
            "Epoch 708/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2557719808.0000 - mae: 27012.9824 - val_loss: 1784656000.0000 - val_mae: 27791.0684\n",
            "Epoch 709/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2557513216.0000 - mae: 26990.3984 - val_loss: 1783128832.0000 - val_mae: 27776.3145\n",
            "Epoch 710/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2556623872.0000 - mae: 27028.9883 - val_loss: 1782639616.0000 - val_mae: 27755.1406\n",
            "Epoch 711/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2555293184.0000 - mae: 27019.5059 - val_loss: 1781484544.0000 - val_mae: 27745.9512\n",
            "Epoch 712/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2555439104.0000 - mae: 26989.8652 - val_loss: 1782163072.0000 - val_mae: 27757.4258\n",
            "Epoch 713/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2554646528.0000 - mae: 27045.6836 - val_loss: 1781991808.0000 - val_mae: 27737.6699\n",
            "Epoch 714/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2555537152.0000 - mae: 26954.8496 - val_loss: 1783183360.0000 - val_mae: 27760.0117\n",
            "Epoch 715/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2553462272.0000 - mae: 26995.4160 - val_loss: 1782936320.0000 - val_mae: 27765.8633\n",
            "Epoch 716/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2553106432.0000 - mae: 26984.9980 - val_loss: 1783900288.0000 - val_mae: 27768.6250\n",
            "Epoch 717/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2553014272.0000 - mae: 27000.4062 - val_loss: 1782889472.0000 - val_mae: 27755.7793\n",
            "Epoch 718/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2551585024.0000 - mae: 26971.7617 - val_loss: 1783271552.0000 - val_mae: 27764.6621\n",
            "Epoch 719/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2551354880.0000 - mae: 27042.4141 - val_loss: 1781311488.0000 - val_mae: 27735.9609\n",
            "Epoch 720/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2550922752.0000 - mae: 26969.1719 - val_loss: 1781077888.0000 - val_mae: 27731.1074\n",
            "Epoch 721/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2550286592.0000 - mae: 26945.7344 - val_loss: 1781359232.0000 - val_mae: 27736.2402\n",
            "Epoch 722/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2549959936.0000 - mae: 26965.3574 - val_loss: 1781179008.0000 - val_mae: 27734.6406\n",
            "Epoch 723/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2550444032.0000 - mae: 26944.6562 - val_loss: 1780062080.0000 - val_mae: 27725.5117\n",
            "Epoch 724/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2548033536.0000 - mae: 26965.3164 - val_loss: 1779638656.0000 - val_mae: 27720.3184\n",
            "Epoch 725/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2549484544.0000 - mae: 26955.7520 - val_loss: 1779641600.0000 - val_mae: 27721.0234\n",
            "Epoch 726/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2548509696.0000 - mae: 26983.9824 - val_loss: 1779765504.0000 - val_mae: 27706.0898\n",
            "Epoch 727/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2547425536.0000 - mae: 26911.1289 - val_loss: 1780218624.0000 - val_mae: 27738.5664\n",
            "Epoch 728/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2548587008.0000 - mae: 26918.7598 - val_loss: 1779697408.0000 - val_mae: 27741.7715\n",
            "Epoch 729/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2546553344.0000 - mae: 26984.2852 - val_loss: 1778036352.0000 - val_mae: 27714.5605\n",
            "Epoch 730/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2545903104.0000 - mae: 26953.0312 - val_loss: 1777725824.0000 - val_mae: 27703.5527\n",
            "Epoch 731/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2545874432.0000 - mae: 26950.3965 - val_loss: 1776750848.0000 - val_mae: 27691.5254\n",
            "Epoch 732/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2546415872.0000 - mae: 26899.9238 - val_loss: 1777024000.0000 - val_mae: 27704.4160\n",
            "Epoch 733/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2545315840.0000 - mae: 26927.7461 - val_loss: 1776226304.0000 - val_mae: 27692.6797\n",
            "Epoch 734/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2544789248.0000 - mae: 26938.9707 - val_loss: 1775696768.0000 - val_mae: 27676.6445\n",
            "Epoch 735/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2543605760.0000 - mae: 26905.5234 - val_loss: 1775201792.0000 - val_mae: 27676.4688\n",
            "Epoch 736/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2543106560.0000 - mae: 26909.2402 - val_loss: 1774489216.0000 - val_mae: 27666.1016\n",
            "Epoch 737/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2544154880.0000 - mae: 26893.0176 - val_loss: 1774613248.0000 - val_mae: 27667.4570\n",
            "Epoch 738/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2542330112.0000 - mae: 26948.1016 - val_loss: 1774535680.0000 - val_mae: 27656.0527\n",
            "Epoch 739/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2540893952.0000 - mae: 26873.8203 - val_loss: 1775953536.0000 - val_mae: 27691.5059\n",
            "Epoch 740/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2541996544.0000 - mae: 26899.4551 - val_loss: 1775335168.0000 - val_mae: 27684.4941\n",
            "Epoch 741/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2539422720.0000 - mae: 26962.1602 - val_loss: 1773167488.0000 - val_mae: 27650.6270\n",
            "Epoch 742/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2542930944.0000 - mae: 26837.6270 - val_loss: 1772061568.0000 - val_mae: 27642.2480\n",
            "Epoch 743/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2540740608.0000 - mae: 26878.9805 - val_loss: 1772437760.0000 - val_mae: 27646.8906\n",
            "Epoch 744/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2539922176.0000 - mae: 26922.9121 - val_loss: 1772000768.0000 - val_mae: 27646.7324\n",
            "Epoch 745/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2538930944.0000 - mae: 26882.4375 - val_loss: 1773032832.0000 - val_mae: 27669.6465\n",
            "Epoch 746/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2538316544.0000 - mae: 26886.0527 - val_loss: 1773420928.0000 - val_mae: 27677.4941\n",
            "Epoch 747/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2538082816.0000 - mae: 26909.5566 - val_loss: 1773377664.0000 - val_mae: 27669.6406\n",
            "Epoch 748/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2537182720.0000 - mae: 26855.6992 - val_loss: 1775551360.0000 - val_mae: 27700.7129\n",
            "Epoch 749/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2535747840.0000 - mae: 26932.5566 - val_loss: 1772416000.0000 - val_mae: 27670.5449\n",
            "Epoch 750/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2535933440.0000 - mae: 26924.7930 - val_loss: 1773041408.0000 - val_mae: 27663.9980\n",
            "Epoch 751/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2536477440.0000 - mae: 26925.5137 - val_loss: 1774045824.0000 - val_mae: 27669.2070\n",
            "Epoch 752/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2536033792.0000 - mae: 26888.5742 - val_loss: 1773869952.0000 - val_mae: 27657.8574\n",
            "Epoch 753/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 2534350848.0000 - mae: 26883.7520 - val_loss: 1774135552.0000 - val_mae: 27657.5762\n",
            "Epoch 754/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2533877760.0000 - mae: 26912.0312 - val_loss: 1774533248.0000 - val_mae: 27650.3359\n",
            "Epoch 754: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7906343ce380>"
            ]
          },
          "metadata": {},
          "execution_count": 322
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_d.fit(X_train,y_train, validation_data=(X_test, y_test), epochs=2000, batch_size=128,\n",
        "          callbacks=callback_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUxHA4eA3dF3",
        "outputId": "d18452e6-5785-4669-8d77-5fe06424b7b8"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "26/26 [==============================] - 1s 18ms/step - loss: 93255450624.0000 - mae: 281663.1562 - val_loss: 94384078848.0000 - val_mae: 283955.6250\n",
            "Epoch 2/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 93250715648.0000 - mae: 281655.4062 - val_loss: 94377615360.0000 - val_mae: 283945.6875\n",
            "Epoch 3/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 93242441728.0000 - mae: 281642.7188 - val_loss: 94367113216.0000 - val_mae: 283930.0312\n",
            "Epoch 4/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 93230546944.0000 - mae: 281624.7188 - val_loss: 94351876096.0000 - val_mae: 283907.8750\n",
            "Epoch 5/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 93213417472.0000 - mae: 281599.7812 - val_loss: 94330650624.0000 - val_mae: 283877.5625\n",
            "Epoch 6/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 93189136384.0000 - mae: 281564.8125 - val_loss: 94302445568.0000 - val_mae: 283837.7500\n",
            "Epoch 7/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 93159522304.0000 - mae: 281521.6562 - val_loss: 94267015168.0000 - val_mae: 283788.2500\n",
            "Epoch 8/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 93123772416.0000 - mae: 281470.3750 - val_loss: 94223663104.0000 - val_mae: 283728.0625\n",
            "Epoch 9/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 93075021824.0000 - mae: 281402.6875 - val_loss: 94170103808.0000 - val_mae: 283654.3125\n",
            "Epoch 10/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 93018628096.0000 - mae: 281322.0625 - val_loss: 94106255360.0000 - val_mae: 283566.6250\n",
            "Epoch 11/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 92957499392.0000 - mae: 281235.4688 - val_loss: 94032683008.0000 - val_mae: 283466.0000\n",
            "Epoch 12/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 92887564288.0000 - mae: 281138.2500 - val_loss: 93948502016.0000 - val_mae: 283351.0000\n",
            "Epoch 13/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 92807159808.0000 - mae: 281018.9688 - val_loss: 93851009024.0000 - val_mae: 283218.0000\n",
            "Epoch 14/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 92691447808.0000 - mae: 280870.4062 - val_loss: 93740949504.0000 - val_mae: 283068.1562\n",
            "Epoch 15/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 92595232768.0000 - mae: 280725.8125 - val_loss: 93615939584.0000 - val_mae: 282898.5625\n",
            "Epoch 16/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 92485730304.0000 - mae: 280568.1875 - val_loss: 93480665088.0000 - val_mae: 282714.4062\n",
            "Epoch 17/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 92325650432.0000 - mae: 280355.5312 - val_loss: 93324419072.0000 - val_mae: 282502.8125\n",
            "Epoch 18/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 92173058048.0000 - mae: 280144.0312 - val_loss: 93155196928.0000 - val_mae: 282273.5625\n",
            "Epoch 19/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 92004270080.0000 - mae: 279896.2500 - val_loss: 92967321600.0000 - val_mae: 282018.9062\n",
            "Epoch 20/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 91808325632.0000 - mae: 279640.0625 - val_loss: 92758155264.0000 - val_mae: 281736.0625\n",
            "Epoch 21/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 91602763776.0000 - mae: 279362.7500 - val_loss: 92537184256.0000 - val_mae: 281435.9375\n",
            "Epoch 22/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 91402797056.0000 - mae: 279068.4375 - val_loss: 92297691136.0000 - val_mae: 281110.5625\n",
            "Epoch 23/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 91157127168.0000 - mae: 278734.9375 - val_loss: 92037095424.0000 - val_mae: 280756.6250\n",
            "Epoch 24/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 90910613504.0000 - mae: 278381.8125 - val_loss: 91762679808.0000 - val_mae: 280382.7812\n",
            "Epoch 25/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 90667737088.0000 - mae: 278030.8750 - val_loss: 91459870720.0000 - val_mae: 279970.7188\n",
            "Epoch 26/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 90343096320.0000 - mae: 277570.6562 - val_loss: 91136483328.0000 - val_mae: 279528.7500\n",
            "Epoch 27/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 90004783104.0000 - mae: 277136.5312 - val_loss: 90787962880.0000 - val_mae: 279052.9375\n",
            "Epoch 28/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 89690275840.0000 - mae: 276682.5000 - val_loss: 90425597952.0000 - val_mae: 278555.3438\n",
            "Epoch 29/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 89343524864.0000 - mae: 276164.6562 - val_loss: 90032054272.0000 - val_mae: 278015.0312\n",
            "Epoch 30/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 89012043776.0000 - mae: 275677.7188 - val_loss: 89617154048.0000 - val_mae: 277443.0938\n",
            "Epoch 31/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 88544673792.0000 - mae: 275057.5000 - val_loss: 89162235904.0000 - val_mae: 276816.4375\n",
            "Epoch 32/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 88120131584.0000 - mae: 274450.0312 - val_loss: 88701173760.0000 - val_mae: 276177.1875\n",
            "Epoch 33/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 87687946240.0000 - mae: 273788.3125 - val_loss: 88214650880.0000 - val_mae: 275500.5625\n",
            "Epoch 34/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 87095787520.0000 - mae: 273028.5312 - val_loss: 87682392064.0000 - val_mae: 274759.7812\n",
            "Epoch 35/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 86672629760.0000 - mae: 272329.6562 - val_loss: 87143645184.0000 - val_mae: 274004.5312\n",
            "Epoch 36/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 86178832384.0000 - mae: 271647.8750 - val_loss: 86578774016.0000 - val_mae: 273209.6875\n",
            "Epoch 37/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 85530632192.0000 - mae: 270716.7188 - val_loss: 85970075648.0000 - val_mae: 272351.4688\n",
            "Epoch 38/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 84962533376.0000 - mae: 269942.8750 - val_loss: 85336547328.0000 - val_mae: 271453.5000\n",
            "Epoch 39/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 84270645248.0000 - mae: 268971.4688 - val_loss: 84675436544.0000 - val_mae: 270510.6250\n",
            "Epoch 40/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 83777347584.0000 - mae: 268138.9688 - val_loss: 84007723008.0000 - val_mae: 269550.7500\n",
            "Epoch 41/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 83209920512.0000 - mae: 267316.9375 - val_loss: 83297370112.0000 - val_mae: 268525.8438\n",
            "Epoch 42/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 82576318464.0000 - mae: 266260.9062 - val_loss: 82557952000.0000 - val_mae: 267452.4062\n",
            "Epoch 43/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 81835810816.0000 - mae: 265135.3125 - val_loss: 81783627776.0000 - val_mae: 266321.2188\n",
            "Epoch 44/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 80908468224.0000 - mae: 263873.5312 - val_loss: 80984694784.0000 - val_mae: 265145.9375\n",
            "Epoch 45/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 80152469504.0000 - mae: 262775.5000 - val_loss: 80170590208.0000 - val_mae: 263940.2500\n",
            "Epoch 46/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 79563366400.0000 - mae: 261797.3125 - val_loss: 79302680576.0000 - val_mae: 262644.9375\n",
            "Epoch 47/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 78567833600.0000 - mae: 260199.1250 - val_loss: 78449172480.0000 - val_mae: 261357.0469\n",
            "Epoch 48/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 77869252608.0000 - mae: 259219.8750 - val_loss: 77547872256.0000 - val_mae: 259990.0312\n",
            "Epoch 49/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 76975489024.0000 - mae: 257658.7500 - val_loss: 76594339840.0000 - val_mae: 258530.1406\n",
            "Epoch 50/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 76008914944.0000 - mae: 256162.2188 - val_loss: 75627257856.0000 - val_mae: 257036.2031\n",
            "Epoch 51/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 75277885440.0000 - mae: 255149.2344 - val_loss: 74654547968.0000 - val_mae: 255516.8906\n",
            "Epoch 52/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 74101768192.0000 - mae: 253205.2500 - val_loss: 73631186944.0000 - val_mae: 253904.4844\n",
            "Epoch 53/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 73022758912.0000 - mae: 251624.4688 - val_loss: 72581472256.0000 - val_mae: 252230.3594\n",
            "Epoch 54/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 72011612160.0000 - mae: 249895.2031 - val_loss: 71500390400.0000 - val_mae: 250488.1719\n",
            "Epoch 55/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 71084040192.0000 - mae: 248251.4062 - val_loss: 70443778048.0000 - val_mae: 248761.7969\n",
            "Epoch 56/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 70290669568.0000 - mae: 246618.7969 - val_loss: 69340405760.0000 - val_mae: 246938.2344\n",
            "Epoch 57/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 69267218432.0000 - mae: 244750.7188 - val_loss: 68188717056.0000 - val_mae: 245013.8438\n",
            "Epoch 58/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 68114649088.0000 - mae: 243099.9844 - val_loss: 67035832320.0000 - val_mae: 243059.3906\n",
            "Epoch 59/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 67275104256.0000 - mae: 241343.8594 - val_loss: 65877291008.0000 - val_mae: 241063.2031\n",
            "Epoch 60/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 66183745536.0000 - mae: 239097.6406 - val_loss: 64663359488.0000 - val_mae: 238943.0781\n",
            "Epoch 61/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 64729575424.0000 - mae: 236885.4688 - val_loss: 63442919424.0000 - val_mae: 236778.5938\n",
            "Epoch 62/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 63307833344.0000 - mae: 234542.7812 - val_loss: 62212558848.0000 - val_mae: 234562.5469\n",
            "Epoch 63/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 62714466304.0000 - mae: 232884.7344 - val_loss: 60977016832.0000 - val_mae: 232294.3125\n",
            "Epoch 64/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 61406855168.0000 - mae: 230260.7344 - val_loss: 59714715648.0000 - val_mae: 229937.3281\n",
            "Epoch 65/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 60128440320.0000 - mae: 227906.4688 - val_loss: 58447872000.0000 - val_mae: 227527.7812\n",
            "Epoch 66/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 58888200192.0000 - mae: 225960.5469 - val_loss: 57133363200.0000 - val_mae: 224979.4844\n",
            "Epoch 67/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 57952178176.0000 - mae: 223255.3906 - val_loss: 55855230976.0000 - val_mae: 222446.6406\n",
            "Epoch 68/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 56930578432.0000 - mae: 220996.2500 - val_loss: 54574014464.0000 - val_mae: 219855.8125\n",
            "Epoch 69/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 55441911808.0000 - mae: 218494.7031 - val_loss: 53256921088.0000 - val_mae: 217132.4062\n",
            "Epoch 70/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 53968883712.0000 - mae: 215045.7344 - val_loss: 51941388288.0000 - val_mae: 214346.9219\n",
            "Epoch 71/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 52915810304.0000 - mae: 212589.6875 - val_loss: 50641596416.0000 - val_mae: 211523.7344\n",
            "Epoch 72/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 51659014144.0000 - mae: 209476.4375 - val_loss: 49342828544.0000 - val_mae: 208629.7344\n",
            "Epoch 73/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 50468061184.0000 - mae: 206920.2500 - val_loss: 48032043008.0000 - val_mae: 205629.7031\n",
            "Epoch 74/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 49717698560.0000 - mae: 204228.6562 - val_loss: 46734090240.0000 - val_mae: 202573.7812\n",
            "Epoch 75/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 48330371072.0000 - mae: 201036.4844 - val_loss: 45438889984.0000 - val_mae: 199429.3125\n",
            "Epoch 76/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 46919049216.0000 - mae: 198359.7344 - val_loss: 44182446080.0000 - val_mae: 196286.5781\n",
            "Epoch 77/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 46109253632.0000 - mae: 196074.1875 - val_loss: 42930524160.0000 - val_mae: 193053.9688\n",
            "Epoch 78/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 44721684480.0000 - mae: 192730.4688 - val_loss: 41692188672.0000 - val_mae: 189788.1875\n",
            "Epoch 79/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 43701207040.0000 - mae: 189350.7344 - val_loss: 40492285952.0000 - val_mae: 186541.3750\n",
            "Epoch 80/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 42739417088.0000 - mae: 186604.2969 - val_loss: 39299432448.0000 - val_mae: 183211.8125\n",
            "Epoch 81/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 41703960576.0000 - mae: 184454.7188 - val_loss: 38143139840.0000 - val_mae: 179861.9375\n",
            "Epoch 82/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 41072967680.0000 - mae: 182012.1719 - val_loss: 37014073344.0000 - val_mae: 176508.5000\n",
            "Epoch 83/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 39346688000.0000 - mae: 177383.5156 - val_loss: 35906924544.0000 - val_mae: 173144.4219\n",
            "Epoch 84/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 38723489792.0000 - mae: 175964.9375 - val_loss: 34824273920.0000 - val_mae: 169747.3125\n",
            "Epoch 85/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 38051827712.0000 - mae: 173034.1094 - val_loss: 33817468928.0000 - val_mae: 166542.1250\n",
            "Epoch 86/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 37269725184.0000 - mae: 170070.8594 - val_loss: 32821827584.0000 - val_mae: 163356.4844\n",
            "Epoch 87/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 36136554496.0000 - mae: 168273.1719 - val_loss: 31873667072.0000 - val_mae: 160323.7188\n",
            "Epoch 88/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 35658334208.0000 - mae: 165849.0469 - val_loss: 31060666368.0000 - val_mae: 157660.8438\n",
            "Epoch 89/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 34784014336.0000 - mae: 164506.7031 - val_loss: 30188802048.0000 - val_mae: 154778.1406\n",
            "Epoch 90/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 33952206848.0000 - mae: 161185.3594 - val_loss: 29391656960.0000 - val_mae: 152202.6719\n",
            "Epoch 91/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 33123844096.0000 - mae: 159533.2812 - val_loss: 28647690240.0000 - val_mae: 149909.7969\n",
            "Epoch 92/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 33142759424.0000 - mae: 158562.0156 - val_loss: 27969988608.0000 - val_mae: 147798.0781\n",
            "Epoch 93/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 32827875328.0000 - mae: 157309.2500 - val_loss: 27314483200.0000 - val_mae: 145740.3594\n",
            "Epoch 94/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 32110249984.0000 - mae: 155888.1875 - val_loss: 26721912832.0000 - val_mae: 143885.9844\n",
            "Epoch 95/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 31381764096.0000 - mae: 153996.2500 - val_loss: 26190587904.0000 - val_mae: 142238.6875\n",
            "Epoch 96/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 31269396480.0000 - mae: 153577.0781 - val_loss: 25682466816.0000 - val_mae: 140686.3906\n",
            "Epoch 97/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 30568689664.0000 - mae: 151155.4688 - val_loss: 25226223616.0000 - val_mae: 139333.1406\n",
            "Epoch 98/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 30640752640.0000 - mae: 151127.7812 - val_loss: 24836474880.0000 - val_mae: 138159.5938\n",
            "Epoch 99/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 30560948224.0000 - mae: 151300.5312 - val_loss: 24459530240.0000 - val_mae: 137007.7344\n",
            "Epoch 100/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 30796417024.0000 - mae: 150467.2969 - val_loss: 24108269568.0000 - val_mae: 135955.3750\n",
            "Epoch 101/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 30040311808.0000 - mae: 148363.6094 - val_loss: 23716534272.0000 - val_mae: 134771.6562\n",
            "Epoch 102/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 29265598464.0000 - mae: 147200.9219 - val_loss: 23412627456.0000 - val_mae: 133822.5625\n",
            "Epoch 103/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 28259874816.0000 - mae: 145380.0625 - val_loss: 23066525696.0000 - val_mae: 132724.6719\n",
            "Epoch 104/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 28568139776.0000 - mae: 146053.0469 - val_loss: 22788265984.0000 - val_mae: 131848.3281\n",
            "Epoch 105/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 28807854080.0000 - mae: 146267.6094 - val_loss: 22486562816.0000 - val_mae: 130886.6562\n",
            "Epoch 106/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 28393095168.0000 - mae: 145172.4844 - val_loss: 22197858304.0000 - val_mae: 129963.3594\n",
            "Epoch 107/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 28317237248.0000 - mae: 144473.7969 - val_loss: 21924777984.0000 - val_mae: 129088.3828\n",
            "Epoch 108/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 27314231296.0000 - mae: 142323.4531 - val_loss: 21611378688.0000 - val_mae: 128079.5781\n",
            "Epoch 109/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 26979020800.0000 - mae: 141315.1094 - val_loss: 21300852736.0000 - val_mae: 127062.8047\n",
            "Epoch 110/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 27087130624.0000 - mae: 140391.7500 - val_loss: 20991217664.0000 - val_mae: 126042.7422\n",
            "Epoch 111/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 26576822272.0000 - mae: 139042.3906 - val_loss: 20687892480.0000 - val_mae: 125032.4375\n",
            "Epoch 112/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 27255750656.0000 - mae: 139270.3281 - val_loss: 20423731200.0000 - val_mae: 124158.9453\n",
            "Epoch 113/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 25855547392.0000 - mae: 137797.0312 - val_loss: 20131424256.0000 - val_mae: 123176.7188\n",
            "Epoch 114/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 25824368640.0000 - mae: 137118.9062 - val_loss: 19831939072.0000 - val_mae: 122161.3516\n",
            "Epoch 115/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 25530492928.0000 - mae: 135918.2500 - val_loss: 19525173248.0000 - val_mae: 121114.1094\n",
            "Epoch 116/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 25415854080.0000 - mae: 135279.1875 - val_loss: 19251499008.0000 - val_mae: 120167.0547\n",
            "Epoch 117/2000\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 25152501760.0000 - mae: 134053.9844 - val_loss: 18948151296.0000 - val_mae: 119113.3203\n",
            "Epoch 118/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 24526235648.0000 - mae: 133453.0312 - val_loss: 18658932736.0000 - val_mae: 118093.9062\n",
            "Epoch 119/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 24610709504.0000 - mae: 132953.9688 - val_loss: 18347145216.0000 - val_mae: 116990.2266\n",
            "Epoch 120/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 24219168768.0000 - mae: 130814.8906 - val_loss: 18055047168.0000 - val_mae: 115938.6797\n",
            "Epoch 121/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 23793176576.0000 - mae: 130275.8516 - val_loss: 17768859648.0000 - val_mae: 114905.7109\n",
            "Epoch 122/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 23157098496.0000 - mae: 128562.7031 - val_loss: 17443282944.0000 - val_mae: 113711.5547\n",
            "Epoch 123/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 23290603520.0000 - mae: 128338.7266 - val_loss: 17159348224.0000 - val_mae: 112667.5703\n",
            "Epoch 124/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 23049637888.0000 - mae: 127851.8125 - val_loss: 16871525376.0000 - val_mae: 111596.1484\n",
            "Epoch 125/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 23172794368.0000 - mae: 126545.3047 - val_loss: 16557316096.0000 - val_mae: 110433.0234\n",
            "Epoch 126/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 22344050688.0000 - mae: 125943.8047 - val_loss: 16268729344.0000 - val_mae: 109353.7109\n",
            "Epoch 127/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 22006306816.0000 - mae: 123593.7891 - val_loss: 15981033472.0000 - val_mae: 108264.6406\n",
            "Epoch 128/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 21404768256.0000 - mae: 123375.2500 - val_loss: 15671130112.0000 - val_mae: 107084.9844\n",
            "Epoch 129/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 21315004416.0000 - mae: 123203.7109 - val_loss: 15379869696.0000 - val_mae: 105972.1719\n",
            "Epoch 130/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 21262303232.0000 - mae: 121188.7188 - val_loss: 15078313984.0000 - val_mae: 104805.9375\n",
            "Epoch 131/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 21286578176.0000 - mae: 120055.0469 - val_loss: 14787365888.0000 - val_mae: 103677.3125\n",
            "Epoch 132/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 20895199232.0000 - mae: 118477.4531 - val_loss: 14512697344.0000 - val_mae: 102600.0156\n",
            "Epoch 133/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 20476063744.0000 - mae: 118823.3750 - val_loss: 14191249408.0000 - val_mae: 101311.1719\n",
            "Epoch 134/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 20034795520.0000 - mae: 117458.1484 - val_loss: 13890667520.0000 - val_mae: 100114.2656\n",
            "Epoch 135/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 19997241344.0000 - mae: 116063.7500 - val_loss: 13604659200.0000 - val_mae: 98948.7812\n",
            "Epoch 136/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 19544590336.0000 - mae: 114890.8359 - val_loss: 13316660224.0000 - val_mae: 97770.7969\n",
            "Epoch 137/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 19491192832.0000 - mae: 113996.7656 - val_loss: 13029851136.0000 - val_mae: 96576.9922\n",
            "Epoch 138/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 19691261952.0000 - mae: 114576.1719 - val_loss: 12768863232.0000 - val_mae: 95486.8203\n",
            "Epoch 139/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 18132400128.0000 - mae: 110753.4922 - val_loss: 12468727808.0000 - val_mae: 94215.9062\n",
            "Epoch 140/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 18420709376.0000 - mae: 110433.3203 - val_loss: 12187447296.0000 - val_mae: 93004.9062\n",
            "Epoch 141/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 17468985344.0000 - mae: 108184.5859 - val_loss: 11885245440.0000 - val_mae: 91682.6016\n",
            "Epoch 142/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 17863477248.0000 - mae: 107422.8984 - val_loss: 11594661888.0000 - val_mae: 90391.5703\n",
            "Epoch 143/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 17543987200.0000 - mae: 107643.3125 - val_loss: 11326891008.0000 - val_mae: 89187.8125\n",
            "Epoch 144/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 17378439168.0000 - mae: 107022.0703 - val_loss: 11057913856.0000 - val_mae: 87961.8203\n",
            "Epoch 145/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 16765983744.0000 - mae: 104999.7734 - val_loss: 10781245440.0000 - val_mae: 86682.3672\n",
            "Epoch 146/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 16403548160.0000 - mae: 103435.4609 - val_loss: 10536085504.0000 - val_mae: 85529.5547\n",
            "Epoch 147/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 16980551680.0000 - mae: 104092.2891 - val_loss: 10302746624.0000 - val_mae: 84421.2422\n",
            "Epoch 148/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 16269218816.0000 - mae: 101578.8906 - val_loss: 10019559424.0000 - val_mae: 83093.2344\n",
            "Epoch 149/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 16651210752.0000 - mae: 101697.7734 - val_loss: 9780020224.0000 - val_mae: 81942.6797\n",
            "Epoch 150/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 16003272704.0000 - mae: 100313.9141 - val_loss: 9536161792.0000 - val_mae: 80770.3828\n",
            "Epoch 151/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 16061484032.0000 - mae: 100153.3359 - val_loss: 9319406592.0000 - val_mae: 79703.8047\n",
            "Epoch 152/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 15585871872.0000 - mae: 97995.0156 - val_loss: 9091320832.0000 - val_mae: 78581.6953\n",
            "Epoch 153/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 15216967680.0000 - mae: 98024.2344 - val_loss: 8838337536.0000 - val_mae: 77332.3359\n",
            "Epoch 154/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 15182231552.0000 - mae: 95911.9141 - val_loss: 8628467712.0000 - val_mae: 76266.3828\n",
            "Epoch 155/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 14906944512.0000 - mae: 95312.7031 - val_loss: 8410759680.0000 - val_mae: 75173.2812\n",
            "Epoch 156/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 14401725440.0000 - mae: 95103.6875 - val_loss: 8172991488.0000 - val_mae: 73979.6562\n",
            "Epoch 157/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 14403375104.0000 - mae: 93949.7188 - val_loss: 7966818816.0000 - val_mae: 72919.2031\n",
            "Epoch 158/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 14130765824.0000 - mae: 93235.1328 - val_loss: 7767635456.0000 - val_mae: 71888.4453\n",
            "Epoch 159/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 14015555584.0000 - mae: 91911.0156 - val_loss: 7563311104.0000 - val_mae: 70832.4688\n",
            "Epoch 160/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 13670423552.0000 - mae: 90948.8203 - val_loss: 7368701952.0000 - val_mae: 69809.7500\n",
            "Epoch 161/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 13418498048.0000 - mae: 91034.1328 - val_loss: 7190903808.0000 - val_mae: 68866.6484\n",
            "Epoch 162/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 13621784576.0000 - mae: 89738.8594 - val_loss: 7011705344.0000 - val_mae: 67910.0156\n",
            "Epoch 163/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 13142573056.0000 - mae: 88767.0391 - val_loss: 6853530112.0000 - val_mae: 67032.8594\n",
            "Epoch 164/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 12602568704.0000 - mae: 87078.4844 - val_loss: 6682131456.0000 - val_mae: 66102.8594\n",
            "Epoch 165/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 13526426624.0000 - mae: 89024.5703 - val_loss: 6583364608.0000 - val_mae: 65534.0664\n",
            "Epoch 166/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 13142134784.0000 - mae: 87460.6094 - val_loss: 6420531712.0000 - val_mae: 64622.9922\n",
            "Epoch 167/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 12025490432.0000 - mae: 84108.1250 - val_loss: 6265177600.0000 - val_mae: 63742.9453\n",
            "Epoch 168/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 12372681728.0000 - mae: 85141.3906 - val_loss: 6125863424.0000 - val_mae: 62942.6133\n",
            "Epoch 169/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 13275747328.0000 - mae: 87421.8125 - val_loss: 6025087488.0000 - val_mae: 62307.8242\n",
            "Epoch 170/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 12337486848.0000 - mae: 85253.3359 - val_loss: 5893177856.0000 - val_mae: 61526.6914\n",
            "Epoch 171/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 12929585152.0000 - mae: 85389.7812 - val_loss: 5786380800.0000 - val_mae: 60862.4609\n",
            "Epoch 172/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 11644142592.0000 - mae: 82976.7266 - val_loss: 5650955264.0000 - val_mae: 60044.4375\n",
            "Epoch 173/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 11958494208.0000 - mae: 82320.6641 - val_loss: 5545929728.0000 - val_mae: 59373.7383\n",
            "Epoch 174/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 11894671360.0000 - mae: 83259.5391 - val_loss: 5457142272.0000 - val_mae: 58788.8789\n",
            "Epoch 175/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 11182425088.0000 - mae: 80407.0547 - val_loss: 5375341056.0000 - val_mae: 58252.5781\n",
            "Epoch 176/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 11836399616.0000 - mae: 82844.4062 - val_loss: 5274067456.0000 - val_mae: 57576.3398\n",
            "Epoch 177/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 11803128832.0000 - mae: 80565.5000 - val_loss: 5201584640.0000 - val_mae: 57087.2148\n",
            "Epoch 178/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 11690289152.0000 - mae: 80935.5156 - val_loss: 5121722880.0000 - val_mae: 56552.4609\n",
            "Epoch 179/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 12322326528.0000 - mae: 83439.2812 - val_loss: 5051969024.0000 - val_mae: 56071.2891\n",
            "Epoch 180/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 11004464128.0000 - mae: 79334.4531 - val_loss: 4931493376.0000 - val_mae: 55282.3008\n",
            "Epoch 181/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 12303885312.0000 - mae: 80801.1641 - val_loss: 4844608000.0000 - val_mae: 54700.1211\n",
            "Epoch 182/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 11084071936.0000 - mae: 79264.9062 - val_loss: 4752171520.0000 - val_mae: 54077.4805\n",
            "Epoch 183/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 11760736256.0000 - mae: 80923.7578 - val_loss: 4705711104.0000 - val_mae: 53716.5391\n",
            "Epoch 184/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 11167349760.0000 - mae: 79219.7344 - val_loss: 4656590848.0000 - val_mae: 53341.7578\n",
            "Epoch 185/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 11277300736.0000 - mae: 77639.3750 - val_loss: 4580411392.0000 - val_mae: 52789.3477\n",
            "Epoch 186/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 10972080128.0000 - mae: 78442.1875 - val_loss: 4499004928.0000 - val_mae: 52191.0703\n",
            "Epoch 187/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 11231543296.0000 - mae: 76969.1016 - val_loss: 4430467072.0000 - val_mae: 51696.6328\n",
            "Epoch 188/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 11133209600.0000 - mae: 77491.0391 - val_loss: 4376818688.0000 - val_mae: 51293.6172\n",
            "Epoch 189/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 10538324992.0000 - mae: 76645.3516 - val_loss: 4329500672.0000 - val_mae: 50928.5352\n",
            "Epoch 190/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 10896573440.0000 - mae: 77076.2891 - val_loss: 4269305344.0000 - val_mae: 50478.5820\n",
            "Epoch 191/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 10543705088.0000 - mae: 76265.1406 - val_loss: 4194008064.0000 - val_mae: 49930.0195\n",
            "Epoch 192/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 10649697280.0000 - mae: 76607.1484 - val_loss: 4154291968.0000 - val_mae: 49593.1094\n",
            "Epoch 193/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 10960200704.0000 - mae: 77200.0547 - val_loss: 4108453120.0000 - val_mae: 49254.0586\n",
            "Epoch 194/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 11108955136.0000 - mae: 77270.9219 - val_loss: 4079664896.0000 - val_mae: 49005.8008\n",
            "Epoch 195/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 10907609088.0000 - mae: 76632.6797 - val_loss: 4058458624.0000 - val_mae: 48808.2227\n",
            "Epoch 196/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 10336875520.0000 - mae: 76680.9766 - val_loss: 4007166720.0000 - val_mae: 48405.3867\n",
            "Epoch 197/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 10569290752.0000 - mae: 76193.1016 - val_loss: 3960478464.0000 - val_mae: 48053.9062\n",
            "Epoch 198/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9844568064.0000 - mae: 73080.0000 - val_loss: 3895586048.0000 - val_mae: 47573.0469\n",
            "Epoch 199/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 10339606528.0000 - mae: 75754.2266 - val_loss: 3848267264.0000 - val_mae: 47177.4727\n",
            "Epoch 200/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 10368025600.0000 - mae: 74708.6797 - val_loss: 3827940608.0000 - val_mae: 46973.2344\n",
            "Epoch 201/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 10541592576.0000 - mae: 74416.5703 - val_loss: 3748388864.0000 - val_mae: 46390.5898\n",
            "Epoch 202/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 10545018880.0000 - mae: 76161.6875 - val_loss: 3699140352.0000 - val_mae: 45999.3516\n",
            "Epoch 203/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9849337856.0000 - mae: 72688.7031 - val_loss: 3686503424.0000 - val_mae: 45840.3711\n",
            "Epoch 204/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 10480410624.0000 - mae: 74503.9922 - val_loss: 3649097984.0000 - val_mae: 45524.1211\n",
            "Epoch 205/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 10619301888.0000 - mae: 74984.4062 - val_loss: 3639376384.0000 - val_mae: 45396.5273\n",
            "Epoch 206/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9962311680.0000 - mae: 73219.3594 - val_loss: 3618118400.0000 - val_mae: 45152.6797\n",
            "Epoch 207/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 10528578560.0000 - mae: 73440.2266 - val_loss: 3586529536.0000 - val_mae: 44883.6641\n",
            "Epoch 208/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 10218275840.0000 - mae: 73602.1719 - val_loss: 3543918336.0000 - val_mae: 44544.2500\n",
            "Epoch 209/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 11161381888.0000 - mae: 75272.9688 - val_loss: 3503235072.0000 - val_mae: 44219.9961\n",
            "Epoch 210/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 10371640320.0000 - mae: 73162.3047 - val_loss: 3472178944.0000 - val_mae: 43926.9141\n",
            "Epoch 211/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 9845529600.0000 - mae: 72755.0547 - val_loss: 3453370880.0000 - val_mae: 43719.6211\n",
            "Epoch 212/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9910872064.0000 - mae: 73327.5859 - val_loss: 3410882560.0000 - val_mae: 43378.7695\n",
            "Epoch 213/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9408391168.0000 - mae: 71005.5156 - val_loss: 3377224448.0000 - val_mae: 43076.8711\n",
            "Epoch 214/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 9796350976.0000 - mae: 72179.0000 - val_loss: 3352380160.0000 - val_mae: 42846.9453\n",
            "Epoch 215/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 10009409536.0000 - mae: 72234.6328 - val_loss: 3335776000.0000 - val_mae: 42641.8281\n",
            "Epoch 216/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 10153887744.0000 - mae: 72901.3125 - val_loss: 3321426432.0000 - val_mae: 42495.4609\n",
            "Epoch 217/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 9428824064.0000 - mae: 72497.2031 - val_loss: 3290021888.0000 - val_mae: 42244.8281\n",
            "Epoch 218/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 10061648896.0000 - mae: 72368.3906 - val_loss: 3277100032.0000 - val_mae: 42114.8672\n",
            "Epoch 219/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 8954477568.0000 - mae: 70601.6172 - val_loss: 3254935808.0000 - val_mae: 41902.0391\n",
            "Epoch 220/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 9864549376.0000 - mae: 71813.6016 - val_loss: 3252434432.0000 - val_mae: 41852.8477\n",
            "Epoch 221/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9385929728.0000 - mae: 70999.9297 - val_loss: 3210015232.0000 - val_mae: 41539.9844\n",
            "Epoch 222/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9785781248.0000 - mae: 71053.6719 - val_loss: 3205913856.0000 - val_mae: 41423.5898\n",
            "Epoch 223/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9746822144.0000 - mae: 71683.1641 - val_loss: 3153012736.0000 - val_mae: 41038.6992\n",
            "Epoch 224/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 9895204864.0000 - mae: 71975.4531 - val_loss: 3114419456.0000 - val_mae: 40739.5273\n",
            "Epoch 225/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9614202880.0000 - mae: 70328.9844 - val_loss: 3106900480.0000 - val_mae: 40649.4219\n",
            "Epoch 226/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9423657984.0000 - mae: 69896.0859 - val_loss: 3078950400.0000 - val_mae: 40437.5977\n",
            "Epoch 227/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 9406824448.0000 - mae: 70846.8203 - val_loss: 3057579008.0000 - val_mae: 40275.5078\n",
            "Epoch 228/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 9525857280.0000 - mae: 71302.4453 - val_loss: 3057804544.0000 - val_mae: 40215.5312\n",
            "Epoch 229/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 10021439488.0000 - mae: 71329.1250 - val_loss: 3061211392.0000 - val_mae: 40176.9180\n",
            "Epoch 230/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9442236416.0000 - mae: 70408.5703 - val_loss: 3042214400.0000 - val_mae: 39992.1484\n",
            "Epoch 231/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 9415590912.0000 - mae: 70286.3047 - val_loss: 3019745280.0000 - val_mae: 39793.5000\n",
            "Epoch 232/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9639809024.0000 - mae: 70537.0547 - val_loss: 3011825152.0000 - val_mae: 39703.4414\n",
            "Epoch 233/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 10010025984.0000 - mae: 70453.9844 - val_loss: 3021886976.0000 - val_mae: 39713.5977\n",
            "Epoch 234/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 9978405888.0000 - mae: 70483.0703 - val_loss: 2973253632.0000 - val_mae: 39366.9922\n",
            "Epoch 235/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 9563277312.0000 - mae: 70469.1641 - val_loss: 2978885888.0000 - val_mae: 39365.5391\n",
            "Epoch 236/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9756733440.0000 - mae: 70727.9609 - val_loss: 2940198144.0000 - val_mae: 39069.1406\n",
            "Epoch 237/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9884278784.0000 - mae: 70574.3906 - val_loss: 2946344192.0000 - val_mae: 39061.1914\n",
            "Epoch 238/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9225171968.0000 - mae: 70035.9062 - val_loss: 2955404544.0000 - val_mae: 39077.1953\n",
            "Epoch 239/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9677110272.0000 - mae: 71335.6406 - val_loss: 2951226368.0000 - val_mae: 39010.6406\n",
            "Epoch 240/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 9440575488.0000 - mae: 70434.3828 - val_loss: 2949293824.0000 - val_mae: 38971.1016\n",
            "Epoch 241/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 10030521344.0000 - mae: 72691.1172 - val_loss: 2949546752.0000 - val_mae: 38948.3359\n",
            "Epoch 242/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9425633280.0000 - mae: 69745.8203 - val_loss: 2938136320.0000 - val_mae: 38842.0352\n",
            "Epoch 243/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9794592768.0000 - mae: 70970.5234 - val_loss: 2918111232.0000 - val_mae: 38665.8398\n",
            "Epoch 244/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9678508032.0000 - mae: 69320.4141 - val_loss: 2865160960.0000 - val_mae: 38298.4492\n",
            "Epoch 245/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9137938432.0000 - mae: 69569.4531 - val_loss: 2831523328.0000 - val_mae: 38069.1875\n",
            "Epoch 246/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 9141390336.0000 - mae: 69014.0703 - val_loss: 2814561792.0000 - val_mae: 37894.6133\n",
            "Epoch 247/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9956028416.0000 - mae: 70046.6094 - val_loss: 2825807616.0000 - val_mae: 37938.6992\n",
            "Epoch 248/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9160451072.0000 - mae: 69407.1406 - val_loss: 2818683648.0000 - val_mae: 37869.0898\n",
            "Epoch 249/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9315675136.0000 - mae: 69100.9531 - val_loss: 2802718976.0000 - val_mae: 37727.3672\n",
            "Epoch 250/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9021285376.0000 - mae: 69161.4531 - val_loss: 2812736768.0000 - val_mae: 37745.0977\n",
            "Epoch 251/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9167381504.0000 - mae: 69255.2422 - val_loss: 2818062080.0000 - val_mae: 37709.6562\n",
            "Epoch 252/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 9649054720.0000 - mae: 70414.6719 - val_loss: 2797459456.0000 - val_mae: 37512.5391\n",
            "Epoch 253/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9981421568.0000 - mae: 70013.9453 - val_loss: 2803886592.0000 - val_mae: 37539.1992\n",
            "Epoch 254/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9219224576.0000 - mae: 68346.5156 - val_loss: 2777170432.0000 - val_mae: 37293.3438\n",
            "Epoch 255/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9190606848.0000 - mae: 70084.2344 - val_loss: 2767713792.0000 - val_mae: 37219.1289\n",
            "Epoch 256/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 8945933312.0000 - mae: 68658.9766 - val_loss: 2772110080.0000 - val_mae: 37200.2109\n",
            "Epoch 257/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9204085760.0000 - mae: 69317.9219 - val_loss: 2738747904.0000 - val_mae: 36935.7188\n",
            "Epoch 258/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9217018880.0000 - mae: 68711.0469 - val_loss: 2710112256.0000 - val_mae: 36722.4727\n",
            "Epoch 259/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 9459691520.0000 - mae: 69890.3828 - val_loss: 2711760128.0000 - val_mae: 36697.0078\n",
            "Epoch 260/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9647544320.0000 - mae: 69094.8906 - val_loss: 2725459200.0000 - val_mae: 36732.2148\n",
            "Epoch 261/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8981153792.0000 - mae: 68447.5000 - val_loss: 2687806208.0000 - val_mae: 36404.8242\n",
            "Epoch 262/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8866494464.0000 - mae: 67409.5000 - val_loss: 2688626944.0000 - val_mae: 36366.3086\n",
            "Epoch 263/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9421626368.0000 - mae: 68891.5156 - val_loss: 2695194112.0000 - val_mae: 36393.2109\n",
            "Epoch 264/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9522057216.0000 - mae: 68791.4609 - val_loss: 2685629184.0000 - val_mae: 36297.5039\n",
            "Epoch 265/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9462019072.0000 - mae: 68880.4297 - val_loss: 2674076160.0000 - val_mae: 36202.7891\n",
            "Epoch 266/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 9127298048.0000 - mae: 67579.6875 - val_loss: 2658743040.0000 - val_mae: 36099.5664\n",
            "Epoch 267/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9124643840.0000 - mae: 68709.5938 - val_loss: 2634778624.0000 - val_mae: 35894.8555\n",
            "Epoch 268/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9356224512.0000 - mae: 69522.4453 - val_loss: 2643799296.0000 - val_mae: 35961.2148\n",
            "Epoch 269/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9125540864.0000 - mae: 68062.6016 - val_loss: 2627768576.0000 - val_mae: 35834.1289\n",
            "Epoch 270/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9065039872.0000 - mae: 68833.4453 - val_loss: 2610763264.0000 - val_mae: 35686.4453\n",
            "Epoch 271/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8918844416.0000 - mae: 66754.6797 - val_loss: 2601398784.0000 - val_mae: 35615.7812\n",
            "Epoch 272/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8844946432.0000 - mae: 67940.7969 - val_loss: 2588077568.0000 - val_mae: 35509.0273\n",
            "Epoch 273/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9094362112.0000 - mae: 68934.2578 - val_loss: 2582421760.0000 - val_mae: 35473.2305\n",
            "Epoch 274/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9391992832.0000 - mae: 67961.0781 - val_loss: 2583027968.0000 - val_mae: 35440.0977\n",
            "Epoch 275/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9455397888.0000 - mae: 68712.5625 - val_loss: 2563298048.0000 - val_mae: 35276.5586\n",
            "Epoch 276/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 8873641984.0000 - mae: 67737.4375 - val_loss: 2574859776.0000 - val_mae: 35319.6680\n",
            "Epoch 277/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8769384448.0000 - mae: 66935.8359 - val_loss: 2548564992.0000 - val_mae: 35137.5430\n",
            "Epoch 278/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9153858560.0000 - mae: 68157.8750 - val_loss: 2574953728.0000 - val_mae: 35267.8789\n",
            "Epoch 279/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9344481280.0000 - mae: 67981.8984 - val_loss: 2559012352.0000 - val_mae: 35132.6875\n",
            "Epoch 280/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9262945280.0000 - mae: 68485.1562 - val_loss: 2576193280.0000 - val_mae: 35244.8086\n",
            "Epoch 281/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9274275840.0000 - mae: 68038.5469 - val_loss: 2553508096.0000 - val_mae: 35053.6562\n",
            "Epoch 282/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9010866176.0000 - mae: 68534.1016 - val_loss: 2552257280.0000 - val_mae: 34984.6992\n",
            "Epoch 283/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8650288128.0000 - mae: 66959.0156 - val_loss: 2524870656.0000 - val_mae: 34791.5508\n",
            "Epoch 284/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8888499200.0000 - mae: 67440.6562 - val_loss: 2506673664.0000 - val_mae: 34637.7031\n",
            "Epoch 285/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 9404739584.0000 - mae: 67972.3906 - val_loss: 2503093504.0000 - val_mae: 34624.8984\n",
            "Epoch 286/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9403987968.0000 - mae: 68641.8984 - val_loss: 2495466496.0000 - val_mae: 34591.4062\n",
            "Epoch 287/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9394395136.0000 - mae: 69392.7500 - val_loss: 2513825280.0000 - val_mae: 34719.2422\n",
            "Epoch 288/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9237330944.0000 - mae: 67902.2422 - val_loss: 2499852288.0000 - val_mae: 34630.5703\n",
            "Epoch 289/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9511753728.0000 - mae: 68474.3828 - val_loss: 2501078784.0000 - val_mae: 34591.1172\n",
            "Epoch 290/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9527454720.0000 - mae: 68023.3984 - val_loss: 2494903296.0000 - val_mae: 34559.4844\n",
            "Epoch 291/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9360656384.0000 - mae: 68282.8047 - val_loss: 2500913920.0000 - val_mae: 34604.2695\n",
            "Epoch 292/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9201731584.0000 - mae: 66777.9922 - val_loss: 2510074624.0000 - val_mae: 34645.3867\n",
            "Epoch 293/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8907789312.0000 - mae: 67396.8672 - val_loss: 2513547264.0000 - val_mae: 34676.8945\n",
            "Epoch 294/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9544683520.0000 - mae: 69227.7969 - val_loss: 2501766400.0000 - val_mae: 34605.5156\n",
            "Epoch 295/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9346315264.0000 - mae: 68483.6562 - val_loss: 2463683584.0000 - val_mae: 34288.7148\n",
            "Epoch 296/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9197370368.0000 - mae: 68337.2344 - val_loss: 2456725504.0000 - val_mae: 34251.0859\n",
            "Epoch 297/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8752651264.0000 - mae: 67299.8281 - val_loss: 2449169408.0000 - val_mae: 34166.3867\n",
            "Epoch 298/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9507552256.0000 - mae: 69942.1094 - val_loss: 2466658560.0000 - val_mae: 34271.6523\n",
            "Epoch 299/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8835144704.0000 - mae: 65651.1250 - val_loss: 2462098432.0000 - val_mae: 34244.1680\n",
            "Epoch 300/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8728091648.0000 - mae: 67914.3672 - val_loss: 2463620352.0000 - val_mae: 34250.9141\n",
            "Epoch 301/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8674134016.0000 - mae: 66699.3984 - val_loss: 2445380864.0000 - val_mae: 34106.7891\n",
            "Epoch 302/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9618480128.0000 - mae: 69521.3203 - val_loss: 2482082816.0000 - val_mae: 34344.7852\n",
            "Epoch 303/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9224427520.0000 - mae: 66805.1797 - val_loss: 2457082880.0000 - val_mae: 34162.7852\n",
            "Epoch 304/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9304298496.0000 - mae: 68422.9453 - val_loss: 2433581568.0000 - val_mae: 33997.7461\n",
            "Epoch 305/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8765588480.0000 - mae: 66878.0859 - val_loss: 2435118080.0000 - val_mae: 33959.5117\n",
            "Epoch 306/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8621257728.0000 - mae: 66555.7500 - val_loss: 2419012096.0000 - val_mae: 33822.6797\n",
            "Epoch 307/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9985976320.0000 - mae: 68969.6719 - val_loss: 2451580928.0000 - val_mae: 34032.7695\n",
            "Epoch 308/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9084122112.0000 - mae: 66971.4922 - val_loss: 2456013568.0000 - val_mae: 34046.4492\n",
            "Epoch 309/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9279238144.0000 - mae: 67100.7344 - val_loss: 2439863808.0000 - val_mae: 33952.7773\n",
            "Epoch 310/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9768937472.0000 - mae: 67784.7969 - val_loss: 2409824512.0000 - val_mae: 33716.1641\n",
            "Epoch 311/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9222183936.0000 - mae: 68388.4531 - val_loss: 2409801984.0000 - val_mae: 33694.6562\n",
            "Epoch 312/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9096113152.0000 - mae: 67369.7891 - val_loss: 2413187584.0000 - val_mae: 33720.6680\n",
            "Epoch 313/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9040432128.0000 - mae: 66812.7969 - val_loss: 2438649856.0000 - val_mae: 33867.3711\n",
            "Epoch 314/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8299989504.0000 - mae: 65902.3438 - val_loss: 2409700352.0000 - val_mae: 33651.9258\n",
            "Epoch 315/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 9307389952.0000 - mae: 67131.5547 - val_loss: 2436363264.0000 - val_mae: 33869.4805\n",
            "Epoch 316/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8945142784.0000 - mae: 66725.7578 - val_loss: 2396742400.0000 - val_mae: 33566.5977\n",
            "Epoch 317/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9213905920.0000 - mae: 67415.5078 - val_loss: 2401516288.0000 - val_mae: 33594.0391\n",
            "Epoch 318/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 9282836480.0000 - mae: 67887.5391 - val_loss: 2438150144.0000 - val_mae: 33882.7891\n",
            "Epoch 319/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 8374636032.0000 - mae: 66881.5312 - val_loss: 2394813696.0000 - val_mae: 33609.1250\n",
            "Epoch 320/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 9375397888.0000 - mae: 67114.1719 - val_loss: 2419240960.0000 - val_mae: 33769.8984\n",
            "Epoch 321/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9205945344.0000 - mae: 68392.4453 - val_loss: 2418880512.0000 - val_mae: 33751.6719\n",
            "Epoch 322/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9719244800.0000 - mae: 68324.6875 - val_loss: 2426597888.0000 - val_mae: 33820.4570\n",
            "Epoch 323/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 9464796160.0000 - mae: 68412.6406 - val_loss: 2392490496.0000 - val_mae: 33575.8438\n",
            "Epoch 324/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 8628977664.0000 - mae: 66601.5312 - val_loss: 2378323456.0000 - val_mae: 33465.2539\n",
            "Epoch 325/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8424446976.0000 - mae: 65929.9375 - val_loss: 2413232384.0000 - val_mae: 33703.7070\n",
            "Epoch 326/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 8966081536.0000 - mae: 67477.8750 - val_loss: 2387136768.0000 - val_mae: 33535.4219\n",
            "Epoch 327/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 9041007616.0000 - mae: 66129.7266 - val_loss: 2386194432.0000 - val_mae: 33471.5273\n",
            "Epoch 328/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 8800456704.0000 - mae: 67864.6250 - val_loss: 2360505344.0000 - val_mae: 33302.1797\n",
            "Epoch 329/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 8559721472.0000 - mae: 66249.6719 - val_loss: 2357516288.0000 - val_mae: 33299.5234\n",
            "Epoch 330/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 8363441664.0000 - mae: 65212.8945 - val_loss: 2372830464.0000 - val_mae: 33404.3984\n",
            "Epoch 331/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 9209081856.0000 - mae: 67601.0547 - val_loss: 2364072704.0000 - val_mae: 33352.8242\n",
            "Epoch 332/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 8568242176.0000 - mae: 67179.3984 - val_loss: 2377719808.0000 - val_mae: 33408.7070\n",
            "Epoch 333/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8364754944.0000 - mae: 64548.7461 - val_loss: 2373710336.0000 - val_mae: 33355.6758\n",
            "Epoch 334/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8328068096.0000 - mae: 65796.2188 - val_loss: 2363990016.0000 - val_mae: 33304.4258\n",
            "Epoch 335/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 8420259840.0000 - mae: 65515.7305 - val_loss: 2354778624.0000 - val_mae: 33212.3633\n",
            "Epoch 336/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8708129792.0000 - mae: 66890.3906 - val_loss: 2368318976.0000 - val_mae: 33315.2539\n",
            "Epoch 337/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9239241728.0000 - mae: 67663.9219 - val_loss: 2349050880.0000 - val_mae: 33152.6289\n",
            "Epoch 338/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8873359360.0000 - mae: 66461.0625 - val_loss: 2372770048.0000 - val_mae: 33329.0977\n",
            "Epoch 339/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 8651218944.0000 - mae: 65845.8672 - val_loss: 2366093056.0000 - val_mae: 33255.5898\n",
            "Epoch 340/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8370142720.0000 - mae: 65429.9062 - val_loss: 2364656128.0000 - val_mae: 33249.1289\n",
            "Epoch 341/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 8407957504.0000 - mae: 65656.5469 - val_loss: 2381840128.0000 - val_mae: 33377.7812\n",
            "Epoch 342/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 8425245184.0000 - mae: 66034.9922 - val_loss: 2412298752.0000 - val_mae: 33566.2148\n",
            "Epoch 343/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9511897088.0000 - mae: 67206.3984 - val_loss: 2374714880.0000 - val_mae: 33261.5977\n",
            "Epoch 344/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 8808761344.0000 - mae: 66912.2109 - val_loss: 2348032512.0000 - val_mae: 33057.9062\n",
            "Epoch 345/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 9149939712.0000 - mae: 66702.3281 - val_loss: 2347505152.0000 - val_mae: 33031.5586\n",
            "Epoch 346/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 9313115136.0000 - mae: 67735.6094 - val_loss: 2367472896.0000 - val_mae: 33171.2500\n",
            "Epoch 347/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 8845342720.0000 - mae: 67280.1641 - val_loss: 2365152256.0000 - val_mae: 33175.3438\n",
            "Epoch 348/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 8335866880.0000 - mae: 66092.1172 - val_loss: 2334319872.0000 - val_mae: 32956.2617\n",
            "Epoch 349/2000\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 9233752064.0000 - mae: 67997.1172 - val_loss: 2308157696.0000 - val_mae: 32730.4863\n",
            "Epoch 350/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 9411080192.0000 - mae: 67943.6719 - val_loss: 2306803712.0000 - val_mae: 32752.6953\n",
            "Epoch 351/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 9173635072.0000 - mae: 67347.4922 - val_loss: 2304937984.0000 - val_mae: 32748.6523\n",
            "Epoch 352/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 8978031616.0000 - mae: 66807.4375 - val_loss: 2326701056.0000 - val_mae: 32920.0078\n",
            "Epoch 353/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8478096896.0000 - mae: 65182.1641 - val_loss: 2317655552.0000 - val_mae: 32834.9258\n",
            "Epoch 354/2000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 8757404672.0000 - mae: 66533.5234 - val_loss: 2300940032.0000 - val_mae: 32704.5371\n",
            "Epoch 355/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8146502144.0000 - mae: 65651.6953 - val_loss: 2310624768.0000 - val_mae: 32750.8535\n",
            "Epoch 356/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 8555964416.0000 - mae: 66421.0703 - val_loss: 2308771328.0000 - val_mae: 32753.4082\n",
            "Epoch 357/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8878868480.0000 - mae: 66808.0859 - val_loss: 2340648448.0000 - val_mae: 32976.8867\n",
            "Epoch 358/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 8590221312.0000 - mae: 65640.5703 - val_loss: 2342944000.0000 - val_mae: 32982.0703\n",
            "Epoch 359/2000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 8785640448.0000 - mae: 66573.7578 - val_loss: 2332132864.0000 - val_mae: 32881.5977\n",
            "Epoch 360/2000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 8623985664.0000 - mae: 66324.2031 - val_loss: 2296630272.0000 - val_mae: 32624.2832\n",
            "Epoch 361/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8935855104.0000 - mae: 66450.1875 - val_loss: 2304763136.0000 - val_mae: 32687.7168\n",
            "Epoch 362/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8854650880.0000 - mae: 66257.9609 - val_loss: 2325497344.0000 - val_mae: 32825.4219\n",
            "Epoch 363/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 9283094528.0000 - mae: 67406.2031 - val_loss: 2307981568.0000 - val_mae: 32711.2734\n",
            "Epoch 364/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 8421038080.0000 - mae: 64815.6484 - val_loss: 2303683840.0000 - val_mae: 32705.5332\n",
            "Epoch 365/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8848820224.0000 - mae: 65889.7969 - val_loss: 2295410432.0000 - val_mae: 32612.7422\n",
            "Epoch 366/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 8342656512.0000 - mae: 65156.1172 - val_loss: 2294309120.0000 - val_mae: 32606.5938\n",
            "Epoch 367/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8916685824.0000 - mae: 66400.9375 - val_loss: 2293757184.0000 - val_mae: 32602.5117\n",
            "Epoch 368/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8873781248.0000 - mae: 67033.3594 - val_loss: 2278965504.0000 - val_mae: 32492.6641\n",
            "Epoch 369/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 9343424512.0000 - mae: 67675.1328 - val_loss: 2277355520.0000 - val_mae: 32506.5371\n",
            "Epoch 370/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8508353536.0000 - mae: 65949.8359 - val_loss: 2301094400.0000 - val_mae: 32694.3965\n",
            "Epoch 371/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 9230450688.0000 - mae: 66059.1484 - val_loss: 2301382656.0000 - val_mae: 32690.6172\n",
            "Epoch 372/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8881290240.0000 - mae: 66623.6172 - val_loss: 2262327040.0000 - val_mae: 32353.6934\n",
            "Epoch 373/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8762126336.0000 - mae: 67149.1016 - val_loss: 2290337536.0000 - val_mae: 32551.0039\n",
            "Epoch 374/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8911728640.0000 - mae: 65492.8281 - val_loss: 2308486400.0000 - val_mae: 32684.0391\n",
            "Epoch 375/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8492858880.0000 - mae: 65774.7031 - val_loss: 2316693248.0000 - val_mae: 32762.0273\n",
            "Epoch 376/2000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 8538308096.0000 - mae: 66496.8984 - val_loss: 2311502592.0000 - val_mae: 32700.1621\n",
            "Epoch 377/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8294322688.0000 - mae: 66168.0312 - val_loss: 2296582912.0000 - val_mae: 32606.5957\n",
            "Epoch 378/2000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 8632186880.0000 - mae: 66260.0938 - val_loss: 2280746752.0000 - val_mae: 32487.9629\n",
            "Epoch 379/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8804098048.0000 - mae: 66704.2422 - val_loss: 2302477312.0000 - val_mae: 32637.9883\n",
            "Epoch 380/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8386996736.0000 - mae: 65000.1172 - val_loss: 2306858496.0000 - val_mae: 32623.8047\n",
            "Epoch 381/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8779131904.0000 - mae: 66074.8203 - val_loss: 2353835008.0000 - val_mae: 32960.2812\n",
            "Epoch 382/2000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 8617692160.0000 - mae: 66060.6797 - val_loss: 2345588992.0000 - val_mae: 32864.4727\n",
            "Epoch 382: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7906343f11b0>"
            ]
          },
          "metadata": {},
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the loss vs epoch chart for both of the trained models. In one of them, the val_loss is lower than the train loss. Which model is that (the one with drop out or the one without drop out?). What is going on here? (15 points)"
      ],
      "metadata": {
        "id": "qd5OeU0_COA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df1 = pd.DataFrame(model.history.history)\n",
        "loss_df1.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VWWp4L1_CSn5",
        "outputId": "75d48fb5-bd65-4296-a092-1bb57e340017"
      },
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             loss           mae      val_loss       val_mae\n",
              "749  2.535933e+09  26924.792969  1.773041e+09  27663.998047\n",
              "750  2.536477e+09  26925.513672  1.774046e+09  27669.207031\n",
              "751  2.536034e+09  26888.574219  1.773870e+09  27657.857422\n",
              "752  2.534351e+09  26883.751953  1.774136e+09  27657.576172\n",
              "753  2.533878e+09  26912.031250  1.774533e+09  27650.335938"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f0d6171-f04f-4195-97c5-c7bcc019f6f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mae</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>749</th>\n",
              "      <td>2.535933e+09</td>\n",
              "      <td>26924.792969</td>\n",
              "      <td>1.773041e+09</td>\n",
              "      <td>27663.998047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750</th>\n",
              "      <td>2.536477e+09</td>\n",
              "      <td>26925.513672</td>\n",
              "      <td>1.774046e+09</td>\n",
              "      <td>27669.207031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>2.536034e+09</td>\n",
              "      <td>26888.574219</td>\n",
              "      <td>1.773870e+09</td>\n",
              "      <td>27657.857422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>752</th>\n",
              "      <td>2.534351e+09</td>\n",
              "      <td>26883.751953</td>\n",
              "      <td>1.774136e+09</td>\n",
              "      <td>27657.576172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>2.533878e+09</td>\n",
              "      <td>26912.031250</td>\n",
              "      <td>1.774533e+09</td>\n",
              "      <td>27650.335938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f0d6171-f04f-4195-97c5-c7bcc019f6f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f0d6171-f04f-4195-97c5-c7bcc019f6f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f0d6171-f04f-4195-97c5-c7bcc019f6f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-def8ac25-1eff-48ac-a8e9-762402469b0b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-def8ac25-1eff-48ac-a8e9-762402469b0b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-def8ac25-1eff-48ac-a8e9-762402469b0b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 324
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df1[['loss', 'val_loss']].plot(legend=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "ht-zFWivBpyc",
        "outputId": "6b0b6080-6f09-4762-893e-e9a5034b8f57"
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df2 = pd.DataFrame(model_d.history.history)\n",
        "loss_df2.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XSEH4ZutBiXD",
        "outputId": "6dcc8b28-22ed-4b3a-d525-2e24e5dcb515"
      },
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             loss           mae      val_loss       val_mae\n",
              "377  8.632187e+09  66260.093750  2.280747e+09  32487.962891\n",
              "378  8.804098e+09  66704.242188  2.302477e+09  32637.988281\n",
              "379  8.386997e+09  65000.117188  2.306858e+09  32623.804688\n",
              "380  8.779132e+09  66074.820312  2.353835e+09  32960.281250\n",
              "381  8.617692e+09  66060.679688  2.345589e+09  32864.472656"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b78d1635-a344-4db3-b009-73f8ab078856\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mae</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>8.632187e+09</td>\n",
              "      <td>66260.093750</td>\n",
              "      <td>2.280747e+09</td>\n",
              "      <td>32487.962891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>8.804098e+09</td>\n",
              "      <td>66704.242188</td>\n",
              "      <td>2.302477e+09</td>\n",
              "      <td>32637.988281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>8.386997e+09</td>\n",
              "      <td>65000.117188</td>\n",
              "      <td>2.306858e+09</td>\n",
              "      <td>32623.804688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>8.779132e+09</td>\n",
              "      <td>66074.820312</td>\n",
              "      <td>2.353835e+09</td>\n",
              "      <td>32960.281250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>8.617692e+09</td>\n",
              "      <td>66060.679688</td>\n",
              "      <td>2.345589e+09</td>\n",
              "      <td>32864.472656</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b78d1635-a344-4db3-b009-73f8ab078856')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b78d1635-a344-4db3-b009-73f8ab078856 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b78d1635-a344-4db3-b009-73f8ab078856');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aa1db7b6-bf89-45aa-9a81-7452bd812c86\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa1db7b6-bf89-45aa-9a81-7452bd812c86')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aa1db7b6-bf89-45aa-9a81-7452bd812c86 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 326
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df2[['loss', 'val_loss']].plot(legend=True) #with dropout\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "I-fbbBX3CFZ4",
        "outputId": "47647947-f133-48ad-e810-6224492e9fc6"
      },
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model with drop out has a significantly lower val_ loss compared to loss. In the training phase some of the neurons are dropped out, reducing the model's effective capacity. The validation set doesn't have drop out and so it is using all the neurons which is why val_loss is less than loss from the dropout."
      ],
      "metadata": {
        "id": "Qg7D3K6LCgAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model without drop out and report the loss and MAE in the test set. (5 points)"
      ],
      "metadata": {
        "id": "kwhGGsN-CTtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwGpXWurCWfn",
        "outputId": "defadf4f-6c65-4208-a26f-98e615df1f5b"
      },
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 2ms/step - loss: 1774533248.0000 - mae: 27650.3379\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1774533248.0, 27650.337890625]"
            ]
          },
          "metadata": {},
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am unsure if these values are supposed to be this high. I ran into problems with tenserflow.keras with filepath on the Modelcheckpoint module. Chatgpt suggested I change it to what is listed above. If this is normal, the loss is 1774533248 and the MAE is 27650."
      ],
      "metadata": {
        "id": "_jjp_70zCrEb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, use the results from the model without drop out and save the predictions in the test set as y_test_pred. (5 points)"
      ],
      "metadata": {
        "id": "xA9UYfjdCW5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0ZdSeWtCZgY",
        "outputId": "723692df-daf4-4d63-c981-b7f87984f05d"
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YumcgtJnNU-L",
        "outputId": "c7daacf3-3a7e-4de9-aead-bc74ed4e85b6"
      },
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[467611.94 ],\n",
              "       [235205.12 ],\n",
              "       [278985.75 ],\n",
              "       [304803.2  ],\n",
              "       [282923.94 ],\n",
              "       [296426.88 ],\n",
              "       [224864.6  ],\n",
              "       [242261.69 ],\n",
              "       [186930.67 ],\n",
              "       [367941.84 ],\n",
              "       [217889.69 ],\n",
              "       [250433.94 ],\n",
              "       [277494.44 ],\n",
              "       [158269.45 ],\n",
              "       [340948.3  ],\n",
              "       [323802.06 ],\n",
              "       [258723.8  ],\n",
              "       [260695.03 ],\n",
              "       [196814.45 ],\n",
              "       [290081.06 ],\n",
              "       [270401.94 ],\n",
              "       [204109.78 ],\n",
              "       [156742.73 ],\n",
              "       [170297.16 ],\n",
              "       [231793.5  ],\n",
              "       [201068.9  ],\n",
              "       [168685.73 ],\n",
              "       [189723.16 ],\n",
              "       [263537.1  ],\n",
              "       [259915.56 ],\n",
              "       [324069.56 ],\n",
              "       [272689.3  ],\n",
              "       [223383.72 ],\n",
              "       [220389.84 ],\n",
              "       [191218.56 ],\n",
              "       [206578.19 ],\n",
              "       [421681.56 ],\n",
              "       [238819.1  ],\n",
              "       [317445.5  ],\n",
              "       [325328.88 ],\n",
              "       [175549.97 ],\n",
              "       [178366.88 ],\n",
              "       [257683.12 ],\n",
              "       [232447.5  ],\n",
              "       [394318.78 ],\n",
              "       [248199.92 ],\n",
              "       [299847.84 ],\n",
              "       [211046.27 ],\n",
              "       [303404.6  ],\n",
              "       [234250.4  ],\n",
              "       [262718.66 ],\n",
              "       [220378.11 ],\n",
              "       [229385.5  ],\n",
              "       [279325.   ],\n",
              "       [371029.   ],\n",
              "       [473958.75 ],\n",
              "       [225246.66 ],\n",
              "       [257770.58 ],\n",
              "       [562812.3  ],\n",
              "       [265919.25 ],\n",
              "       [234549.9  ],\n",
              "       [358096.7  ],\n",
              "       [218441.1  ],\n",
              "       [289377.88 ],\n",
              "       [160616.03 ],\n",
              "       [243990.12 ],\n",
              "       [416718.44 ],\n",
              "       [398185.1  ],\n",
              "       [412236.56 ],\n",
              "       [286800.53 ],\n",
              "       [303016.25 ],\n",
              "       [241686.47 ],\n",
              "       [638980.8  ],\n",
              "       [355956.06 ],\n",
              "       [275352.9  ],\n",
              "       [380084.7  ],\n",
              "       [204856.9  ],\n",
              "       [257593.56 ],\n",
              "       [205875.75 ],\n",
              "       [304013.75 ],\n",
              "       [272840.4  ],\n",
              "       [279405.5  ],\n",
              "       [175423.02 ],\n",
              "       [225102.56 ],\n",
              "       [286005.56 ],\n",
              "       [215190.12 ],\n",
              "       [217244.62 ],\n",
              "       [384662.62 ],\n",
              "       [226099.88 ],\n",
              "       [463290.06 ],\n",
              "       [145721.22 ],\n",
              "       [229545.8  ],\n",
              "       [278216.12 ],\n",
              "       [191720.1  ],\n",
              "       [312901.8  ],\n",
              "       [322723.38 ],\n",
              "       [405392.34 ],\n",
              "       [224955.06 ],\n",
              "       [221049.19 ],\n",
              "       [203696.   ],\n",
              "       [488485.5  ],\n",
              "       [218131.7  ],\n",
              "       [160962.12 ],\n",
              "       [181674.   ],\n",
              "       [130033.664],\n",
              "       [320819.75 ],\n",
              "       [136495.06 ],\n",
              "       [331853.25 ],\n",
              "       [262577.75 ],\n",
              "       [231059.81 ],\n",
              "       [139760.25 ],\n",
              "       [495139.56 ],\n",
              "       [312339.88 ],\n",
              "       [272447.66 ],\n",
              "       [193851.75 ],\n",
              "       [216000.42 ],\n",
              "       [233078.72 ],\n",
              "       [443457.3  ],\n",
              "       [249568.03 ],\n",
              "       [330556.25 ],\n",
              "       [208323.06 ],\n",
              "       [269783.06 ],\n",
              "       [247948.34 ],\n",
              "       [270425.16 ],\n",
              "       [366374.   ],\n",
              "       [216248.19 ],\n",
              "       [422863.16 ],\n",
              "       [247641.88 ],\n",
              "       [434671.4  ],\n",
              "       [246070.9  ],\n",
              "       [332293.94 ],\n",
              "       [161156.75 ],\n",
              "       [211587.77 ],\n",
              "       [260336.31 ],\n",
              "       [380044.25 ],\n",
              "       [223247.03 ],\n",
              "       [260965.42 ],\n",
              "       [347579.75 ],\n",
              "       [199091.39 ],\n",
              "       [210494.3  ],\n",
              "       [298436.12 ],\n",
              "       [336449.06 ],\n",
              "       [392166.72 ],\n",
              "       [188305.69 ],\n",
              "       [222516.   ],\n",
              "       [171020.27 ],\n",
              "       [329597.3  ],\n",
              "       [148400.06 ],\n",
              "       [214019.72 ],\n",
              "       [292792.1  ],\n",
              "       [291625.8  ],\n",
              "       [322150.4  ],\n",
              "       [311973.34 ],\n",
              "       [230881.11 ],\n",
              "       [221475.97 ],\n",
              "       [266105.3  ],\n",
              "       [263317.47 ],\n",
              "       [165593.84 ],\n",
              "       [322172.25 ],\n",
              "       [221245.72 ],\n",
              "       [247047.88 ],\n",
              "       [348768.06 ],\n",
              "       [231587.06 ],\n",
              "       [165279.47 ],\n",
              "       [188834.62 ],\n",
              "       [132226.02 ],\n",
              "       [315212.8  ],\n",
              "       [165240.   ],\n",
              "       [249526.47 ],\n",
              "       [490351.5  ],\n",
              "       [227814.03 ],\n",
              "       [364084.97 ],\n",
              "       [291455.72 ],\n",
              "       [199795.61 ],\n",
              "       [352033.84 ],\n",
              "       [250434.34 ],\n",
              "       [214887.08 ],\n",
              "       [318850.8  ],\n",
              "       [231043.69 ],\n",
              "       [381039.38 ],\n",
              "       [215326.47 ],\n",
              "       [205137.56 ],\n",
              "       [483418.94 ],\n",
              "       [250609.86 ],\n",
              "       [232762.5  ],\n",
              "       [207275.9  ],\n",
              "       [277098.2  ],\n",
              "       [222091.69 ],\n",
              "       [194290.17 ],\n",
              "       [157124.06 ],\n",
              "       [397615.06 ],\n",
              "       [291480.25 ],\n",
              "       [337566.2  ],\n",
              "       [801605.4  ],\n",
              "       [156048.61 ],\n",
              "       [263932.12 ],\n",
              "       [186510.44 ],\n",
              "       [290686.47 ],\n",
              "       [276394.8  ],\n",
              "       [211532.98 ],\n",
              "       [261376.84 ],\n",
              "       [450910.6  ],\n",
              "       [360397.75 ],\n",
              "       [275860.62 ],\n",
              "       [597256.2  ],\n",
              "       [284717.9  ],\n",
              "       [195279.22 ],\n",
              "       [221116.88 ],\n",
              "       [367254.2  ],\n",
              "       [219508.31 ],\n",
              "       [226584.23 ],\n",
              "       [207856.25 ],\n",
              "       [278309.   ],\n",
              "       [207388.97 ],\n",
              "       [367553.12 ],\n",
              "       [406488.22 ],\n",
              "       [376348.16 ],\n",
              "       [280374.56 ],\n",
              "       [286305.12 ],\n",
              "       [232283.75 ],\n",
              "       [251797.28 ],\n",
              "       [343306.4  ],\n",
              "       [205198.3  ],\n",
              "       [191568.6  ],\n",
              "       [349484.2  ],\n",
              "       [212543.4  ],\n",
              "       [212657.38 ],\n",
              "       [406961.88 ],\n",
              "       [356239.53 ],\n",
              "       [358817.   ],\n",
              "       [618018.2  ],\n",
              "       [280259.78 ],\n",
              "       [135915.47 ],\n",
              "       [221561.16 ],\n",
              "       [221120.77 ],\n",
              "       [236607.28 ],\n",
              "       [155854.34 ],\n",
              "       [206626.12 ],\n",
              "       [554458.56 ],\n",
              "       [192721.69 ],\n",
              "       [367645.53 ],\n",
              "       [255882.33 ],\n",
              "       [249718.84 ],\n",
              "       [250163.34 ],\n",
              "       [192144.95 ],\n",
              "       [231143.31 ],\n",
              "       [304812.2  ],\n",
              "       [243782.28 ],\n",
              "       [192607.81 ],\n",
              "       [440865.5  ],\n",
              "       [308535.38 ],\n",
              "       [542060.5  ],\n",
              "       [356080.84 ],\n",
              "       [194558.33 ],\n",
              "       [204290.88 ],\n",
              "       [174426.62 ],\n",
              "       [315098.5  ],\n",
              "       [217852.84 ],\n",
              "       [264974.3  ],\n",
              "       [360081.25 ],\n",
              "       [135221.25 ],\n",
              "       [165088.9  ],\n",
              "       [228135.88 ],\n",
              "       [232414.73 ],\n",
              "       [369363.44 ],\n",
              "       [552083.75 ],\n",
              "       [158527.75 ],\n",
              "       [318083.38 ],\n",
              "       [469603.12 ],\n",
              "       [384424.2  ],\n",
              "       [296922.75 ],\n",
              "       [188061.34 ],\n",
              "       [190297.72 ],\n",
              "       [175690.9  ],\n",
              "       [275873.03 ],\n",
              "       [261736.5  ],\n",
              "       [357931.38 ],\n",
              "       [295833.25 ],\n",
              "       [201606.81 ],\n",
              "       [304969.06 ],\n",
              "       [218063.22 ],\n",
              "       [279343.12 ],\n",
              "       [640990.25 ],\n",
              "       [391610.25 ],\n",
              "       [222631.61 ],\n",
              "       [192306.83 ],\n",
              "       [165805.53 ],\n",
              "       [339137.7  ],\n",
              "       [281165.   ],\n",
              "       [164990.08 ],\n",
              "       [311881.1  ],\n",
              "       [356157.06 ],\n",
              "       [192069.94 ],\n",
              "       [271835.16 ],\n",
              "       [362897.5  ],\n",
              "       [282173.66 ],\n",
              "       [314021.6  ],\n",
              "       [414838.72 ],\n",
              "       [266603.62 ],\n",
              "       [530049.   ],\n",
              "       [138900.81 ],\n",
              "       [154283.12 ],\n",
              "       [326475.06 ],\n",
              "       [171604.27 ],\n",
              "       [271170.3  ],\n",
              "       [201385.22 ],\n",
              "       [250517.16 ],\n",
              "       [427181.12 ],\n",
              "       [344823.22 ],\n",
              "       [479762.88 ],\n",
              "       [249816.58 ],\n",
              "       [259733.72 ],\n",
              "       [245189.05 ],\n",
              "       [206589.5  ],\n",
              "       [235147.53 ],\n",
              "       [303739.5  ],\n",
              "       [252939.08 ],\n",
              "       [282041.28 ],\n",
              "       [ 66484.586],\n",
              "       [378338.5  ],\n",
              "       [229661.61 ],\n",
              "       [256624.62 ],\n",
              "       [230559.08 ],\n",
              "       [287498.   ],\n",
              "       [183407.52 ],\n",
              "       [198123.66 ],\n",
              "       [215911.03 ],\n",
              "       [375999.72 ],\n",
              "       [162961.69 ],\n",
              "       [259015.   ],\n",
              "       [139553.75 ],\n",
              "       [169729.47 ],\n",
              "       [298246.12 ],\n",
              "       [288559.   ],\n",
              "       [254296.5  ],\n",
              "       [280498.44 ],\n",
              "       [269036.94 ],\n",
              "       [200485.16 ],\n",
              "       [223786.   ],\n",
              "       [268626.62 ],\n",
              "       [146771.22 ],\n",
              "       [279782.97 ],\n",
              "       [355050.8  ],\n",
              "       [302260.6  ],\n",
              "       [235154.9  ],\n",
              "       [222583.44 ],\n",
              "       [310566.6  ],\n",
              "       [228431.38 ],\n",
              "       [495540.22 ],\n",
              "       [260964.27 ],\n",
              "       [389956.94 ],\n",
              "       [229649.19 ],\n",
              "       [306318.9  ],\n",
              "       [283313.44 ],\n",
              "       [228274.4  ],\n",
              "       [197409.17 ],\n",
              "       [420478.62 ],\n",
              "       [177856.56 ],\n",
              "       [192258.7  ],\n",
              "       [337483.12 ],\n",
              "       [649458.2  ],\n",
              "       [353262.75 ],\n",
              "       [389812.56 ],\n",
              "       [158927.16 ],\n",
              "       [298866.8  ],\n",
              "       [355652.78 ],\n",
              "       [ 59685.473],\n",
              "       [231703.19 ],\n",
              "       [364874.53 ],\n",
              "       [242180.6  ],\n",
              "       [506238.56 ],\n",
              "       [216889.52 ],\n",
              "       [261281.97 ],\n",
              "       [222103.72 ],\n",
              "       [193553.56 ],\n",
              "       [356054.66 ],\n",
              "       [425895.78 ],\n",
              "       [584800.2  ],\n",
              "       [246017.81 ],\n",
              "       [255162.36 ],\n",
              "       [230290.38 ],\n",
              "       [221944.53 ],\n",
              "       [406383.8  ],\n",
              "       [342833.44 ],\n",
              "       [248009.61 ],\n",
              "       [218805.16 ],\n",
              "       [184085.56 ],\n",
              "       [182059.88 ],\n",
              "       [317935.9  ],\n",
              "       [237981.53 ],\n",
              "       [249743.06 ],\n",
              "       [238454.27 ],\n",
              "       [194411.72 ],\n",
              "       [313769.7  ],\n",
              "       [390382.8  ],\n",
              "       [337990.06 ],\n",
              "       [545642.56 ],\n",
              "       [334085.66 ],\n",
              "       [203892.3  ],\n",
              "       [243478.67 ],\n",
              "       [414130.06 ],\n",
              "       [386585.88 ],\n",
              "       [314186.2  ],\n",
              "       [401998.6  ],\n",
              "       [232239.6  ],\n",
              "       [226890.44 ],\n",
              "       [303824.7  ],\n",
              "       [234514.34 ],\n",
              "       [287248.12 ],\n",
              "       [284721.25 ],\n",
              "       [224801.94 ],\n",
              "       [211134.4  ],\n",
              "       [256527.95 ],\n",
              "       [519784.3  ],\n",
              "       [244633.55 ],\n",
              "       [339462.44 ],\n",
              "       [240476.1  ],\n",
              "       [259307.4  ],\n",
              "       [193063.94 ],\n",
              "       [364177.88 ],\n",
              "       [201864.03 ],\n",
              "       [295666.88 ],\n",
              "       [296848.53 ],\n",
              "       [322492.25 ],\n",
              "       [182915.75 ],\n",
              "       [214836.1  ],\n",
              "       [343588.3  ],\n",
              "       [271070.84 ],\n",
              "       [216040.22 ],\n",
              "       [209022.81 ],\n",
              "       [292047.12 ],\n",
              "       [196455.62 ],\n",
              "       [253417.67 ],\n",
              "       [320160.22 ],\n",
              "       [251708.22 ],\n",
              "       [154111.9  ],\n",
              "       [693042.75 ],\n",
              "       [151342.28 ],\n",
              "       [357329.72 ],\n",
              "       [267671.38 ],\n",
              "       [221203.36 ],\n",
              "       [277761.62 ],\n",
              "       [331066.34 ],\n",
              "       [312051.62 ],\n",
              "       [228918.81 ],\n",
              "       [480251.5  ],\n",
              "       [215381.83 ],\n",
              "       [250135.22 ],\n",
              "       [275964.88 ],\n",
              "       [187868.61 ],\n",
              "       [269577.4  ],\n",
              "       [232659.72 ],\n",
              "       [322885.66 ],\n",
              "       [508694.97 ],\n",
              "       [429977.53 ],\n",
              "       [234315.75 ],\n",
              "       [148210.   ],\n",
              "       [199017.31 ],\n",
              "       [413667.53 ],\n",
              "       [287457.53 ],\n",
              "       [206191.34 ],\n",
              "       [221848.88 ],\n",
              "       [366030.4  ],\n",
              "       [545427.56 ],\n",
              "       [289732.62 ],\n",
              "       [218799.47 ],\n",
              "       [277454.1  ],\n",
              "       [200875.4  ],\n",
              "       [321557.53 ],\n",
              "       [187022.88 ],\n",
              "       [225033.95 ],\n",
              "       [231786.78 ],\n",
              "       [371011.72 ],\n",
              "       [159274.44 ],\n",
              "       [621249.56 ],\n",
              "       [288058.34 ],\n",
              "       [248727.47 ],\n",
              "       [212119.25 ],\n",
              "       [306616.38 ],\n",
              "       [226879.16 ],\n",
              "       [362814.75 ],\n",
              "       [313058.7  ],\n",
              "       [234102.84 ],\n",
              "       [181798.4  ],\n",
              "       [197845.27 ],\n",
              "       [249041.6  ],\n",
              "       [174585.98 ],\n",
              "       [141998.48 ],\n",
              "       [256630.1  ],\n",
              "       [162202.97 ],\n",
              "       [240025.   ],\n",
              "       [269053.56 ],\n",
              "       [277969.7  ],\n",
              "       [734811.4  ],\n",
              "       [201237.34 ],\n",
              "       [531112.   ],\n",
              "       [213419.88 ],\n",
              "       [196567.22 ],\n",
              "       [247575.2  ],\n",
              "       [405013.25 ],\n",
              "       [346982.97 ],\n",
              "       [595474.94 ],\n",
              "       [242352.5  ],\n",
              "       [353428.   ],\n",
              "       [236892.27 ],\n",
              "       [198689.22 ],\n",
              "       [232803.53 ],\n",
              "       [361415.25 ],\n",
              "       [137007.53 ],\n",
              "       [286303.53 ],\n",
              "       [361544.84 ],\n",
              "       [362298.66 ],\n",
              "       [208652.06 ],\n",
              "       [252424.22 ],\n",
              "       [310802.5  ],\n",
              "       [361335.16 ],\n",
              "       [235419.06 ],\n",
              "       [314755.8  ],\n",
              "       [235198.66 ],\n",
              "       [469220.06 ],\n",
              "       [217085.94 ],\n",
              "       [213497.28 ],\n",
              "       [196941.34 ],\n",
              "       [301796.56 ],\n",
              "       [366189.84 ],\n",
              "       [251969.45 ],\n",
              "       [225121.34 ],\n",
              "       [233017.22 ],\n",
              "       [250625.64 ],\n",
              "       [206441.69 ],\n",
              "       [293983.25 ],\n",
              "       [203943.88 ],\n",
              "       [297786.94 ],\n",
              "       [239904.6  ],\n",
              "       [444221.06 ],\n",
              "       [253406.38 ],\n",
              "       [218104.4  ],\n",
              "       [234205.03 ],\n",
              "       [284561.94 ],\n",
              "       [214500.06 ],\n",
              "       [228742.58 ],\n",
              "       [185240.14 ],\n",
              "       [311031.03 ],\n",
              "       [335649.16 ],\n",
              "       [223085.64 ],\n",
              "       [339010.06 ],\n",
              "       [242112.6  ],\n",
              "       [357731.44 ],\n",
              "       [230648.47 ],\n",
              "       [248759.9  ],\n",
              "       [284967.8  ],\n",
              "       [277036.94 ],\n",
              "       [441614.7  ],\n",
              "       [253507.44 ],\n",
              "       [320368.03 ],\n",
              "       [667126.7  ],\n",
              "       [213108.08 ],\n",
              "       [447505.12 ],\n",
              "       [446361.5  ],\n",
              "       [256209.88 ],\n",
              "       [311355.5  ],\n",
              "       [239749.66 ],\n",
              "       [243343.78 ],\n",
              "       [596699.5  ],\n",
              "       [355967.06 ],\n",
              "       [203660.8  ],\n",
              "       [206617.45 ],\n",
              "       [227415.67 ],\n",
              "       [378872.03 ],\n",
              "       [416471.94 ],\n",
              "       [189536.25 ],\n",
              "       [159324.83 ],\n",
              "       [770370.94 ],\n",
              "       [204011.64 ],\n",
              "       [227500.34 ],\n",
              "       [355422.75 ],\n",
              "       [281190.56 ],\n",
              "       [197797.11 ],\n",
              "       [190814.48 ],\n",
              "       [198705.22 ],\n",
              "       [218495.58 ],\n",
              "       [189589.34 ],\n",
              "       [267946.44 ],\n",
              "       [338755.2  ],\n",
              "       [454631.6  ],\n",
              "       [285539.12 ],\n",
              "       [346092.   ],\n",
              "       [158780.88 ],\n",
              "       [204511.05 ],\n",
              "       [191076.97 ],\n",
              "       [310088.25 ],\n",
              "       [314076.56 ],\n",
              "       [237871.   ],\n",
              "       [297300.94 ],\n",
              "       [395663.4  ],\n",
              "       [203426.5  ],\n",
              "       [502545.84 ],\n",
              "       [197124.9  ],\n",
              "       [376484.88 ],\n",
              "       [355906.94 ],\n",
              "       [409439.88 ],\n",
              "       [332314.6  ],\n",
              "       [512002.   ],\n",
              "       [182405.94 ],\n",
              "       [197410.33 ],\n",
              "       [308673.22 ],\n",
              "       [465804.5  ],\n",
              "       [380021.   ],\n",
              "       [275523.3  ],\n",
              "       [231471.88 ],\n",
              "       [298066.44 ],\n",
              "       [176685.56 ],\n",
              "       [227002.84 ],\n",
              "       [208750.62 ],\n",
              "       [333621.25 ],\n",
              "       [247149.81 ],\n",
              "       [380057.   ],\n",
              "       [434003.75 ],\n",
              "       [342612.25 ],\n",
              "       [191488.47 ],\n",
              "       [212012.53 ],\n",
              "       [323475.4  ],\n",
              "       [210612.42 ],\n",
              "       [250663.84 ],\n",
              "       [223537.36 ],\n",
              "       [257480.52 ],\n",
              "       [223200.72 ],\n",
              "       [261313.69 ],\n",
              "       [283175.22 ],\n",
              "       [225622.9  ],\n",
              "       [223848.19 ],\n",
              "       [282841.38 ],\n",
              "       [117849.32 ],\n",
              "       [232732.03 ],\n",
              "       [241403.2  ],\n",
              "       [265162.88 ],\n",
              "       [431251.8  ],\n",
              "       [444796.3  ],\n",
              "       [270655.94 ],\n",
              "       [391341.97 ],\n",
              "       [189716.77 ],\n",
              "       [238114.53 ],\n",
              "       [277105.8  ],\n",
              "       [265573.7  ],\n",
              "       [270841.3  ],\n",
              "       [318039.75 ],\n",
              "       [339281.9  ],\n",
              "       [199551.28 ],\n",
              "       [642441.2  ],\n",
              "       [251183.72 ],\n",
              "       [376239.88 ],\n",
              "       [485637.75 ],\n",
              "       [228253.56 ],\n",
              "       [285181.4  ],\n",
              "       [449432.2  ],\n",
              "       [236585.03 ],\n",
              "       [252432.12 ],\n",
              "       [211228.11 ],\n",
              "       [175788.72 ],\n",
              "       [263053.75 ],\n",
              "       [241575.48 ],\n",
              "       [259191.03 ],\n",
              "       [697106.2  ],\n",
              "       [219480.72 ],\n",
              "       [349280.   ],\n",
              "       [397283.7  ],\n",
              "       [269034.5  ],\n",
              "       [170731.7  ],\n",
              "       [247992.48 ],\n",
              "       [208770.94 ],\n",
              "       [242576.06 ],\n",
              "       [625291.06 ],\n",
              "       [293577.   ],\n",
              "       [303755.53 ],\n",
              "       [378505.   ],\n",
              "       [183688.9  ],\n",
              "       [211945.06 ],\n",
              "       [194965.44 ],\n",
              "       [239410.19 ],\n",
              "       [262387.3  ],\n",
              "       [184631.58 ],\n",
              "       [561949.44 ],\n",
              "       [254007.16 ],\n",
              "       [176399.4  ],\n",
              "       [213677.31 ],\n",
              "       [280717.12 ],\n",
              "       [390236.4  ],\n",
              "       [259751.28 ],\n",
              "       [209074.8  ],\n",
              "       [283465.94 ],\n",
              "       [332771.78 ],\n",
              "       [240161.92 ],\n",
              "       [258082.88 ],\n",
              "       [815447.25 ],\n",
              "       [247799.5  ],\n",
              "       [818172.7  ],\n",
              "       [306556.7  ],\n",
              "       [433427.22 ],\n",
              "       [195463.16 ],\n",
              "       [406051.7  ],\n",
              "       [239288.78 ],\n",
              "       [279118.44 ],\n",
              "       [291793.88 ],\n",
              "       [313259.44 ],\n",
              "       [189042.72 ],\n",
              "       [191766.03 ],\n",
              "       [233463.31 ],\n",
              "       [247433.19 ],\n",
              "       [205047.52 ],\n",
              "       [255219.9  ],\n",
              "       [152546.11 ],\n",
              "       [154202.6  ],\n",
              "       [326209.66 ],\n",
              "       [647935.2  ],\n",
              "       [197970.3  ],\n",
              "       [277764.22 ],\n",
              "       [461514.2  ],\n",
              "       [228545.44 ],\n",
              "       [264214.94 ],\n",
              "       [322449.62 ],\n",
              "       [202743.53 ],\n",
              "       [219909.55 ],\n",
              "       [347729.7  ],\n",
              "       [270777.56 ],\n",
              "       [196248.4  ],\n",
              "       [263512.5  ],\n",
              "       [286131.94 ],\n",
              "       [366505.4  ],\n",
              "       [251767.25 ],\n",
              "       [208410.31 ],\n",
              "       [269473.7  ],\n",
              "       [198418.8  ],\n",
              "       [191521.67 ],\n",
              "       [646642.   ],\n",
              "       [264866.2  ],\n",
              "       [250110.69 ],\n",
              "       [218995.78 ],\n",
              "       [208989.22 ],\n",
              "       [328180.47 ],\n",
              "       [267118.72 ],\n",
              "       [383141.5  ],\n",
              "       [384017.88 ],\n",
              "       [287095.84 ],\n",
              "       [152457.19 ],\n",
              "       [277022.94 ],\n",
              "       [605431.25 ],\n",
              "       [361466.5  ],\n",
              "       [181474.56 ],\n",
              "       [261989.2  ],\n",
              "       [387375.3  ],\n",
              "       [289742.38 ],\n",
              "       [221402.17 ],\n",
              "       [328450.06 ],\n",
              "       [310737.   ],\n",
              "       [293790.3  ],\n",
              "       [185301.94 ],\n",
              "       [254734.56 ],\n",
              "       [802291.56 ],\n",
              "       [349637.8  ],\n",
              "       [337473.28 ],\n",
              "       [246733.66 ],\n",
              "       [216077.34 ],\n",
              "       [303755.06 ],\n",
              "       [984442.25 ],\n",
              "       [221850.83 ],\n",
              "       [384989.62 ],\n",
              "       [257319.47 ],\n",
              "       [210300.66 ],\n",
              "       [233265.53 ],\n",
              "       [197672.6  ],\n",
              "       [187256.23 ],\n",
              "       [407473.25 ],\n",
              "       [154186.22 ],\n",
              "       [337343.34 ],\n",
              "       [227607.16 ],\n",
              "       [288562.3  ],\n",
              "       [365607.53 ],\n",
              "       [364961.22 ],\n",
              "       [186718.62 ],\n",
              "       [233177.61 ],\n",
              "       [210774.1  ],\n",
              "       [448168.88 ],\n",
              "       [194747.67 ],\n",
              "       [431578.12 ],\n",
              "       [344617.75 ],\n",
              "       [341463.12 ],\n",
              "       [454425.78 ],\n",
              "       [232212.38 ],\n",
              "       [228999.1  ],\n",
              "       [240693.84 ],\n",
              "       [218463.62 ],\n",
              "       [391697.34 ],\n",
              "       [354983.94 ],\n",
              "       [241684.77 ],\n",
              "       [431301.12 ],\n",
              "       [225107.5  ],\n",
              "       [210902.94 ],\n",
              "       [184787.19 ],\n",
              "       [537235.75 ],\n",
              "       [311335.94 ],\n",
              "       [269281.53 ],\n",
              "       [187600.5  ],\n",
              "       [200710.75 ],\n",
              "       [407987.88 ],\n",
              "       [239474.75 ],\n",
              "       [226927.69 ],\n",
              "       [314205.94 ],\n",
              "       [215910.5  ],\n",
              "       [227809.23 ],\n",
              "       [443382.47 ],\n",
              "       [195414.78 ],\n",
              "       [226629.6  ],\n",
              "       [291774.9  ],\n",
              "       [338573.06 ],\n",
              "       [186006.1  ],\n",
              "       [296488.25 ],\n",
              "       [136106.34 ],\n",
              "       [270313.38 ],\n",
              "       [324406.94 ],\n",
              "       [305979.44 ],\n",
              "       [547646.25 ],\n",
              "       [255278.78 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From sklearn.metrics, import mean_absolute_percentage_error, explained_variance_score and r2_score. Read sklearn documentation to make sure you understand what are these metrics. Report these metrics in the test set using model without drop out? (6 points)"
      ],
      "metadata": {
        "id": "aqwtDstGCZ1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error, explained_variance_score, r2_score"
      ],
      "metadata": {
        "id": "u6I07Qp7CcjM"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean_absolute_percentage_error(y_test, y_test_pred))\n",
        "print(explained_variance_score(y_test, y_test_pred))\n",
        "print(r2_score(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXzFbUkWMluV",
        "outputId": "1f27d2e6-0c37-4f6c-b96d-652ae8e9128d"
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12430888208784613\n",
            "0.8715249660251378\n",
            "0.8709762776591102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the MAPE, the model without dropout on average is 12.43 percent off with its predictions. Based on the explained variance score, the model can explain for 87.15 percent of the variation in housing prices. Based on the r2 score, the model's variance is able to be predicted 87.10 percent of the time by the model features."
      ],
      "metadata": {
        "id": "7Vb7nDIcOFrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Plot the scatter plot for y_true vs y_pred in the test set. Are you satisfied with what you observe? Hint: in a prefect regression model, y_true and y_pred will line up along the 45 degree line. (4 points)\n"
      ],
      "metadata": {
        "id": "lx1aR2CIBXEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(y_test,y_test_pred)\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "-oYDp4vuCcCv",
        "outputId": "8e23bb5a-6b9c-4242-fc1d-88e474898e1b"
      },
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Predictions')"
            ]
          },
          "metadata": {},
          "execution_count": 333
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model predicts well for lower values, but for higher values it doesn't predict as well. Overall it does a good job predicting, but I wouldn't rely as much on the higher valued predictions."
      ],
      "metadata": {
        "id": "xwnp_y_rWWjR"
      }
    }
  ]
}